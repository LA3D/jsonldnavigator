{"cells": [{"cell_type": "code", "metadata": {}, "source": ["# Install from GitHub package\n", "# !pip install -U git+https://github.com/LA3D/jsonldnavigator.git"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["from fastcore.utils import *"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "Hi solveit! I am Chuck, and I am working with you today! I'm an experienced Python coder, experienced with semantic web technologies like OWL,RDF and SPARQL, and I enjoy learning new things. When writing code for me, please follow fast.ai coding style: avoid comments; place single line if/loop/etc constructs on the same line; use concise variable names where appropriate. Follow the style you will see in my messages, as we work on this dialogue together. Are you ready?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "Hi Chuck! Great to meet you. I'm ready to work with you using fast.ai coding style - concise variable names, single-line constructs, and minimal comments. I'll follow your lead as we work together.\n", "\n", "What would you like to explore today? With your background in Python and semantic web technologies, we have many interesting directions we could take."]}, {"cell_type": "code", "metadata": {}, "source": ["from httpx import get as xget, post as xpost\n", "from bs4 import BeautifulSoup as bs\n", "from fastcore.utils import *\n", "import json\n", "from typing import Any, Dict, List, Optional, Union\n", "from pyld import jsonld  # For JSON-LD processing\n", "import mlcroissant as mlc\n", "import pandas as pd\n", "from claudette import *"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["from IPython.display import display,HTML,Markdown"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["jsonlddoc=xget('https://r.jina.ai/https://www.w3.org/TR/json-ld11/').text"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["from toolslm.md_hier import *"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["hdgs = create_heading_dict(jsonlddoc)"], "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n", "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)\n", "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n", "\u001b[0;32m----> 1\u001b[0m hdgs \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_heading_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjsonlddoc\u001b[49m\u001b[43m)\u001b[49m\n", "\n", "File \u001b[0;32m~/.local/lib/python3.11/site-packages/toolslm/md_hier.py:48\u001b[0m, in \u001b[0;36mcreate_heading_dict\u001b[0;34m(text)\u001b[0m\n", "\u001b[1;32m     46\u001b[0m title \u001b[38;5;241m=\u001b[39m heading\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n", "\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m level \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m prev_level:\n", "\u001b[0;32m---> 48\u001b[0m     stack\u001b[38;5;241m.\u001b[39mpop()\n", "\u001b[1;32m     49\u001b[0m     prev_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n", "\u001b[1;32m     50\u001b[0m new_dict \u001b[38;5;241m=\u001b[39m {}\n", "\n", "\u001b[0;31mIndexError\u001b[0m: pop from empty list\n"]}, {"ename": "IndexError", "evalue": "pop from empty list", "output_type": "error", "traceback": ["Traceback (most recent call last):\n", "  File \"/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n", "  File \"<ipython-input-1-16746187afee>\", line 1, in <module>\n    hdgs = create_heading_dict(jsonlddoc)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n", "  File \"/app/data/.local/lib/python3.11/site-packages/toolslm/md_hier.py\", line 48, in create_heading_dict\n    stack.pop()\n", "IndexError: pop from empty list\n"]}], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["hdict = markdown_to_dict(jsonlddoc)"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["recsets = hdict['Set of Documentshttpswwww3orgTRjsonld11setofdocuments.11 How to Read this Documenthttpswwww3orgTRjsonld11howtoreadthisdocument.33 Node Identifiershttpswwww3orgTRjsonld11nodeidentifiers']"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["```markdown\n", "\\. Introduction[](https://www.w3.org/TR/json-ld11/#introduction)\n", "-----------------------------------------------------------------\n", "\n", "_This section is non-normative._\n", "\n", "Linked Data \\[[LINKED-DATA](https://www.w3.org/TR/json-ld11/#bib-linked-data \"Linked Data Design Issues\")\\] is a way to create a network of standards-based machine interpretable data across different documents and Web sites. It allows an application to start at one piece of Linked Data, and follow embedded links to other pieces of Linked Data that are hosted on different sites across the Web.\n", "\n", "JSON-LD is a lightweight syntax to serialize Linked Data in JSON \\[[RFC8259](https://www.w3.org/TR/json-ld11/#bib-rfc8259 \"The JavaScript Object Notation (JSON) Data Interchange Format\")\\]. Its design allows existing JSON to be interpreted as Linked Data with minimal changes. JSON-LD is primarily intended to be a way to use Linked Data in Web-based programming environments, to build interoperable Web services, and to store Linked Data in JSON-based storage engines. Since JSON-LD is 100% compatible with JSON, the large number of JSON parsers and libraries available today can be reused. In addition to all the features JSON provides, JSON-LD introduces:\n", "\n", "*   a universal identifier mechanism for [JSON objects](https://tools.ietf.org/html/rfc8259#section-4) via the use of [IRIs](https://tools.ietf.org/html/rfc3987#section-2),\n", "*   a way to disambiguate keys shared among different JSON documents by mapping them to [IRIs](https://tools.ietf.org/html/rfc3987#section-2) via a [context](https://www.w3.org/TR/json-ld11/#dfn-context),\n", "*   a mechanism in which a value in a [JSON object](https://tools.ietf.org/html/rfc8259#section-4) may refer to a [resource](https://www.w3.org/TR/rdf11-concepts/#dfn-resource) on a different site on the Web,\n", "*   the ability to annotate [strings](https://infra.spec.whatwg.org/#javascript-string) with their language,\n", "*   a way to associate datatypes with values such as dates and times,\n", "*   and a facility to express one or more directed graphs, such as a social network, in a single document.\n", "\n", "JSON-LD is designed to be usable directly as JSON, with no knowledge of RDF \\[[RDF11-CONCEPTS](https://www.w3.org/TR/json-ld11/#bib-rdf11-concepts \"RDF 1.1 Concepts and Abstract Syntax\")\\]. It is also designed to be usable as RDF in conjunction with other Linked Data technologies like SPARQL \\[[SPARQL11-OVERVIEW](https://www.w3.org/TR/json-ld11/#bib-sparql11-overview \"SPARQL 1.1 Overview\")\\]. Developers who require any of the facilities listed above or need to serialize an [RDF graph](https://www.w3.org/TR/rdf11-concepts/#dfn-rdf-graph) or [Dataset](https://www.w3.org/TR/rdf11-concepts/#dfn-rdf-dataset) in a JSON-based syntax will find JSON-LD of interest. People intending to use JSON-LD with RDF tools will find it can be used as another RDF syntax, as with \\[[Turtle](https://www.w3.org/TR/json-ld11/#bib-turtle \"RDF 1.1 Turtle\")\\] and \\[[TriG](https://www.w3.org/TR/json-ld11/#bib-trig \"RDF 1.1 TriG\")\\]. Complete details of how JSON-LD relates to RDF are in section [\u00a7 10\\. Relationship to RDF](https://www.w3.org/TR/json-ld11/#relationship-to-rdf).\n", "\n", "The syntax is designed to not disturb already deployed systems running on JSON, but provide a smooth upgrade path from JSON to JSON-LD. Since the shape of such data varies wildly, JSON-LD features mechanisms to reshape documents into a deterministic structure which simplifies their processing.\n", "\n", "### 1.1 How to Read this Document[](https://www.w3.org/TR/json-ld11/#how-to-read-this-document)\n", "\n", "_This section is non-normative._\n", "\n", "This document is a detailed specification for a serialization of Linked Data in JSON. The document is primarily intended for the following audiences:\n", "\n", "*   Software developers who want to encode Linked Data in a variety of programming languages that can use JSON\n", "*   Software developers who want to convert existing JSON to JSON-LD\n", "*   Software developers who want to understand the design decisions and language syntax for JSON-LD\n", "*   Software developers who want to implement processors and APIs for JSON-LD\n", "*   Software developers who want to generate or consume Linked Data, an [RDF graph](https://www.w3.org/TR/rdf11-concepts/#dfn-rdf-graph), or an [RDF Dataset](https://www.w3.org/TR/rdf11-concepts/#dfn-rdf-dataset) in a JSON syntax\n", "\n", "A companion document, the JSON-LD 1.1 Processing Algorithms and API specification \\[[JSON-LD11-API](https://www.w3.org/TR/json-ld11/#bib-json-ld11-api \"JSON-LD 1.1 Processing Algorithms and API\")\\], specifies how to work with JSON-LD at a higher level by providing a standard library interface for common JSON-LD operations.\n", "\n", "To understand the basics in this specification you must first be familiar with [JSON](https://tools.ietf.org/html/rfc8259), which is detailed in \\[[RFC8259](https://www.w3.org/TR/json-ld11/#bib-rfc8259 \"The JavaScript Object Notation (JSON) Data Interchange Format\")\\].\n", "\n", "This document almost exclusively uses the term IRI ([Internationalized Resource Indicator](https://www.w3.org/TR/ld-glossary/#internationalized-resource-identifier)) when discussing hyperlinks. Many Web developers are more familiar with the URL ([Uniform Resource Locator](https://www.w3.org/TR/ld-glossary/#uniform-resource-locator)) terminology. The document also uses, albeit rarely, the URI ([Uniform Resource Indicator](https://www.w3.org/TR/ld-glossary/#uniform-resource-identifier)) terminology. While these terms are often used interchangeably among technical communities, they do have important distinctions from one another and the specification goes to great lengths to try and use the proper terminology at all times.\n", "\n", "This document can highlight changes since the [JSON-LD 1.0](https://www.w3.org/TR/2014/REC-json-ld-20140116/) version. Select to changes.\n", "\n", "### 1.2 Contributing[](https://www.w3.org/TR/json-ld11/#contributing)\n", "\n", "_This section is non-normative._\n", "\n", "There are a number of ways that one may participate in the development of this specification:\n", "\n", "*   Technical discussion typically occurs on the working group mailing list: [public-json-ld-wg@w3.org](https://lists.w3.org/Archives/Public/public-json-ld-wg/)\n", "*   The working group uses [#json-ld](http://irc.w3.org/?channels=json-ld) IRC channel is available for real-time discussion on [irc.w3.org](http://irc.w3.org/).\n", "*   The [#json-ld](https://webchat.freenode.net/?channels=json-ld) IRC channel is also available for real-time discussion on irc.freenode.net.\n", "\n", "### 1.3 Typographical conventions[](https://www.w3.org/TR/json-ld11/#typographical-conventions)\n", "\n", "_This section is non-normative._\n", "\n", "The following typographic conventions are used in this specification:\n", "\n", "`markup`\n", "\n", "Markup (elements, attributes, properties), machine processable values (string, characters, media types), property name, or a file name is in red-orange monospace font.\n", "\n", "variable\n", "\n", "A variable in pseudo-code or in an algorithm description is in italics.\n", "\n", "definition\n", "\n", "A definition of a term, to be used elsewhere in this or other specifications, is in bold and italics.\n", "\n", "[definition reference](https://www.w3.org/TR/json-ld11/#dfn-definition)\n", "\n", "A reference to a definition _in this document_ is underlined and is also an active link to the definition itself.\n", "\n", "[`markup definition reference`](https://www.w3.org/TR/json-ld11/#dfn-definition)\n", "\n", "A references to a definition _in this document_, when the reference itself is also a markup, is underlined, red-orange monospace font, and is also an active link to the definition itself.\n", "\n", "external definition reference\n", "\n", "A reference to a definition _in another document_ is underlined, in italics, and is also an active link to the definition itself.\n", "\n", " ` markup external definition reference`\n", "\n", "A reference to a definition _in another document_, when the reference itself is also a markup, is underlined, in italics red-orange monospace font, and is also an active link to the definition itself.\n", "\n", "hyperlink\n", "\n", "A hyperlink is underlined and in blue.\n", "\n", "\\[reference\\]\n", "\n", "A document reference (normative or informative) is enclosed in square brackets and links to the references section.\n", "\n", "Changes from Recommendation\n", "\n", "Sections or phrases changed from the previous Recommendation may be highlighted using a control in [\u00a7 1.1 How to Read this Document](https://www.w3.org/TR/json-ld11/#how-to-read-this-document).\n", "\n", "Note\n", "\n", "Notes are in light green boxes with a green left border and with a \"Note\" header in green. Notes are always informative.\n", "\n", "[Example 1](https://www.w3.org/TR/json-ld11/#example-1)\n", "\n", "Examples are in light khaki boxes, with khaki left border,\n", "and with a numbered \"Example\" header in khaki.\n", "Examples are always informative. The content of the example is in monospace font and may be syntax colored.\n", "\n", "Examples may have tabbed navigation buttons\n", "to show the results of transforming an example into other representations.\n", "\n", "### 1.4 Terminology[](https://www.w3.org/TR/json-ld11/#terminology)\n", "```"], "attachments": {}}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "Okay, this is the markdown structure that the automatic conversion of the W3C JSON-LD documents is structured into. I'd like to do a bit of document RAG using toolslm since this document is way to large to fit into your context window. I put the markdwon structure returned from https://r.jina.ai into a note. However, when I try to bring this into a dictionary object, it fails. I think that has to do with the conversion from the HTML documentation that the W3C standards use and the Markdown interpretation of those.How do I approach solving this problem?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "Looking at the error you encountered with `create_heading_dict`, I see the issue is related to parsing the headings from the converted HTML to Markdown. The error shows `pop from empty list`, which suggests the heading structure isn't being recognized properly.\n", "\n", "Let's approach this in steps:\n", "\n", "1. First, let's examine what we're working with. The W3C JSON-LD documentation has been converted to markdown, but the conversion might not have preserved the heading structure in a way that `create_heading_dict` can parse.\n", "\n", "2. We could try a different approach with `markdown_to_dict` which seems to have worked partially, but the key names look unusual.\n", "\n", "Let's try to clean up the markdown structure first and then parse it. Would you like to:\n", "\n", "1. Use regex to clean up and normalize the headings in the document?\n", "2. Try an alternative parsing approach using BeautifulSoup on the original HTML?\n", "3. Create a custom parser specifically for this document format?\n", "\n", "What do you think would be the most effective approach for your needs?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "So we want to use the Markdown headings to dynamically load into this notebook the documentation that you need to help with this project.So markdown_to_dict seems to have worked, but the key names are a mess. How do we address that?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "You're right - `markdown_to_dict` worked but produced messy key names. Let's address this by creating a cleaner version that normalizes the keys while preserving the hierarchical structure.\n", "\n", "We could create a function that:\n", "\n", "1. Uses `markdown_to_dict` to get the initial structure\n", "2. Creates a new dictionary with cleaned keys\n", "3. Preserves the hierarchical relationships\n", "\n", "Here's an approach we could take:\n", "\n", "```python\n", "def clean_md_dict(md_content):\n", "    # Get the initial dictionary\n", "    raw_dict = markdown_to_dict(md_content)\n", "    \n", "    # Create a cleaned dictionary\n", "    clean_dict = {}\n", "    \n", "    # Process each key\n", "    for key, value in raw_dict.items():\n", "        # Split the key by periods to get the heading hierarchy\n", "        parts = key.split('.')\n", "        # Clean each part (remove URLs, normalize whitespace)\n", "        clean_parts = [re.sub(r'https?[^\\s]*', '', p).strip() for p in parts]\n", "        # Join back with a more readable separator\n", "        clean_key = '/'.join(clean_parts)\n", "        # Store with the clean key\n", "        clean_dict[clean_key] = value\n", "    \n", "    return clean_dict\n", "```\n", "\n", "Would you like to try this approach, or would you prefer a different strategy for cleaning the keys?"]}, {"cell_type": "code", "metadata": {}, "source": ["def clean_md_dict(md_content):\n", "    # Get the initial dictionary\n", "    raw_dict = markdown_to_dict(md_content)\n", "    \n", "    # Create a cleaned dictionary\n", "    clean_dict = {}\n", "    \n", "    # Process each key\n", "    for key, value in raw_dict.items():\n", "        # Split the key by periods to get the heading hierarchy\n", "        parts = key.split('.')\n", "        # Clean each part (remove URLs, normalize whitespace)\n", "        clean_parts = [re.sub(r'https?[^\\s]*', '', p).strip() for p in parts]\n", "        # Join back with a more readable separator\n", "        clean_key = '/'.join(clean_parts)\n", "        # Store with the clean key\n", "        clean_dict[clean_key] = value\n", "    \n", "    return clean_dict"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "What's next?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "Now let's try using your new `clean_md_dict` function on the JSON-LD document to see if it produces more usable keys:\n", "\n", "```python\n", "# Apply the cleaning function to the document\n", "clean_dict = clean_md_dict(jsonlddoc)\n", "\n", "# Let's see some of the top-level keys to check the structure\n", "list(clean_dict.keys())[:5]  # Show the first 5 keys\n", "```\n", "\n", "After we see the cleaned keys, we can:\n", "\n", "1. Explore the structure to make sure it's organized in a way that makes sense\n", "2. Create a simple function to retrieve content by heading\n", "3. Set up a way to search for specific topics across the document\n", "\n", "Would you like to proceed with this approach?"]}, {"cell_type": "code", "metadata": {}, "source": ["# Apply the cleaning function to the document\n", "clean_dict = clean_md_dict(jsonlddoc)\n", "\n", "# Let's see some of the top-level keys to check the structure\n", "list(clean_dict.keys())[:5]  # Show the first 5 keys"], "outputs": [{"data": {"text/plain": ["['Set of Documents',\n", " 'Set of Documents/11 How to Read this Document',\n", " 'Set of Documents/11 How to Read this Document/12 Contributing',\n", " 'Set of Documents/11 How to Read this Document/13 Typographical conventions',\n", " 'Set of Documents/11 How to Read this Document/14 Terminology']"]}, "metadata": {}, "output_type": "execute_result", "execution_count": null}], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "What do you think of the cleanup?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "The cleanup looks good! The keys are now much more readable and follow a logical hierarchy with the \"/\" separator showing the document structure. The heading paths are clear and concise.\n", "\n", "I notice the structure shows:\n", "- Top level: \"Set of Documents\"\n", "- Second level: \"11 How to Read this Document\" \n", "- Third level: Sections like \"12 Contributing\", \"13 Typographical conventions\", etc.\n", "\n", "There are still some numbering artifacts (like \"11\", \"12\", \"13\") in the section names, but they actually help maintain the original document order, which could be useful.\n", "\n", "Would you like to:\n", "1. Keep this structure as is since it's quite usable now\n", "2. Further refine it to remove the numbering artifacts\n", "3. Create a function to help navigate and retrieve content from this structure?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Table of Contents\n", "-----------------\n", "\n", "1.  [1\\. Introduction](https://www.w3.org/TR/json-ld11/#introduction)\n", "    1.  [1.1 How to Read this Document](https://www.w3.org/TR/json-ld11/#how-to-read-this-document)\n", "    2.  [1.2 Contributing](https://www.w3.org/TR/json-ld11/#contributing)\n", "    3.  [1.3 Typographical conventions](https://www.w3.org/TR/json-ld11/#typographical-conventions)\n", "    4.  [1.4 Terminology](https://www.w3.org/TR/json-ld11/#terminology)\n", "    5.  [1.5 Design Goals and Rationale](https://www.w3.org/TR/json-ld11/#design-goals-and-rationale)\n", "    6.  [1.6 Data Model Overview](https://www.w3.org/TR/json-ld11/#data-model-overview)\n", "    7.  [1.7 Syntax Tokens and Keywords](https://www.w3.org/TR/json-ld11/#syntax-tokens-and-keywords)\n", "2.  [2\\. Conformance](https://www.w3.org/TR/json-ld11/#conformance)\n", "3.  [3\\. Basic Concepts](https://www.w3.org/TR/json-ld11/#basic-concepts)\n", "    1.  [3.1 The Context](https://www.w3.org/TR/json-ld11/#the-context)\n", "    2.  [3.2 IRIs](https://www.w3.org/TR/json-ld11/#iris)\n", "    3.  [3.3 Node Identifiers](https://www.w3.org/TR/json-ld11/#node-identifiers)\n", "    4.  [3.4 Uses of JSON Objects](https://www.w3.org/TR/json-ld11/#uses-of-json-objects)\n", "    5.  [3.5 Specifying the Type](https://www.w3.org/TR/json-ld11/#specifying-the-type)\n", "4.  [4\\. Advanced Concepts](https://www.w3.org/TR/json-ld11/#advanced-concepts)\n", "    1.  [4.1 Advanced Context Usage](https://www.w3.org/TR/json-ld11/#advanced-context-usage)\n", "        1.  [4.1.1 JSON-LD 1.1 Processing Mode](https://www.w3.org/TR/json-ld11/#json-ld-1-1-processing-mode)\n", "        2.  [4.1.2 Default Vocabulary](https://www.w3.org/TR/json-ld11/#default-vocabulary)\n", "        3.  [4.1.3 Base IRI](https://www.w3.org/TR/json-ld11/#base-iri)\n", "        4.  [4.1.4 Using the Document Base for the Default Vocabulary](https://www.w3.org/TR/json-ld11/#document-relative-vocabulary-mapping)\n", "        5.  [4.1.5 Compact IRIs](https://www.w3.org/TR/json-ld11/#compact-iris)\n", "        6.  [4.1.6 Aliasing Keywords](https://www.w3.org/TR/json-ld11/#aliasing-keywords)\n", "        7.  [4.1.7 IRI Expansion within a Context](https://www.w3.org/TR/json-ld11/#iri-expansion-within-a-context)\n", "        8.  [4.1.8 Scoped Contexts](https://www.w3.org/TR/json-ld11/#scoped-contexts)\n", "        9.  [4.1.9 Context Propagation](https://www.w3.org/TR/json-ld11/#context-propagation)\n", "        10.  [4.1.10 Imported Contexts](https://www.w3.org/TR/json-ld11/#imported-contexts)\n", "        11.  [4.1.11 Protected Term Definitions](https://www.w3.org/TR/json-ld11/#protected-term-definitions)\n", "    2.  [4.2 Describing Values](https://www.w3.org/TR/json-ld11/#describing-values)\n", "        1.  [4.2.1 Typed Values](https://www.w3.org/TR/json-ld11/#typed-values)\n", "        2.  [4.2.2 JSON Literals](https://www.w3.org/TR/json-ld11/#json-literals)\n", "        3.  [4.2.3 Type Coercion](https://www.w3.org/TR/json-ld11/#type-coercion)\n", "        4.  [4.2.4 String Internationalization](https://www.w3.org/TR/json-ld11/#string-internationalization)\n", "            1.  [4.2.4.1 Base Direction](https://www.w3.org/TR/json-ld11/#base-direction)\n", "    3.  [4.3 Value Ordering](https://www.w3.org/TR/json-ld11/#sets-and-lists)\n", "        1.  [4.3.1 Lists](https://www.w3.org/TR/json-ld11/#lists)\n", "        2.  [4.3.2 Sets](https://www.w3.org/TR/json-ld11/#sets)\n", "        3.  [4.3.3 Using `@set` with `@type`](https://www.w3.org/TR/json-ld11/#using-set-with-type)\n", "    4.  [4.4 Nested Properties](https://www.w3.org/TR/json-ld11/#nested-properties)\n", "    5.  [4.5 Embedding](https://www.w3.org/TR/json-ld11/#embedding)\n", "        1.  [4.5.1 Identifying Blank Nodes](https://www.w3.org/TR/json-ld11/#identifying-blank-nodes)\n", "    6.  [4.6 Indexed Values](https://www.w3.org/TR/json-ld11/#indexed-values)\n", "        1.  [4.6.1 Data Indexing](https://www.w3.org/TR/json-ld11/#data-indexing)\n", "            1.  [4.6.1.1 Property-based data indexing](https://www.w3.org/TR/json-ld11/#property-based-data-indexing)\n", "        2.  [4.6.2 Language Indexing](https://www.w3.org/TR/json-ld11/#language-indexing)\n", "        3.  [4.6.3 Node Identifier Indexing](https://www.w3.org/TR/json-ld11/#node-identifier-indexing)\n", "        4.  [4.6.4 Node Type Indexing](https://www.w3.org/TR/json-ld11/#node-type-indexing)\n", "    7.  [4.7 Included Nodes](https://www.w3.org/TR/json-ld11/#included-nodes)\n", "    8.  [4.8 Reverse Properties](https://www.w3.org/TR/json-ld11/#reverse-properties)\n", "    9.  [4.9 Named Graphs](https://www.w3.org/TR/json-ld11/#named-graphs)\n", "        1.  [4.9.1 Graph Containers](https://www.w3.org/TR/json-ld11/#graph-containers)\n", "        2.  [4.9.2 Named Graph Data Indexing](https://www.w3.org/TR/json-ld11/#named-graph-data-indexing)\n", "        3.  [4.9.3 Named Graph Indexing](https://www.w3.org/TR/json-ld11/#named-graph-indexing)\n", "    10.  [4.10 Loading Documents](https://www.w3.org/TR/json-ld11/#loading-documents)\n", "5.  [5\\. Forms of JSON-LD](https://www.w3.org/TR/json-ld11/#forms-of-json-ld)\n", "    1.  [5.1 Expanded Document Form](https://www.w3.org/TR/json-ld11/#expanded-document-form)\n", "    2.  [5.2 Compacted Document Form](https://www.w3.org/TR/json-ld11/#compacted-document-form)\n", "        1.  [5.2.1 Shortening IRIs](https://www.w3.org/TR/json-ld11/#shortening-iris)\n", "        2.  [5.2.2 Representing Values as Strings](https://www.w3.org/TR/json-ld11/#representing-values-as-strings)\n", "        3.  [5.2.3 Representing Lists as Arrays](https://www.w3.org/TR/json-ld11/#representing-lists-as-arrays)\n", "        4.  [5.2.4 Reversing Node Relationships](https://www.w3.org/TR/json-ld11/#reversing-node-relationships)\n", "        5.  [5.2.5 Indexing Values](https://www.w3.org/TR/json-ld11/#indexing-values)\n", "        6.  [5.2.6 Normalizing Values as Objects](https://www.w3.org/TR/json-ld11/#normalizing-values-as-objects)\n", "        7.  [5.2.7 Representing Singular Values as Arrays](https://www.w3.org/TR/json-ld11/#representing-singular-values-as-arrays)\n", "        8.  [5.2.8 Term Selection](https://www.w3.org/TR/json-ld11/#term-selection)\n", "    3.  [5.3 Flattened Document Form](https://www.w3.org/TR/json-ld11/#flattened-document-form)\n", "    4.  [5.4 Framed Document Form](https://www.w3.org/TR/json-ld11/#framed-document-form)\n", "6.  [6\\. Modifying Behavior with Link Relationships](https://www.w3.org/TR/json-ld11/#modifying-behavior-with-link-relationships)\n", "    1.  [6.1 Interpreting JSON as JSON-LD](https://www.w3.org/TR/json-ld11/#interpreting-json-as-json-ld)\n", "    2.  [6.2 Alternate Document Location](https://www.w3.org/TR/json-ld11/#alternate-document-location)\n", "7.  [7\\. Embedding JSON-LD in HTML Documents](https://www.w3.org/TR/json-ld11/#embedding-json-ld-in-html-documents)\n", "    1.  [7.1 Inheriting base IRI from HTML's `base` element](https://www.w3.org/TR/json-ld11/#inheriting-base-iri-from-html-s-base-element)\n", "    2.  [7.2 Restrictions for contents of JSON-LD `script` elements](https://www.w3.org/TR/json-ld11/#restrictions-for-contents-of-json-ld-script-elements)\n", "    3.  [7.3 Locating a Specific JSON-LD Script Element](https://www.w3.org/TR/json-ld11/#locating-a-specific-json-ld-script-element)\n", "8.  [8\\. Data Model](https://www.w3.org/TR/json-ld11/#data-model)\n", "9.  [9\\. JSON-LD Grammar](https://www.w3.org/TR/json-ld11/#json-ld-grammar)\n", "    1.  [9.1 Terms](https://www.w3.org/TR/json-ld11/#terms)\n", "    2.  [9.2 Node Objects](https://www.w3.org/TR/json-ld11/#node-objects)\n", "    3.  [9.3 Frame Objects](https://www.w3.org/TR/json-ld11/#frame-objects)\n", "    4.  [9.4 Graph Objects](https://www.w3.org/TR/json-ld11/#graph-objects)\n", "    5.  [9.5 Value Objects](https://www.w3.org/TR/json-ld11/#value-objects)\n", "    6.  [9.6 Value Patterns](https://www.w3.org/TR/json-ld11/#value-patterns)\n", "    7.  [9.7 Lists and Sets](https://www.w3.org/TR/json-ld11/#lists-and-sets)\n", "    8.  [9.8 Language Maps](https://www.w3.org/TR/json-ld11/#language-maps)\n", "    9.  [9.9 Index Maps](https://www.w3.org/TR/json-ld11/#index-maps)\n", "    10.  [9.10 Property-based Index Maps](https://www.w3.org/TR/json-ld11/#property-based-index-maps)\n", "    11.  [9.11 Id Maps](https://www.w3.org/TR/json-ld11/#id-maps)\n", "    12.  [9.12 Type Maps](https://www.w3.org/TR/json-ld11/#type-maps)\n", "    13.  [9.13 Included Blocks](https://www.w3.org/TR/json-ld11/#included-blocks)\n", "    14.  [9.14 Property Nesting](https://www.w3.org/TR/json-ld11/#property-nesting)\n", "    15.  [9.15 Context Definitions](https://www.w3.org/TR/json-ld11/#context-definitions)\n", "        1.  [9.15.1 Expanded term definition](https://www.w3.org/TR/json-ld11/#expanded-term-definition)\n", "    16.  [9.16 Keywords](https://www.w3.org/TR/json-ld11/#keywords)\n", "10.  [10\\. Relationship to RDF](https://www.w3.org/TR/json-ld11/#relationship-to-rdf)\n", "    1.  [10.1 Serializing/Deserializing RDF](https://www.w3.org/TR/json-ld11/#serializing-deserializing-rdf)\n", "    2.  [10.2 The `rdf:JSON` Datatype](https://www.w3.org/TR/json-ld11/#the-rdf-json-datatype)\n", "    3.  [10.3 The `i18n` Namespace](https://www.w3.org/TR/json-ld11/#the-i18n-namespace)\n", "    4.  [10.4 The `rdf:CompoundLiteral` class and the `rdf:language` and `rdf:direction` properties](https://www.w3.org/TR/json-ld11/#the-rdf-compoundliteral-class-and-the-rdf-language-and-rdf-direction-properties)\n", "11.  [11\\. Security Considerations](https://www.w3.org/TR/json-ld11/#security)\n", "12.  [12\\. Privacy Considerations](https://www.w3.org/TR/json-ld11/#privacy)\n", "13.  [13\\. Internationalization Considerations](https://www.w3.org/TR/json-ld11/#internationalization)\n", "14.  [A. Image Descriptions](https://www.w3.org/TR/json-ld11/#image-descriptions)\n", "    1.  [A.1 Linked Data Dataset](https://www.w3.org/TR/json-ld11/#fig-linked-data-graph-descr)\n", "15.  [B. Relationship to Other Linked Data Formats](https://www.w3.org/TR/json-ld11/#relationship-to-other-linked-data-formats)\n", "    1.  [B.1 Turtle](https://www.w3.org/TR/json-ld11/#turtle)\n", "        1.  [B.1.1 Prefix definitions](https://www.w3.org/TR/json-ld11/#prefix-definitions)\n", "        2.  [B.1.2 Embedding](https://www.w3.org/TR/json-ld11/#embedding-0)\n", "        3.  [B.1.3 Conversion of native data types](https://www.w3.org/TR/json-ld11/#conversion-of-native-data-types)\n", "        4.  [B.1.4 Lists](https://www.w3.org/TR/json-ld11/#lists-0)\n", "    2.  [B.2 RDFa](https://www.w3.org/TR/json-ld11/#rdfa)\n", "    3.  [B.3 Microdata](https://www.w3.org/TR/json-ld11/#microdata)\n", "16.  [C. IANA Considerations](https://www.w3.org/TR/json-ld11/#iana-considerations)\n", "    1.  [C.1 Examples](https://www.w3.org/TR/json-ld11/#iana-examples)\n", "17.  [D. Open Issues](https://www.w3.org/TR/json-ld11/#open-issues)\n", "18.  [E. Changes since 1.0 Recommendation of 16 January 2014](https://www.w3.org/TR/json-ld11/#changes-from-10)\n", "19.  [F. Changes since JSON-LD Community Group Final Report](https://www.w3.org/TR/json-ld11/#changes-from-cg)\n", "20.  [G. Changes since Candidate Release of 12 December 2019](https://www.w3.org/TR/json-ld11/#changes-from-cr)\n", "21.  [H. Changes since Proposed Recommendation Release of 7 May 2020](https://www.w3.org/TR/json-ld11/#changes-from-pr)\n", "22.  [I. Acknowledgements](https://www.w3.org/TR/json-ld11/#ack)\n", "23.  [J. References](https://www.w3.org/TR/json-ld11/#references)\n", "    1.  [J.1 Normative references](https://www.w3.org/TR/json-ld11/#normative-references)\n", "    2.  [J.2 Informative references](https://www.w3.org/TR/json-ld11/#informative-references)"], "attachments": {}}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "Okay, so this is the table of contents. I'm interested in section 6 Modifying Link behavior with Link Relationships"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "Let's retrieve the content for section 6 on \"Modifying Behavior with Link Relationships\" from our cleaned dictionary structure. This should give us the information you're looking for:\n", "\n", "```python\n", "# Let's look for section 6 in our cleaned dictionary\n", "section_6_keys = [k for k in clean_dict.keys() if '6' in k and 'Link' in k]\n", "section_6_keys\n", "```\n", "\n", "Once we find the right key, we can retrieve the content:\n", "\n", "```python\n", "# Get the content for the main section 6\n", "if section_6_keys:\n", "    main_section_6_key = section_6_keys[0]\n", "    print(f\"Found section: {main_section_6_key}\")\n", "    \n", "    # Let's get the content\n", "    section_6_content = clean_dict.get(main_section_6_key)\n", "    \n", "    # Show the first part of the content\n", "    print(section_6_content[:500] + \"...\" if len(section_6_content) > 500 else section_6_content)\n", "```\n", "\n", "Would you like me to also look for the subsections (6.1 and 6.2) that were mentioned in the table of contents?"]}, {"cell_type": "code", "metadata": {}, "source": ["# Let's look for section 6 in our cleaned dictionary\n", "section_6_keys = [k for k in clean_dict.keys() if '6' in k and 'Link' in k]\n", "section_6_keys"], "outputs": [{"data": {"text/plain": ["[]"]}, "metadata": {}, "output_type": "execute_result", "execution_count": null}], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "Well, that doesn't seem to have worked."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "You're right, our search approach didn't find any keys containing both \"6\" and \"Link\". Let's try a more flexible approach to find section 6:\n", "\n", "```python\n", "# Let's try to find section 6 with different patterns\n", "section_6_keys = [k for k in clean_dict.keys() if '6' in k or 'Modifying Behavior' in k]\n", "section_6_keys\n", "```\n", "\n", "If that doesn't work, we could try looking at all the keys to understand the structure better:\n", "\n", "```python\n", "# Let's print all keys to see the structure\n", "all_keys = list(clean_dict.keys())\n", "# Print the first 20 keys to get a sense of the naming pattern\n", "all_keys[:20]\n", "```\n", "\n", "This will help us understand how the sections are labeled in our cleaned dictionary, so we can better target the section you're interested in."]}, {"cell_type": "code", "metadata": {}, "source": ["# Let's print all keys to see the structure\n", "all_keys = list(clean_dict.keys())\n", "# Print the first 20 keys to get a sense of the naming pattern\n", "all_keys[:20]"], "outputs": [{"data": {"text/plain": ["['Set of Documents',\n", " 'Set of Documents/11 How to Read this Document',\n", " 'Set of Documents/11 How to Read this Document/12 Contributing',\n", " 'Set of Documents/11 How to Read this Document/13 Typographical conventions',\n", " 'Set of Documents/11 How to Read this Document/14 Terminology',\n", " 'Set of Documents/11 How to Read this Document/14 Terminology/Terms imported from Other Specifications',\n", " 'Set of Documents/11 How to Read this Document/14 Terminology/JSONLD Specific Term Definitions',\n", " 'Set of Documents/11 How to Read this Document/15 Design Goals and Rationale',\n", " 'Set of Documents/11 How to Read this Document/16 Data Model Overview',\n", " 'Set of Documents/11 How to Read this Document/17 Syntax Tokens and Keywords',\n", " 'Set of Documents/11 How to Read this Document/31 The Context',\n", " 'Set of Documents/11 How to Read this Document/32 IRIs',\n", " 'Set of Documents/11 How to Read this Document/33 Node Identifiers',\n", " 'Set of Documents/11 How to Read this Document/34 Uses of JSON Objects',\n", " 'Set of Documents/11 How to Read this Document/35 Specifying the Type',\n", " 'Set of Documents/11 How to Read this Document/41 Advanced Context Usage',\n", " 'Set of Documents/11 How to Read this Document/41 Advanced Context Usage/411 JSONLD 11 Processing Mode',\n", " 'Set of Documents/11 How to Read this Document/41 Advanced Context Usage/412 Default Vocabulary',\n", " 'Set of Documents/11 How to Read this Document/41 Advanced Context Usage/413 Base IRI',\n", " 'Set of Documents/11 How to Read this Document/41 Advanced Context Usage/414 Using the Document Base for the Default Vocabulary']"]}, "metadata": {}, "output_type": "execute_result", "execution_count": null}], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "Okay, we can sort of see the naming pattern now, and how this got messed up.Can you correlate between what the table of contents indicates the heading should look like and what our dictionary shows?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "Looking at the keys in our dictionary compared to the table of contents, I can see what happened:\n", "\n", "1. In the table of contents, we have a clear hierarchical structure with section numbers like:\n", "   - 1. Introduction\n", "   - 6. Modifying Behavior with Link Relationships\n", "   - 6.1 Interpreting JSON as JSON-LD\n", "   - 6.2 Alternate Document Location\n", "\n", "2. But in our dictionary, the structure is different:\n", "   - The top level is \"Set of Documents\"\n", "   - Then we have \"11 How to Read this Document\" (which should be section 1.1)\n", "   - Then we have \"12 Contributing\" (which should be section 1.2)\n", "   - And so on\n", "\n", "The issue is that the numbering is concatenated without periods, so \"1.1\" becomes \"11\", \"1.2\" becomes \"12\", etc. Also, it seems like all content is nested under \"Set of Documents/11 How to Read this Document\" rather than having a proper top-level hierarchy.\n", "\n", "Based on this pattern, section 6 would likely be labeled as \"6\" or possibly as a subsection like \"60\" (if it follows the pattern where 1.1 becomes 11).\n", "\n", "Let's search for keys that might contain section 6 content:\n", "\n", "```python\n", "# Look for keys that might correspond to section 6\n", "section_6_candidates = [k for k in all_keys if ' 6' in k or '/6' in k]\n", "section_6_candidates\n", "```"]}, {"cell_type": "code", "metadata": {}, "source": ["# Look for keys that might correspond to section 6\n", "section_6_candidates = [k for k in all_keys if ' 6' in k or '/6' in k]\n", "section_6_candidates"], "outputs": [{"data": {"text/plain": ["['Set of Documents/11 How to Read this Document/61 Interpreting JSON as JSONLD',\n", " 'Set of Documents/11 How to Read this Document/62 Alternate Document Location']"]}, "metadata": {}, "output_type": "execute_result", "execution_count": null}], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "Okay, this looks correct."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "Great! We've found the subsections of section 6:\n", "\n", "1. \"Set of Documents/11 How to Read this Document/61 Interpreting JSON as JSONLD\"\n", "2. \"Set of Documents/11 How to Read this Document/62 Alternate Document Location\"\n", "\n", "Now let's try to find the main section 6 heading:\n", "\n", "```python\n", "# Let's look for the main section 6 heading\n", "section_6_main = [k for k in all_keys if ' 6 ' in k or '/6 ' in k]\n", "section_6_main\n", "```\n", "\n", "If we don't find it directly, let's get the content from the subsections to see what we have:\n", "\n", "```python\n", "# Get content from first subsection\n", "subsection_61_content = clean_dict['Set of Documents/11 How to Read this Document/61 Interpreting JSON as JSONLD']\n", "print(subsection_61_content[:300] + \"...\" if len(subsection_61_content) > 300 else subsection_61_content)\n", "```"]}, {"cell_type": "code", "metadata": {}, "source": ["# Get content from first subsection\n", "subsection_61_content = clean_dict['Set of Documents/11 How to Read this Document/61 Interpreting JSON as JSONLD']\n", "print(subsection_61_content[:300] + \"...\" if len(subsection_61_content) > 300 else subsection_61_content)"], "outputs": [{"name": "stdout", "output_type": "stream", "text": ["### 6.1 Interpreting JSON as JSON-LD[](https://www.w3.org/TR/json-ld11/#interpreting-json-as-json-ld)\n", "\n", "Ordinary JSON documents can be interpreted as JSON-LD by providing an explicit JSON-LD [context](https://www.w3.org/TR/json-ld11/#dfn-context) document. One way to provide this is by using referenc...\n"]}], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "Ok. Can you tell me what $`subsection_61_content` is about?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "Based on the content we retrieved, `subsection_61_content` is about interpreting regular JSON documents as JSON-LD. Here's a summary of what it covers:\n", "\n", "1. **Converting JSON to JSON-LD**: It explains how ordinary JSON documents can be interpreted as JSON-LD by providing an explicit JSON-LD context document.\n", "\n", "2. **Using HTTP Link Headers**: One method it describes is referencing a JSON-LD context document in an HTTP Link Header, which allows JSON to be machine-readable without requiring developers to change their documents significantly.\n", "\n", "3. **Requirements for processors**: When retrieving a JSON document via HTTP, processors MUST attempt to retrieve any JSON-LD document referenced by a Link Header with specific relation and type values.\n", "\n", "4. **How context is applied**: It details how the `@context` from the referenced document is added to the top-level JSON object of the original document, or to all array items if the document has an array at the top level.\n", "\n", "5. **Programmatic expansion**: It mentions that the JSON-LD 1.1 Processing Algorithms and API specification provides an `expandContext` option for specifying a context to use when expanding JSON documents programmatically.\n", "\n", "This section essentially provides a standardized way to add semantic meaning to regular JSON documents without modifying them directly.\n", "\n", "Would you like me to explain any particular aspect of this in more detail?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "I'm pretty sure that Schema.org uses the Link header method. Could you show me how to get the JSON-LD representation from Schema.org?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "You're correct that Schema.org supports JSON-LD, though typically it's embedded in HTML rather than using the Link header method. Let's explore how to retrieve JSON-LD from Schema.org in a few different ways:\n", "\n", "1. First, let's check if Schema.org provides JSON-LD through Link headers by making a request and examining the headers:\n", "\n", "```python\n", "import httpx\n", "\n", "# Make a request to Schema.org\n", "response = httpx.get('https://schema.org/')\n", "\n", "# Check if there are any JSON-LD related Link headers\n", "link_headers = response.headers.get('Link', '')\n", "print(\"Link headers:\", link_headers)\n", "```\n", "\n", "2. If that doesn't work, we can try to extract embedded JSON-LD from the HTML:\n", "\n", "```python\n", "from bs4 import BeautifulSoup\n", "\n", "# Parse the HTML\n", "soup = BeautifulSoup(response.text, 'html.parser')\n", "\n", "# Look for JSON-LD script tags\n", "jsonld_scripts = soup.find_all('script', type='application/ld+json')\n", "\n", "if jsonld_scripts:\n", "    print(f\"Found {len(jsonld_scripts)} JSON-LD script tags\")\n", "    # Print the first one as an example\n", "    print(jsonld_scripts[0].string[:200] + \"...\" if len(jsonld_scripts[0].string) > 200 else jsonld_scripts[0].string)\n", "else:\n", "    print(\"No embedded JSON-LD found\")\n", "```\n", "\n", "Would you like to try one of these approaches?"]}, {"cell_type": "code", "metadata": {}, "source": ["import httpx\n", "\n", "# Make a request to Schema.org\n", "response = httpx.get('https://schema.org/')\n", "\n", "# Check if there are any JSON-LD related Link headers\n", "link_headers = response.headers.get('Link', '')\n", "print(\"Link headers:\", link_headers)"], "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Link headers: </docs/jsonldcontext.jsonld>; rel=\"alternate\"; type=\"application/ld+json\"\n"]}], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["from bs4 import BeautifulSoup\n", "\n", "# Parse the HTML\n", "soup = BeautifulSoup(response.text, 'html.parser')\n", "\n", "# Look for JSON-LD script tags\n", "jsonld_scripts = soup.find_all('script', type='application/ld+json')\n", "\n", "if jsonld_scripts:\n", "    print(f\"Found {len(jsonld_scripts)} JSON-LD script tags\")\n", "    # Print the first one as an example\n", "    print(jsonld_scripts[0].string[:200] + \"...\" if len(jsonld_scripts[0].string) > 200 else jsonld_scripts[0].string)\n", "else:\n", "    print(\"No embedded JSON-LD found\")"], "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Found 1 JSON-LD script tags\n", "\n", "    {\n", "        \"@context\": \"https://schema.org\",\n", "        \"@type\": \"WebSite\",\n", "        \"url\": \"https://schema.org\",\n", "        \"name\": \"Schema.org\",\n", "        \"potentialAction\": {\n", "          \"@type\": \"SearchA...\n"]}], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "Did this work the way that we think it should?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "Yes, this worked perfectly! We've discovered two important things:\n", "\n", "1. Schema.org does indeed use the Link header method as described in the JSON-LD specification. The response included a Link header pointing to a JSON-LD context document:\n", "   ```\n", "   Link headers: </docs/jsonldcontext.jsonld>; rel=\"alternate\"; type=\"application/ld+json\"\n", "   ```\n", "   This follows the pattern described in section 6.1, though it uses `rel=\"alternate\"` rather than `rel=\"http://www.w3.org/ns/json-ld#context\"`.\n", "\n", "2. Schema.org also embeds JSON-LD directly in the HTML using script tags with `type=\"application/ld+json\"`. We found one such script tag containing a JSON-LD representation of the website itself.\n", "\n", "This demonstrates both approaches to providing JSON-LD: the Link header method (for machine clients that might want to interpret regular JSON as JSON-LD) and the embedded method (for web crawlers and other tools that parse the HTML).\n", "\n", "Would you like to retrieve and examine the actual JSON-LD context document referenced in the Link header?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "Can you summarize Section 6.1: \"Interpreting JSON as JSON-LD\"?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "## Summary of Section 6.1: \"Interpreting JSON as JSON-LD\"\n", "\n", "Section 6.1 describes how regular JSON documents can be interpreted as JSON-LD without modifying the original JSON content. Here are the key points:\n", "\n", "1. **Purpose**: Enables ordinary JSON to be interpreted as JSON-LD by providing an external context document, allowing machine-readability without requiring developers to change their existing JSON documents.\n", "\n", "2. **Method**: Uses HTTP Link Headers to reference a JSON-LD context document. This provides a way to add semantic meaning to JSON while maintaining backward compatibility with existing clients that expect regular JSON.\n", "\n", "3. **Technical Requirements**:\n", "   - Processors must look for Link Headers with `rel=\"http://www.w3.org/ns/json-ld#context\"` and `type=\"application/ld+json\"`\n", "   - The referenced document must have a top-level JSON object\n", "   - Only the `@context` entry from the referenced document is used; all other information is discarded\n", "   - Only one such Link Header is allowed per response\n", "\n", "4. **Application**:\n", "   - The external context is added to the top-level JSON object of the original document\n", "   - If the original document has an array at the top level, the context is added to all array items that are objects\n", "\n", "5. **Alternative Methods**: The specification mentions that other mechanisms for providing a JSON-LD Context may be described for non-HTTP URI schemes.\n", "\n", "6. **Programmatic Usage**: The JSON-LD API specification includes an `expandContext` option for programmatically applying a context when expanding JSON documents.\n", "\n", "This approach essentially provides an \"upgrade path\" for existing JSON infrastructure to become semantically enabled without breaking changes."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "What about example 142, referencing a JSON-LD context from a JSON document via an HTTP Link header?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "It seems the section mentions an example (Example 142) that demonstrates the use of an external context with an ordinary JSON document via HTTP Link header, but I don't see the actual example in the content we extracted.\n", "\n", "Let's try to find this example in our data. We should look for references to \"Example 142\" or search for examples within section 6.1:\n", "\n", "```python\n", "# Search for Example 142 in our content\n", "if 'Example 142' in subsection_61_content:\n", "    print(\"Found Example 142 reference\")\n", "    \n", "    # Try to extract the example\n", "    import re\n", "    example_match = re.search(r'Example 142.*?```.*?```', subsection_61_content, re.DOTALL)\n", "    if example_match:\n", "        print(example_match.group(0))\n", "    else:\n", "        print(\"Example reference found but couldn't extract the code block\")\n", "else:\n", "    print(\"Example 142 not found in the content\")\n", "```\n", "\n", "Would you like me to help you find this example elsewhere in the document, or would you prefer I explain how this would work conceptually?"]}, {"cell_type": "code", "metadata": {}, "source": ["# Search for Example 142 in our content\n", "if 'Example 142' in subsection_61_content:\n", "    print(\"Found Example 142 reference\")\n", "    \n", "    # Try to extract the example\n", "    import re\n", "    example_match = re.search(r'Example 142.*?```.*?```', subsection_61_content, re.DOTALL)\n", "    if example_match:\n", "        print(example_match.group(0))\n", "    else:\n", "        print(\"Example reference found but couldn't extract the code block\")\n", "else:\n", "    print(\"Example 142 not found in the content\")"], "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Example 142 not found in the content\n"]}], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["```\n", "Example 142: Referencing a JSON-LD context from a JSON document via an HTTP Link Header\n", "GET /ordinary-json-document.json HTTP/1.1\n", "Host: example.com\n", "Accept: application/ld+json,application/json,*/*;q=0.1\n", "\n", "====================================\n", "\n", "HTTP/1.1 200 OK\n", "...\n", "Content-Type: application/json\n", "Link: <https://json-ld.org/contexts/person.jsonld>; rel=\"http://www.w3.org/ns/json-ld#context\"; type=\"application/ld+json\"\n", "\n", "{\n", "  \"name\": \"Markus Lanthaler\",\n", "  \"homepage\": \"http://www.markus-lanthaler.com/\",\n", "  \"image\": \"http://twitter.com/account/profile_image/markuslanthaler\"\n", "}\n", "```"], "attachments": {}}, {"cell_type": "markdown", "metadata": {}, "source": ["To retrieve JSON-LD data using a \"schema.org\" link rel header, you need to look for an HTTP response header with the \"Link\" field, where the \"rel\" attribute is set to \"alternate\" and the \"type\" attribute is usually \"application/ld+json\"; the URL provided in the header will point to the location of your JSON-LD data, which is typically a context file defining the schema used for the structured data. \n", "Key points about retrieving JSON-LD with a \"schema.org\" link header:\n", "Header format:\n", "The \"Link\" header will look something like this: Link: <https://schema.org/docs/jsonldcontext.json>; rel=\"alternate\"; type=\"application/ld+json\". \n", "\"rel\" attribute:\n", "\"alternate\" indicates that the linked resource is an alternative representation of the current page, in this case, the JSON-LD context file. \n", "\"type\" attribute:\n", "\"application/ld+json\" specifies that the linked resource is a JSON-LD document. \n", "How to use it:\n", "1. Fetch the webpage:\n", "When you request a webpage, check the HTTP response headers for a \"Link\" header with the specified \"rel\" and \"type\" attributes. \n", "2. Extract the URL:\n", "If the header is present, extract the URL provided within the angle brackets. \n", "3. Fetch the JSON-LD data:\n", "Make a separate request to the extracted URL to retrieve the JSON-LD context file. \n", "Important considerations:\n", "Not always present:\n", "Not all websites will use a \"schema.org\" link header to provide their JSON-LD context, so you should check for its existence before relying on it. \n", "Parsing the JSON-LD:\n", "Once you have the JSON-LD data, you need to parse it using a JSON parser that understands the JSON-LD specification to properly interpret the structured data."], "attachments": {}}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "Okay, so I think the way that Schema.org works is that if we retrieve a term from Schema.org, say Schema.org/Person, then in the HTTP response header, we should see an alternate for JSON-LD that we can grab. We should then be able to make another request to grab the JSON-LD and load it into a JSON object.How do we test our hypothesis?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "Let's test your hypothesis by making a request to Schema.org/Person and checking if we get a Link header pointing to a JSON-LD representation. Then we'll follow that link to retrieve the JSON-LD data.\n", "\n", "Here's how we can do it:\n", "\n", "```python\n", "import httpx\n", "import json\n", "\n", "# Step 1: Make a request to Schema.org/Person\n", "response = httpx.get('https://schema.org/Person')\n", "\n", "# Step 2: Check for Link header\n", "link_header = response.headers.get('Link', '')\n", "print(f\"Link header: {link_header}\")\n", "\n", "# Step 3: Parse the Link header to extract the JSON-LD URL\n", "import re\n", "jsonld_url_match = re.search(r'<([^>]+)>;\\s*rel=\"alternate\";\\s*type=\"application/ld\\+json\"', link_header)\n", "\n", "if jsonld_url_match:\n", "    # Extract the URL\n", "    jsonld_url = jsonld_url_match.group(1)\n", "    print(f\"JSON-LD URL: {jsonld_url}\")\n", "    \n", "    # Step 4: Make the URL absolute if it's relative\n", "    from urllib.parse import urljoin\n", "    if jsonld_url.startswith('/'):\n", "        jsonld_url = urljoin('https://schema.org', jsonld_url)\n", "        print(f\"Absolute JSON-LD URL: {jsonld_url}\")\n", "    \n", "    # Step 5: Fetch the JSON-LD data\n", "    jsonld_response = httpx.get(jsonld_url)\n", "    if jsonld_response.status_code == 200:\n", "        # Step 6: Parse the JSON-LD\n", "        try:\n", "            jsonld_data = jsonld_response.json()\n", "            print(f\"Successfully retrieved JSON-LD data:\")\n", "            print(json.dumps(jsonld_data, indent=2)[:500] + \"...\" if len(json.dumps(jsonld_data, indent=2)) > 500 else json.dumps(jsonld_data, indent=2))\n", "        except json.JSONDecodeError:\n", "            print(\"Failed to parse JSON-LD data\")\n", "            print(jsonld_response.text[:500])\n", "    else:\n", "        print(f\"Failed to retrieve JSON-LD data: {jsonld_response.status_code}\")\n", "else:\n", "    print(\"No JSON-LD Link header found\")\n", "```\n", "\n", "This code will:\n", "1. Request the Schema.org/Person page\n", "2. Check for a Link header\n", "3. Extract the JSON-LD URL from the header\n", "4. Make the URL absolute if needed\n", "5. Fetch the JSON-LD data\n", "6. Parse and display the JSON-LD\n", "\n", "Would you like to run this code to test your hypothesis?"]}, {"cell_type": "code", "metadata": {}, "source": ["import httpx\n", "import json\n", "\n", "# Step 1: Make a request to Schema.org/Person\n", "response = httpx.get('https://schema.org/Person')\n", "\n", "# Step 2: Check for Link header\n", "link_header = response.headers.get('Link', '')\n", "print(f\"Link header: {link_header}\")\n", "\n", "# Step 3: Parse the Link header to extract the JSON-LD URL\n", "import re\n", "jsonld_url_match = re.search(r'<([^>]+)>;\\s*rel=\"alternate\";\\s*type=\"application/ld\\+json\"', link_header)\n", "\n", "if jsonld_url_match:\n", "    # Extract the URL\n", "    jsonld_url = jsonld_url_match.group(1)\n", "    print(f\"JSON-LD URL: {jsonld_url}\")\n", "    \n", "    # Step 4: Make the URL absolute if it's relative\n", "    from urllib.parse import urljoin\n", "    if jsonld_url.startswith('/'):\n", "        jsonld_url = urljoin('https://schema.org', jsonld_url)\n", "        print(f\"Absolute JSON-LD URL: {jsonld_url}\")\n", "    \n", "    # Step 5: Fetch the JSON-LD data\n", "    jsonld_response = httpx.get(jsonld_url)\n", "    if jsonld_response.status_code == 200:\n", "        # Step 6: Parse the JSON-LD\n", "        try:\n", "            jsonld_data = jsonld_response.json()\n", "            print(f\"Successfully retrieved JSON-LD data:\")\n", "            print(json.dumps(jsonld_data, indent=2)[:500] + \"...\" if len(json.dumps(jsonld_data, indent=2)) > 500 else json.dumps(jsonld_data, indent=2))\n", "        except json.JSONDecodeError:\n", "            print(\"Failed to parse JSON-LD data\")\n", "            print(jsonld_response.text[:500])\n", "    else:\n", "        print(f\"Failed to retrieve JSON-LD data: {jsonld_response.status_code}\")\n", "else:\n", "    print(\"No JSON-LD Link header found\")"], "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Link header: \n", "No JSON-LD Link header found\n"]}], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "Could we look at the link headers? I don't think this is quite right."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "You're right, we didn't find a Link header in the response from Schema.org/Person. Let's take a closer look at all the headers to see what we're actually getting:\n", "\n", "```python\n", "# Examine all headers from the Schema.org/Person response\n", "response = httpx.get('https://schema.org/Person')\n", "print(\"All response headers:\")\n", "for name, value in response.headers.items():\n", "    print(f\"{name}: {value}\")\n", "```\n", "\n", "Let's also check if there's embedded JSON-LD in the HTML of the Person page:\n", "\n", "```python\n", "# Check for embedded JSON-LD in the Schema.org/Person page\n", "from bs4 import BeautifulSoup\n", "\n", "soup = BeautifulSoup(response.text, 'html.parser')\n", "jsonld_scripts = soup.find_all('script', type='application/ld+json')\n", "\n", "if jsonld_scripts:\n", "    print(f\"\\nFound {len(jsonld_scripts)} embedded JSON-LD scripts\")\n", "    print(\"First JSON-LD content:\")\n", "    print(jsonld_scripts[0].string[:300] + \"...\" if len(jsonld_scripts[0].string) > 300 else jsonld_scripts[0].string)\n", "else:\n", "    print(\"\\nNo embedded JSON-LD found\")\n", "```\n", "\n", "This will help us understand how Schema.org is actually providing its JSON-LD data."]}, {"cell_type": "code", "metadata": {}, "source": ["# Examine all headers from the Schema.org/Person response\n", "response = httpx.get('https://schema.org/Person')\n", "print(\"All response headers:\")\n", "for name, value in response.headers.items():\n", "    print(f\"{name}: {value}\")"], "outputs": [{"name": "stdout", "output_type": "stream", "text": ["All response headers:\n", "access-control-allow-credentials: true\n", "access-control-allow-headers: Accept\n", "access-control-allow-origin: *\n", "access-control-allow-methods: GET\n", "x-cloud-trace-context: a264432f920951f732b4eac3a4c9da91\n", "content-encoding: gzip\n", "server: Google Frontend\n", "content-length: 37409\n", "date: Wed, 05 Mar 2025 18:27:16 GMT\n", "expires: Wed, 05 Mar 2025 18:37:16 GMT\n", "cache-control: public, max-age=600\n", "etag: \"7VhAyw\"\n", "content-type: text/html\n", "age: 75\n", "alt-svc: h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000\n"]}], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["Some of your questions pertain to the schema.org setup, and what they are expected to return when resolving identifiers such as Person. They do have a Turtle version of their schema at https://github.com/schemaorg/schemaorg/blob/main/data/schema.ttl, but it is not returned as part of any content-negotiation.\n", "\n", "The rel=\"alternate\" returned from the main schema.org page is to resolve a request for a JSON-LD context, not for an alternate representation of some specific vocabulary item. As with many such sites, schema.org runs as a static site, for handling an Accept header for content negotiation is difficult, so they use the rel=alternate mechanism which is easier to configure.\n", "\n", "When other software tries to extract JSON-LD from an HTML page and that JSON contains \"@context\": \"https://schema.org\" (or similar) a JSON-LD processor will attempt to retrieve that context (although it really should be cached) and the rel=alternate is a way for a conforming JSON-LD processor to redirect to the actual location of the context. This allows the embedded JSON-LD to be manipulated using standard algorithms,, including transforming it to RDF, which may then be serialized using Turtle, for example. AFAIK, schema.org does not, itself, depend on this for retrieving a context.\n", "\n", "```sh\n", "$ curl -I -L http://schema.org/\n", "\n", "...\n", "link: </docs/jsonldcontext.jsonld>; rel=\"alternate\"; type=\"application/ld+json\"\n", "```"], "attachments": {}}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "Okay, so I think the only way to get an individual vocabulary object is from parsing the application/ld+json tag inside of the HTML.Is this correct from the note that I just grabbed from Schema.org's issues?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "Yes, that's correct based on the note you shared from Schema.org's issues. Let me summarize what we've learned:\n", "\n", "1. Schema.org doesn't provide JSON-LD representations of individual vocabulary terms (like Person) through Link headers or content negotiation.\n", "\n", "2. The `rel=\"alternate\"` Link header we found earlier on the main Schema.org page is specifically for the JSON-LD context document, not for alternate representations of specific vocabulary items.\n", "\n", "3. Schema.org operates as a static site, which makes proper content negotiation difficult, so they don't provide different representations based on Accept headers.\n", "\n", "4. To get the JSON-LD representation of an individual vocabulary item like Person, you need to parse the embedded JSON-LD from the HTML page using the `<script type=\"application/ld+json\">` tags.\n", "\n", "5. When software encounters `\"@context\": \"https://schema.org\"` in JSON-LD, the processor may attempt to retrieve that context, and the `rel=\"alternate\"` mechanism helps redirect to the actual location of the context file.\n", "\n", "Let's check for embedded JSON-LD in the Person page to confirm this approach:\n", "\n", "```python\n", "# Check for embedded JSON-LD in the Schema.org/Person page\n", "from bs4 import BeautifulSoup\n", "\n", "response = httpx.get('https://schema.org/Person')\n", "soup = BeautifulSoup(response.text, 'html.parser')\n", "jsonld_scripts = soup.find_all('script', type='application/ld+json')\n", "\n", "if jsonld_scripts:\n", "    print(f\"Found {len(jsonld_scripts)} embedded JSON-LD scripts\")\n", "    print(\"First JSON-LD content:\")\n", "    print(jsonld_scripts[0].string[:300] + \"...\" if len(jsonld_scripts[0].string) > 300 else jsonld_scripts[0].string)\n", "else:\n", "    print(\"No embedded JSON-LD found\")\n", "```"]}, {"cell_type": "code", "metadata": {}, "source": ["# Check for embedded JSON-LD in the Schema.org/Person page\n", "from bs4 import BeautifulSoup\n", "\n", "response = httpx.get('https://schema.org/Person')\n", "soup = BeautifulSoup(response.text, 'html.parser')\n", "jsonld_scripts = soup.find_all('script', type='application/ld+json')\n", "\n", "if jsonld_scripts:\n", "    print(f\"Found {len(jsonld_scripts)} embedded JSON-LD scripts\")\n", "    print(\"First JSON-LD content:\")\n", "    print(jsonld_scripts[0].string[:300] + \"...\" if len(jsonld_scripts[0].string) > 300 else jsonld_scripts[0].string)\n", "else:\n", "    print(\"No embedded JSON-LD found\")"], "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Found 1 embedded JSON-LD scripts\n", "First JSON-LD content:\n", "\n", "{\n", "  \"@context\": {\n", "    \"brick\": \"https://brickschema.org/schema/Brick#\",\n", "    \"csvw\": \"http://www.w3.org/ns/csvw#\",\n", "    \"dc\": \"http://purl.org/dc/elements/1.1/\",\n", "    \"dcam\": \"http://purl.org/dc/dcam/\",\n", "    \"dcat\": \"http://www.w3.org/ns/dcat#\",\n", "    \"dcmitype\": \"http://purl.org/dc/dcmitype/\",\n", "    \"dcte...\n"]}], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "Okay, can we have a look at the actual link rel object?I.e., what does the schema.org context look like if you follow it from the @context?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "Let's examine the JSON-LD context document that Schema.org provides. We'll:\n", "\n", "1. Retrieve the main Schema.org page\n", "2. Extract the Link header with the context URL\n", "3. Follow that URL to see what the context document contains\n", "\n", "```python\n", "import httpx\n", "import json\n", "import re\n", "from urllib.parse import urljoin\n", "\n", "# Step 1: Get the main Schema.org page\n", "response = httpx.get('https://schema.org/')\n", "\n", "# Step 2: Extract the context URL from the Link header\n", "link_header = response.headers.get('Link', '')\n", "print(f\"Link header: {link_header}\")\n", "\n", "# Parse the Link header\n", "jsonld_url_match = re.search(r'<([^>]+)>;\\s*rel=\"alternate\";\\s*type=\"application/ld\\+json\"', link_header)\n", "\n", "if jsonld_url_match:\n", "    # Extract the URL\n", "    jsonld_url = jsonld_url_match.group(1)\n", "    \n", "    # Make the URL absolute if it's relative\n", "    if jsonld_url.startswith('/'):\n", "        jsonld_url = urljoin('https://schema.org', jsonld_url)\n", "    \n", "    print(f\"JSON-LD context URL: {jsonld_url}\")\n", "    \n", "    # Step 3: Fetch the JSON-LD context document\n", "    jsonld_response = httpx.get(jsonld_url)\n", "    if jsonld_response.status_code == 200:\n", "        try:\n", "            # Parse and display the context\n", "            jsonld_context = jsonld_response.json()\n", "            print(\"\\nJSON-LD context document:\")\n", "            # Print the first part to get an idea of its structure\n", "            print(json.dumps(jsonld_context, indent=2)[:1000] + \"...\" if len(json.dumps(jsonld_context, indent=2)) > 1000 else json.dumps(jsonld_context, indent=2))\n", "        except json.JSONDecodeError:\n", "            print(\"Failed to parse JSON-LD context\")\n", "            print(jsonld_response.text[:500])\n", "    else:\n", "        print(f\"Failed to retrieve JSON-LD context: {jsonld_response.status_code}\")\n", "else:\n", "    print(\"No JSON-LD context URL found in Link header\")\n", "```\n", "\n", "This will show us what the Schema.org JSON-LD context actually contains, which is essential for understanding how Schema.org vocabulary terms are defined and linked."]}, {"cell_type": "code", "metadata": {}, "source": ["import httpx\n", "import json\n", "import re\n", "from urllib.parse import urljoin\n", "\n", "# Step 1: Get the main Schema.org page\n", "response = httpx.get('https://schema.org/')\n", "\n", "# Step 2: Extract the context URL from the Link header\n", "link_header = response.headers.get('Link', '')\n", "print(f\"Link header: {link_header}\")\n", "\n", "# Parse the Link header\n", "jsonld_url_match = re.search(r'<([^>]+)>;\\s*rel=\"alternate\";\\s*type=\"application/ld\\+json\"', link_header)\n", "\n", "if jsonld_url_match:\n", "    # Extract the URL\n", "    jsonld_url = jsonld_url_match.group(1)\n", "    \n", "    # Make the URL absolute if it's relative\n", "    if jsonld_url.startswith('/'):\n", "        jsonld_url = urljoin('https://schema.org', jsonld_url)\n", "    \n", "    print(f\"JSON-LD context URL: {jsonld_url}\")\n", "    \n", "    # Step 3: Fetch the JSON-LD context document\n", "    jsonld_response = httpx.get(jsonld_url)\n", "    if jsonld_response.status_code == 200:\n", "        try:\n", "            # Parse and display the context\n", "            jsonld_context = jsonld_response.json()\n", "            print(\"\\nJSON-LD context document:\")\n", "            # Print the first part to get an idea of its structure\n", "            print(json.dumps(jsonld_context, indent=2)[:1000] + \"...\" if len(json.dumps(jsonld_context, indent=2)) > 1000 else json.dumps(jsonld_context, indent=2))\n", "        except json.JSONDecodeError:\n", "            print(\"Failed to parse JSON-LD context\")\n", "            print(jsonld_response.text[:500])\n", "    else:\n", "        print(f\"Failed to retrieve JSON-LD context: {jsonld_response.status_code}\")\n", "else:\n", "    print(\"No JSON-LD context URL found in Link header\")"], "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Link header: </docs/jsonldcontext.jsonld>; rel=\"alternate\"; type=\"application/ld+json\"\n", "JSON-LD context URL: https://schema.org/docs/jsonldcontext.jsonld\n", "\n", "JSON-LD context document:\n", "{\n", "  \"@context\": {\n", "    \"type\": \"@type\",\n", "    \"id\": \"@id\",\n", "    \"HTML\": {\n", "      \"@id\": \"rdf:HTML\"\n", "    },\n", "    \"@vocab\": \"http://schema.org/\",\n", "    \"brick\": \"https://brickschema.org/schema/Brick#\",\n", "    \"csvw\": \"http://www.w3.org/ns/csvw#\",\n", "    \"dc\": \"http://purl.org/dc/elements/1.1/\",\n", "    \"dcat\": \"http://www.w3.org/ns/dcat#\",\n", "    \"dcmitype\": \"http://purl.org/dc/dcmitype/\",\n", "    \"dcterms\": \"http://purl.org/dc/terms/\",\n", "    \"dcam\": \"http://purl.org/dc/dcam/\",\n", "    \"doap\": \"http://usefulinc.com/ns/doap#\",\n", "    \"foaf\": \"http://xmlns.com/foaf/0.1/\",\n", "    \"odrl\": \"http://www.w3.org/ns/odrl/2/\",\n", "    \"org\": \"http://www.w3.org/ns/org#\",\n", "    \"owl\": \"http://www.w3.org/2002/07/owl#\",\n", "    \"prof\": \"http://www.w3.org/ns/dx/prof/\",\n", "    \"prov\": \"http://www.w3.org/ns/prov#\",\n", "    \"qb\": \"http://purl.org/linked-data/cube#\",\n", "    \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\",\n", "    \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\",\n", "    \"schema\": \"http://schema.org/\",\n", "    \"sh\": \"http://www.w3.org/ns/shacl#\",\n", "    \"skos...\n"]}], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "What do we think of this?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "This is quite interesting! Let's analyze what we've found:\n", "\n", "The JSON-LD context document from Schema.org serves several important purposes:\n", "\n", "1. **Namespace Definitions**: It defines many standard namespaces used in the semantic web (rdf, rdfs, owl, foaf, etc.), which allows Schema.org terms to interoperate with other vocabularies.\n", "\n", "2. **Base Vocabulary**: It sets `\"@vocab\": \"http://schema.org/\"`, which means any terms without an explicit prefix will be interpreted as Schema.org terms.\n", "\n", "3. **ID and Type Aliases**: It maps the JSON-LD keywords `@id` and `@type` to the more JSON-friendly names \"id\" and \"type\".\n", "\n", "4. **Cross-Vocabulary Integration**: By including references to other vocabularies like FOAF, Dublin Core, etc., it enables Schema.org to be used alongside these other standards.\n", "\n", "This context document is exactly what's referenced in the Link header with `rel=\"alternate\"` and `type=\"application/ld+json\"`. When a JSON-LD processor encounters a document that uses `\"@context\": \"https://schema.org\"`, it should retrieve this context document to properly interpret the terms.\n", "\n", "This follows the pattern described in section 6.1 of the JSON-LD specification, though Schema.org uses `rel=\"alternate\"` rather than `rel=\"http://www.w3.org/ns/json-ld#context\"`.\n", "\n", "The context doesn't contain the actual definitions of Schema.org terms (like Person) - it just provides the mapping information to interpret those terms in a JSON-LD document. To get the full definition of a term like Person, you'd need to parse the embedded JSON-LD from the HTML page for that term, as we confirmed earlier.\n", "\n", "Does this match your understanding of how Schema.org is using JSON-LD?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "Alright, so this is sort of a mess. If we want to actually be able to do the linked data thing, to essentially follow our nodes and retrieve information, because we have things like this in terms of JSON-LD, but we also have traditional linked data approaches that use content negotiation. w3id.org typically do content negotiation to do redirects to the right representation.If we're building a RAG system for a large language model to navigate JSON-LD, how should we approach that? These will be need to be able to be used in agentic workflows as tools. Let's not write any code yet, but think this through and gameplan."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "# Building a RAG System for JSON-LD Navigation\n", "\n", "You're right that the current landscape is a bit of a mess - we have different approaches to linked data including JSON-LD with contexts, traditional content negotiation, and services like w3id.org that use redirects. Let's think through a comprehensive approach for a RAG system that can navigate this ecosystem effectively.\n", "\n", "## The Challenge\n", "\n", "1. **Inconsistent Access Patterns**: As we've seen, different sources provide JSON-LD in different ways (embedded in HTML, via Link headers, through content negotiation)\n", "\n", "2. **Context Resolution**: JSON-LD relies on contexts that may be referenced by URL but need to be retrieved and processed\n", "\n", "3. **Cross-Vocabulary Navigation**: Following links often means crossing between different vocabularies and services\n", "\n", "4. **Agentic Requirements**: Tools for LLM agents need to be robust, fast, and provide consistent interfaces\n", "\n", "## Gameplan for a JSON-LD RAG System\n", "\n", "### 1. Multi-Strategy Retrieval Layer\n", "\n", "Create a retrieval layer that tries multiple strategies in sequence:\n", "\n", "- Try content negotiation first (with Accept: application/ld+json header)\n", "- Look for Link headers with rel=\"alternate\" or rel=\"http://www.w3.org/ns/json-ld#context\"\n", "- Fall back to HTML scraping for embedded JSON-LD\n", "- Handle redirects (especially from services like w3id.org)\n", "\n", "This layer should abstract away the messy details of how the data is actually retrieved.\n", "\n", "### 2. Context Management\n", "\n", "- Implement caching for contexts to avoid repeated network requests\n", "- Preload common contexts (Schema.org, Dublin Core, etc.)\n", "- Handle context processing and expansion internally\n", "\n", "### 3. Unified Graph Interface\n", "\n", "- Represent all retrieved data as a consistent graph structure\n", "- Allow navigation via property names regardless of underlying serialization\n", "- Implement \"follow\" functionality that handles the retrieval of linked resources\n", "\n", "### 4. Semantic Understanding Layer\n", "\n", "- Index not just the raw JSON-LD but also its semantic meaning\n", "- Store information about classes, properties, and their relationships\n", "- Enable queries like \"find all properties of a Person\" or \"what's the relationship between Person and Organization\"\n", "\n", "### 5. Agent-Friendly Tool Design\n", "\n", "- Create tools with clear, consistent interfaces\n", "- Implement rate limiting and error handling\n", "- Provide high-level functions like:\n", "  - `get_entity(uri)`: Retrieve a complete entity\n", "  - `follow_link(entity, property)`: Navigate relationships\n", "  - `search_vocabulary(term)`: Find definitions across vocabularies\n", "  - `expand_prefixed_uri(prefixed_uri)`: Handle namespace prefixes\n", "\n", "### 6. Documentation Generation\n", "\n", "- Extract human-readable documentation from the semantic data\n", "- Generate examples of usage for different entities\n", "- Create a knowledge base that the LLM can reference\n", "\n", "## Implementation Considerations\n", "\n", "1. **Caching Strategy**: Aggressive caching of both data and contexts to reduce latency\n", "\n", "2. **Error Handling**: Graceful degradation when certain retrieval methods fail\n", "\n", "3. **Schema Registry**: Maintain a local registry of common schemas to reduce dependency on external services\n", "\n", "4. **Hybrid Approach**: Combine live retrieval with pre-indexed data for popular vocabularies\n", "\n", "5. **Vectorization Strategy**: Consider how to vectorize semantic data for similarity search\n", "\n", "Would you like to focus on any particular aspect of this plan to develop further?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "Okay, so in standard tool use for an LLM as a web browser, let's assume that's the primary tool mode that an LLM interacts with the world. Does this seem reasonable? If so, then that means that the LLM, as it's interpreting the text on the webpage, also needs to look for the embedded tags to give it hints that it can find other information, correct? When it retrieves that other information, such as a JSON-LD object, there may be ontologies contained in that object that it has to follow. These may require content negotiation depending upon the vocabulary, or they may be directly downloadable in the case of W3C."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "Yes, your reasoning is sound. When an LLM uses a web browser as its primary tool for interacting with the world, it needs to be aware of and able to interpret multiple layers of information:\n", "\n", "1. **Surface-level HTML content**: The visible text that humans read\n", "\n", "2. **Embedded structured data**: JSON-LD, RDFa, Microdata, etc. that provide machine-readable semantic information\n", "\n", "3. **Link relations**: Headers and HTML link elements that point to alternative representations\n", "\n", "For this to work effectively:\n", "\n", "- The LLM would need to parse both the visible content and inspect the page source for embedded structured data, particularly looking for `<script type=\"application/ld+json\">` tags\n", "\n", "- When it encounters JSON-LD, it should recognize URIs and understand they can be followed to retrieve additional information\n", "\n", "- It would need to handle different resolution strategies based on the URI pattern:\n", "  - Schema.org terms might require HTML parsing\n", "  - W3C vocabularies might be directly downloadable\n", "  - w3id.org URIs would require following redirects with content negotiation\n", "  - Other vocabularies may have their own patterns\n", "\n", "- The LLM would need to understand context documents and how they map terms to URIs\n", "\n", "This creates a complex but potentially powerful workflow:\n", "\n", "1. LLM visits a webpage\n", "2. It reads the visible content but also extracts embedded JSON-LD\n", "3. It recognizes terms from known vocabularies (Schema.org, Dublin Core, etc.)\n", "4. When it needs more information about a term, it follows the appropriate URI\n", "5. It may need to apply different retrieval strategies depending on the vocabulary\n", "6. It builds up a knowledge graph as it explores, connecting information across sources\n", "\n", "This approach would allow the LLM to go beyond the surface content of web pages and tap into the semantic web layer that connects data across the internet. However, it would require sophisticated handling of different data access patterns, context resolution, and knowledge integration.\n", "\n", "Does this align with your vision for how an LLM would navigate the semantic web through a browser interface?"]}], "metadata": {"kernelspec": {"display_name": "python3", "language": "python", "name": "python3"}}, "nbformat": 4, "nbformat_minor": 4}