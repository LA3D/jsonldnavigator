{"cells": [{"cell_type": "code", "metadata": {}, "source": ["# !pip install -U mlcroissant"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["from fastcore.utils import *"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "Hi solveit! I am Chuck, and I am working with you today! I'm an experienced Python coder, experienced with semantic web technologies like OWL,RDF and SPARQL, and I enjoy learning new things. When writing code for me, please follow fast.ai coding style: avoid comments; place single line if/loop/etc constructs on the same line; use concise variable names where appropriate. Follow the style you will see in my messages, as we work on this dialogue together. Are you ready?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "Hi Chuck! Great to meet you. I'm ready to work with you using fast.ai coding style - concise variable names, single-line constructs, and minimal comments. I'll follow your lead as we work together.\n", "\n", "What would you like to explore today? With your background in Python and semantic web technologies, we have many interesting directions we could take."]}, {"cell_type": "code", "metadata": {}, "source": ["from httpx import get as xget, post as xpost\n", "from bs4 import BeautifulSoup as bs\n", "from fastcore.utils import *\n", "import json\n", "from typing import Any, Dict, List, Optional, Union\n", "from pyld import jsonld  # For JSON-LD processing\n", "import mlcroissant as mlc\n", "import pandas as pd\n", "from claudette import *"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["from IPython.display import display,HTML,Markdown"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["crurl = 'https://raw.githubusercontent.com/mlcommons/croissant/refs/heads/main/docs/croissant-spec-draft.md'\n", "crpage = xget(crurl).text.replace(r'\\*','*')\n", "crtext = bs(crpage,'html.parser').get_text()"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["from toolslm.md_hier import *"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["hdgs = create_heading_dict(crtext)"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["hdgs"], "outputs": [{"data": {"text/plain": ["{'Croissant Format Specification (draft)': {'Introduction': {'Discoverability': {},\n", "   'Portability and Reproducibility': {},\n", "   'Responsible AI': {}},\n", "  'Terminology': {},\n", "  'Format Example': {},\n", "  'Prerequisites': {'Namespaces': {},\n", "   'ID and Reference Mechanism': {},\n", "   'Croissant in Web Pages': {}},\n", "  'Dataset-level Information': {'schema.org/Dataset': {'Required': {},\n", "    'Recommended': {},\n", "    'Other schema.org Properties': {}},\n", "   'Modified and Added Properties': {},\n", "   'Dataset Versioning/Checkpoints': {'Version': {},\n", "    'Checksums': {},\n", "    'Live Datasets': {'Example 1: Daily refreshes': {},\n", "     'Example 2: Daily snapshots': {}}}},\n", "  'Resources': {'FileObject': {}, 'FileSet': {}},\n", "  'RecordSets': {'RecordSet': {},\n", "   'Field': {},\n", "   'DataSource': {'Extract': {}, 'Transform': {}, 'Format': {}},\n", "   'Data Types': {'DataType': {},\n", "    'Using data types from other vocabularies': {},\n", "    'Typing RecordSets': {}},\n", "   'Embedding data': {'Data': {}, 'Examples': {}},\n", "   'Joins': {},\n", "   'Hierarchical RecordSets': {'Nested Fields': {}, 'Nested Records': {}}},\n", "  'ML-specific Features': {'Categorical Data': {},\n", "   'Splits': {},\n", "   'Label Data': {},\n", "   'BoundingBox': {},\n", "   'SegmentationMask': {}},\n", "  'Appendix 1: JSON-LD context': {}}}"], "text/markdown": ["```json\n", "{ 'Croissant Format Specification (draft)': { 'Appendix 1: JSON-LD context': {},\n", "                                              'Dataset-level Information': { 'Dataset Versioning/Checkpoints': { 'Checksums': { },\n", "                                                                                                                 'Live Datasets': { 'Example 1: Daily refreshes': { },\n", "                                                                                                                                    'Example 2: Daily snapshots': { }},\n", "                                                                                                                 'Version': { }},\n", "                                                                             'Modified and Added Properties': { },\n", "                                                                             'schema.org/Dataset': { 'Other schema.org Properties': { },\n", "                                                                                                     'Recommended': { },\n", "                                                                                                     'Required': { }}},\n", "                                              'Format Example': {},\n", "                                              'Introduction': { 'Discoverability': { },\n", "                                                                'Portability and Reproducibility': { },\n", "                                                                'Responsible AI': { }},\n", "                                              'ML-specific Features': { 'BoundingBox': { },\n", "                                                                        'Categorical Data': { },\n", "                                                                        'Label Data': { },\n", "                                                                        'SegmentationMask': { },\n", "                                                                        'Splits': { }},\n", "                                              'Prerequisites': { 'Croissant in Web Pages': { },\n", "                                                                 'ID and Reference Mechanism': { },\n", "                                                                 'Namespaces': { }},\n", "                                              'RecordSets': { 'Data Types': { 'DataType': { },\n", "                                                                              'Typing RecordSets': { },\n", "                                                                              'Using data types from other vocabularies': { }},\n", "                                                              'DataSource': { 'Extract': { },\n", "                                                                              'Format': { },\n", "                                                                              'Transform': { }},\n", "                                                              'Embedding data': { 'Data': { },\n", "                                                                                  'Examples': { }},\n", "                                                              'Field': {},\n", "                                                              'Hierarchical RecordSets': { 'Nested Fields': { },\n", "                                                                                           'Nested Records': { }},\n", "                                                              'Joins': {},\n", "                                                              'RecordSet': {}},\n", "                                              'Resources': { 'FileObject': {},\n", "                                                             'FileSet': {}},\n", "                                              'Terminology': {}}}\n", "```"]}, "metadata": {}, "output_type": "execute_result", "execution_count": null}], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["crturl = 'https://raw.githubusercontent.com/mlcommons/croissant/refs/heads/main/docs/croissant.ttl'"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["## Sample Croissant Dataset\n", "The [Kaggle Titanic Dataset](https://www.kaggle.com/datasets/yasserh/titanic-dataset) offers a Croissant metadata download.\n", "```python\n", "import mlcroissant as mlc\n", "import pandas as pd\n", "\n", "# Fetch the Croissant JSON-LD\n", "croissant_dataset = mlc.Dataset('https://www.kaggle.com/datasets/yasserh/titanic-dataset/croissant/download')\n", "\n", "# Check what record sets are in the dataset\n", "record_sets = croissant_dataset.metadata.record_sets\n", "print(record_sets)\n", "\n", "# Fetch the records and put them in a DataFrame\n", "record_set_df = pd.DataFrame(croissant_dataset.records(record_set=record_sets[0].uuid))\n", "record_set_df.head()\n", "```"], "attachments": {}}, {"cell_type": "code", "metadata": {}, "source": ["# Fetch the Croissant JSON-LD\n", "croissant_dataset = mlc.Dataset('https://www.kaggle.com/datasets/yasserh/titanic-dataset/croissant/download')"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["# Check what record sets are in the dataset\n", "record_sets = croissant_dataset.metadata.record_sets\n", "print(record_sets)"], "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[RecordSet(uuid=\"Titanic-Dataset.csv\")]\n"]}], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["## There is a bug with the mime typer being unsupported for download and conversion to a pandas dataframe.\n", "# Fetch the records and put them in a DataFrame\n", "# record_set_df = pd.DataFrame(croissant_dataset.records(record_set=record_sets[0].uuid))\n", "# record_set_df.head()"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["hdict = markdown_to_dict(crtext)"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["recsets = hdict['Croissant Format Specification draft.Datasetlevel Information']"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["# JSON-LD Navigation Tools for LLMs: Project Summary\n", "\n", "## Motivation and Goals\n", "\n", "We're developing a set of tools to help LLMs effectively navigate and understand JSON-LD documents, with a particular focus on Croissant metadata for ML datasets. The motivation is to:\n", "\n", "1. Create semantic navigation capabilities for JSON-LD similar to what toolslm.md_hier provides for Markdown\n", "2. Enable LLMs to access and understand complex semantic web data without requiring deep JSON-LD expertise\n", "3. Support agentic workflows where LLMs can autonomously explore and extract meaning from JSON-LD documents\n", "4. Make Croissant dataset metadata more accessible to LLM-based tools\n", "\n", "## Approach\n", "\n", "We're following a fast.ai-inspired methodology characterized by:\n", "\n", "1. **Simple, focused functions** that do one thing well\n", "2. **Minimal abstractions** with clean, pythonic interfaces\n", "3. **Composable tools** that can be combined in flexible ways\n", "4. **Leveraging LLM capabilities** rather than building complex parsing logic\n", "\n", "Our approach uses prompt chaining to progressively build understanding of JSON-LD documents:\n", "\n", "1. **Document Overview Analysis**: Identify types, properties, and the document's purpose\n", "2. **Context Resolution**: Map namespace prefixes to URIs and understand vocabularies\n", "3. **Type-Based Exploration**: Analyze each type and its relationships\n", "4. **Path Generation**: Create navigation paths for accessing important properties\n", "5. **Document Summary**: Synthesize a comprehensive understanding of the document\n", "\n", "## Implementation\n", "\n", "We've built several key components:\n", "\n", "1. **JSON-LD Analysis Class**: A container for analysis results with helper methods\n", "2. **Namespace Resolution**: Tools for fetching and understanding vocabulary definitions\n", "3. **Term Explanation**: Using LLMs to extract meaning from vocabulary definitions\n", "4. **XML-Tagged Response Parsing**: Extracting structured information from LLM responses\n", "\n", "We've integrated these with toolslm-inspired patterns for:\n", "- Content fetching and parsing\n", "- Caching results for efficiency\n", "- Providing clean, notebook-friendly representations\n", "\n", "## Agentic Workflow Integration\n", "\n", "The tools are designed to support agentic workflows by:\n", "\n", "1. Providing ground truth from JSON-LD documents\n", "2. Enabling semantic exploration of document structure\n", "3. Supporting term definition lookup and explanation\n", "4. Generating navigation paths for accessing data\n", "\n", "The LLM acts as the semantic analyzer, while our code provides the scaffolding to make JSON-LD documents accessible and navigable.\n", "\n", "The end goal is a clean, efficient toolkit that enables LLMs to work with JSON-LD data as easily as they work with natural language text."], "attachments": {}}, {"cell_type": "markdown", "metadata": {}, "source": ["## Da Plan\n", "So we're essentially building a RAG-like system for JSON-LD that parallels what toolslm does for Markdown.\n", "\n", "The core idea is to create functions that can:\n", "\n", "- Parse JSON-LD documents\n", "- Create navigable structures (similar to the hierarchical dictionaries for markdown)\n", "- Provide intuitive access patterns for LLMs to query and reason over the semantic data\n", "\n", "\n", "1. Parses JSON-LD documents into navigable structures\n", "2. Identifies and exposes affordances within those structures\n", "3. Provides intuitive access patterns that leverage these affordances\n", "\n", "For a `jsonld_to_dict` function (similar to `markdown_to_dict`), we'd want to:\n", "\n", "1. Extract the basic hierarchical structure\n", "2. Identify affordances like context mappings, type information, and references\n", "3. Include these affordances in our navigable structure\n", "\n", "This would give LLMs both the content and the \"handles\" they need to navigate effectively."], "attachments": {}}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "Yep, I think you've got it. Why don't you go ahead and sketch out what this function might look like? Remember we're doing this in a Jeremy Howard sort of style, so we want to do this step by step, and we'll be exporting to nbdev, so we want to keep that in mind."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "Let's sketch out our approach in a step-by-step Jeremy Howard style, keeping nbdev export in mind. We'll start with the core function and build up.\n", "\n", "First, let's define our main function signature:\n", "\n", "```python\n", "__all__ = ['jsonld_to_dict', 'extract_affordances', 'navigate_jsonld']\n", "\n", "def jsonld_to_dict(json_ld, include_affordances=True):\n", "    \"Convert JSON-LD to a navigable dictionary structure with affordances\"\n", "    # Main conversion logic will go here\n", "    if include_affordances: affordances = extract_affordances(json_ld)\n", "    # Create the base structure\n", "    result = _create_base_structure(json_ld)\n", "    # Add affordances if requested\n", "    if include_affordances: result = _add_affordances(result, affordances)\n", "    return dict2obj(result)\n", "```\n", "\n", "Next, let's define the function to extract affordances:\n", "\n", "```python\n", "def extract_affordances(json_ld):\n", "    \"Extract navigation affordances from JSON-LD document\"\n", "    affordances = {}\n", "    # Extract context mappings\n", "    affordances['context'] = _extract_context(json_ld)\n", "    # Extract type information\n", "    affordances['types'] = _extract_types(json_ld)\n", "    # Extract ID references\n", "    affordances['references'] = _extract_references(json_ld)\n", "    # Extract vocabulary info\n", "    affordances['vocab'] = _extract_vocabulary(json_ld)\n", "    return affordances\n", "```\n", "\n", "Now, for navigation:\n", "\n", "```python\n", "def navigate_jsonld(jsonld_dict, path=None, by_type=None, by_id=None):\n", "    \"Navigate the JSON-LD dictionary by path, type, or ID\"\n", "    if path: return _navigate_by_path(jsonld_dict, path)\n", "    if by_type: return _navigate_by_type(jsonld_dict, by_type)\n", "    if by_id: return _navigate_by_id(jsonld_dict, by_id)\n", "    return jsonld_dict\n", "```\n", "\n", "Does this approach make sense as a starting point? We can then implement the helper functions like `_extract_context`, `_extract_types`, etc."]}, {"cell_type": "code", "metadata": {}, "source": ["def _create_base_structure(json_ld):\n", "    \"Create the base dictionary structure from JSON-LD\"\n", "    if isinstance(json_ld, str): json_ld = json.loads(json_ld)\n", "    \n", "    # Handle both single objects and arrays of objects\n", "    docs = json_ld if isinstance(json_ld, list) else [json_ld]\n", "    \n", "    # Create a result with @id as keys where available\n", "    result = {}\n", "    for doc in docs:\n", "        if '@id' in doc:\n", "            result[doc['@id']] = doc\n", "        else:\n", "            # For items without @id, use a generated key\n", "            key = f\"item_{len(result)}\"\n", "            result[key] = doc\n", "    \n", "    return result"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["def _extract_context(json_ld):\n", "    \"Extract and analyze context mappings from JSON-LD\"\n", "    if isinstance(json_ld, str): json_ld = json.loads(json_ld)\n", "    \n", "    # Handle both single objects and arrays\n", "    docs = json_ld if isinstance(json_ld, list) else [json_ld]\n", "    \n", "    # Extract all contexts\n", "    context_info = {\n", "        'prefixes': {},      # Namespace prefixes\n", "        'terms': {},         # Term definitions\n", "        'vocab': None,       # Default vocabulary\n", "        'urls': [],          # External context URLs\n", "        'base': None         # Base IRI\n", "    }\n", "    \n", "    for doc in docs:\n", "        if '@context' not in doc: continue\n", "        \n", "        ctx = doc['@context']\n", "        \n", "        # Handle context array\n", "        if isinstance(ctx, list):\n", "            for item in ctx:\n", "                _process_context_item(item, context_info)\n", "        else:\n", "            _process_context_item(ctx, context_info)\n", "    \n", "    return context_info"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["def _process_context_item(ctx, context_info):\n", "    \"Process a single context item (URL or object)\"\n", "    if isinstance(ctx, str):\n", "        # URL context\n", "        context_info['urls'].append(ctx)\n", "        # Here we could fetch and process the external context\n", "    elif isinstance(ctx, dict):\n", "        # Object context\n", "        for key, value in ctx.items():\n", "            if key == '@vocab':\n", "                context_info['vocab'] = value\n", "            elif key == '@base':\n", "                context_info['base'] = value\n", "            elif isinstance(value, str):\n", "                # Simple prefix mapping\n", "                context_info['prefixes'][key] = value\n", "            elif isinstance(value, dict):\n", "                # Term definition\n", "                context_info['terms'][key] = value"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "What do we want to do next?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "Let's implement a function to fetch and process external contexts. This is important for \"following our nose\" in JSON-LD, as many documents reference external context files that contain crucial vocabulary definitions.\n", "\n", "```python\n", "def fetch_context(url, cache=True):\n", "    \"Fetch external JSON-LD context from URL\"\n", "    # Use a simple cache to avoid refetching\n", "    if cache and url in _context_cache: return _context_cache[url]\n", "    \n", "    try:\n", "        resp = xget(url)\n", "        if resp.status_code == 200:\n", "            ctx = resp.json()\n", "            if cache: _context_cache[url] = ctx\n", "            return ctx\n", "        else:\n", "            return None\n", "    except Exception as e:\n", "        print(f\"Error fetching context from {url}: {e}\")\n", "        return None\n", "\n", "# Initialize a simple cache\n", "_context_cache = {}\n", "```\n", "\n", "Now, let's enhance our `_process_context_item` function to use this:\n", "\n", "```python\n", "def _process_context_item(ctx, context_info, fetch_external=True):\n", "    \"Process a single context item (URL or object)\"\n", "    if isinstance(ctx, str):\n", "        # URL context\n", "        context_info['urls'].append(ctx)\n", "        if fetch_external:\n", "            external_ctx = fetch_context(ctx)\n", "            if external_ctx and '@context' in external_ctx:\n", "                # Process the external context\n", "                _process_context_item(external_ctx['@context'], context_info)\n", "    elif isinstance(ctx, dict):\n", "        # Object context\n", "        for key, value in ctx.items():\n", "            if key == '@vocab':\n", "                context_info['vocab'] = value\n", "            elif key == '@base':\n", "                context_info['base'] = value\n", "            elif isinstance(value, str):\n", "                # Simple prefix mapping\n", "                context_info['prefixes'][key] = value\n", "            elif isinstance(value, dict):\n", "                # Term definition\n", "                context_info['terms'][key] = value\n", "```\n", "\n", "Next, should we implement `_extract_types` to identify all the entity types in the document? This would help us build a type-based navigation system."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "Alright, we need to be a little bit careful here. So for example, if you tried to actually dereference the vocabulary for \"croissant,\" you would be sorely disappointed in its dereferenceability. Just because we can't dereference something from its URL doesn't necessarily mean that it's an error.For example, let's start with schema.org or some subset of that - how might we approach dereferencing that?Schema.org is very, very large. So do we want to actually go to the HTML pages, use BeautifulSoup and extract it? There's some logic here that the LLM has to be able to manage in tool use to figure out what it can actually put into its context window to make sure it's being factual about what's being said about the vocabulary."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "You raise an excellent point about dereferencing vocabularies. You're right that not all vocabulary URLs are directly dereferenceable, and even when they are (like schema.org), they might be too large or in formats not immediately useful.\n", "\n", "Let's refine our approach to be more robust and practical:\n", "\n", "```python\n", "def fetch_vocabulary_info(url, cache=True):\n", "    \"Fetch vocabulary information, using appropriate methods based on the URL\"\n", "    if cache and url in _vocab_cache: return _vocab_cache[url]\n", "    \n", "    result = {'terms': {}, 'source': None, 'status': 'unknown'}\n", "    \n", "    # Handle different vocabulary sources differently\n", "    if 'schema.org' in url:\n", "        # For schema.org, use a more targeted approach\n", "        result = _fetch_schema_org_term(url)\n", "    elif 'w3.org' in url:\n", "        # W3C vocabularies often have specific formats\n", "        result = _fetch_w3c_vocabulary(url)\n", "    else:\n", "        # Generic approach - try JSON-LD first, fall back to HTML\n", "        try:\n", "            # Try JSON-LD\n", "            json_result = _try_fetch_jsonld(url)\n", "            if json_result:\n", "                result = json_result\n", "            else:\n", "                # Try HTML with extraction\n", "                html_result = _try_fetch_html(url)\n", "                if html_result:\n", "                    result = html_result\n", "                else:\n", "                    result['status'] = 'not_found'\n", "        except Exception as e:\n", "            result['status'] = 'error'\n", "            result['error'] = str(e)\n", "    \n", "    if cache: _vocab_cache[url] = result\n", "    return result\n", "\n", "# Initialize vocabulary cache\n", "_vocab_cache = {}\n", "```\n", "\n", "This function provides a framework for handling different vocabulary sources. For schema.org specifically, we could implement:\n", "\n", "```python\n", "def _fetch_schema_org_term(url):\n", "    \"Fetch term information from schema.org\"\n", "    result = {'terms': {}, 'source': 'schema.org', 'status': 'processed'}\n", "    \n", "    # Extract the term name from URL\n", "    term = url.split('/')[-1]\n", "    \n", "    try:\n", "        # Schema.org provides JSON-LD for each term\n", "        term_url = f\"https://schema.org/{term}.jsonld\"\n", "        resp = xget(term_url)\n", "        \n", "        if resp.status_code == 200:\n", "            data = resp.json()\n", "            # Process the JSON-LD definition\n", "            if '@graph' in data:\n", "                for item in data['@graph']:\n", "                    if '@id' in item and item['@id'].endswith(term):\n", "                        result['terms'][term] = item\n", "                        break\n", "        else:\n", "            # Fall back to HTML scraping if needed\n", "            html_url = f\"https://schema.org/{term}\"\n", "            result = _extract_from_schema_org_html(html_url)\n", "    except Exception as e:\n", "        result['status'] = 'error'\n", "        result['error'] = str(e)\n", "    \n", "    return result\n", "```\n", "\n", "What do you think? Should we focus on implementing these vocabulary fetching functions, or would you prefer to move on to implementing `_extract_types` first?"]}, {"cell_type": "code", "metadata": {}, "source": ["# Let's start with a simple JSON-LD example\n", "sample_jsonld = {\n", "    \"@context\": {\n", "        \"schema\": \"https://schema.org/\",\n", "        \"name\": \"schema:name\",\n", "        \"description\": \"schema:description\",\n", "        \"image\": {\"@id\": \"schema:image\", \"@type\": \"@id\"},\n", "        \"dataset\": \"schema:Dataset\"\n", "    },\n", "    \"@type\": \"schema:Dataset\",\n", "    \"@id\": \"https://example.org/datasets/123\",\n", "    \"name\": \"Sample Dataset\",\n", "    \"description\": \"A sample dataset for testing our JSON-LD tools\",\n", "    \"image\": \"https://example.org/images/dataset123.jpg\"\n", "}"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["def extract_basic_structure(json_ld):\n", "    \"Extract basic structure from JSON-LD document\"\n", "    if isinstance(json_ld, str): json_ld = json.loads(json_ld)\n", "    \n", "    # Create a simple structure with key information\n", "    structure = {\n", "        'id': json_ld.get('@id'),\n", "        'type': json_ld.get('@type'),\n", "        'properties': {}\n", "    }\n", "    \n", "    # Extract properties (excluding @-prefixed ones)\n", "    for key, value in json_ld.items():\n", "        if not key.startswith('@'):\n", "            structure['properties'][key] = value\n", "    \n", "    return structure\n", "\n", "# Let's test it\n", "basic_structure = extract_basic_structure(sample_jsonld)\n", "basic_structure"], "outputs": [{"data": {"text/plain": ["{'id': 'https://example.org/datasets/123',\n", " 'type': 'schema:Dataset',\n", " 'properties': {'name': 'Sample Dataset',\n", "  'description': 'A sample dataset for testing our JSON-LD tools',\n", "  'image': 'https://example.org/images/dataset123.jpg'}}"]}, "metadata": {}, "output_type": "execute_result", "execution_count": null}], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["def extract_context_mappings(json_ld):\n", "    \"Extract context mappings from JSON-LD document\"\n", "    if isinstance(json_ld, str): json_ld = json.loads(json_ld)\n", "    \n", "    context = json_ld.get('@context', {})\n", "    if not context: return {}\n", "    \n", "    # Initialize context mappings\n", "    mappings = {\n", "        'prefixes': {},  # namespace prefixes (schema -> https://schema.org/)\n", "        'terms': {},     # term definitions (name -> schema:name)\n", "        'vocab': None    # default vocabulary\n", "    }\n", "    \n", "    # Process context\n", "    if isinstance(context, dict):\n", "        for key, value in context.items():\n", "            if key == '@vocab':\n", "                mappings['vocab'] = value\n", "            elif isinstance(value, str):\n", "                # Simple mapping (prefix or term)\n", "                if value.startswith('http'):\n", "                    # It's a prefix\n", "                    mappings['prefixes'][key] = value\n", "                else:\n", "                    # It's a term mapping\n", "                    mappings['terms'][key] = value\n", "            elif isinstance(value, dict):\n", "                # Complex term definition\n", "                mappings['terms'][key] = value\n", "    \n", "    return mappings\n", "\n", "# Test it\n", "context_mappings = extract_context_mappings(sample_jsonld)\n", "context_mappings"], "outputs": [{"data": {"text/plain": ["{'prefixes': {'schema': 'https://schema.org/'},\n", " 'terms': {'name': 'schema:name',\n", "  'description': 'schema:description',\n", "  'image': {'@id': 'schema:image', '@type': '@id'},\n", "  'dataset': 'schema:Dataset'},\n", " 'vocab': None}"]}, "metadata": {}, "output_type": "execute_result", "execution_count": null}], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["def resolve_term(term, context_mappings):\n", "    \"Resolve a term to its full URI using context mappings\"\n", "    if not term or not context_mappings: return term\n", "    \n", "    # Handle terms that are already URIs\n", "    if term.startswith('http'): return term\n", "    \n", "    # Handle prefixed terms (e.g., schema:Dataset)\n", "    if ':' in term:\n", "        prefix, local_part = term.split(':', 1)\n", "        if prefix in context_mappings['prefixes']:\n", "            return context_mappings['prefixes'][prefix] + local_part\n", "        return term\n", "    \n", "    # Handle mapped terms\n", "    if term in context_mappings['terms']:\n", "        term_def = context_mappings['terms'][term]\n", "        if isinstance(term_def, str):\n", "            # Recursively resolve\n", "            return resolve_term(term_def, context_mappings)\n", "        elif isinstance(term_def, dict) and '@id' in term_def:\n", "            # Complex term definition\n", "            return resolve_term(term_def['@id'], context_mappings)\n", "    \n", "    # Use default vocabulary if available\n", "    if context_mappings['vocab']:\n", "        return context_mappings['vocab'] + term\n", "    \n", "    return term\n", "\n", "# Let's test it with a few examples\n", "test_terms = [\n", "    'schema:Dataset',\n", "    'name',\n", "    'image',\n", "    'https://example.org/direct'\n", "]\n", "\n", "for term in test_terms:\n", "    resolved = resolve_term(term, context_mappings)\n", "    print(f\"{term} -> {resolved}\")"], "outputs": [{"name": "stdout", "output_type": "stream", "text": ["schema:Dataset -> https://schema.org/Dataset\n", "name -> https://schema.org/name\n", "image -> https://schema.org/image\n", "https://example.org/direct -> https://example.org/direct\n"]}], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["def fetch_schema_org_term_info(term):\n", "    \"Fetch detailed information about a Schema.org term using BeautifulSoup\"\n", "    url = f\"https://schema.org/{term}\"\n", "    response = xget(url)\n", "    \n", "    if response.status_code != 200:\n", "        return {\"error\": f\"Failed to fetch {url}, status code: {response.status_code}\"}\n", "    \n", "    # Parse the HTML\n", "    soup = bs(response.text, 'html.parser')\n", "    \n", "    # Look for JSON-LD script in the page\n", "    jsonld_script = soup.find('script', {'type': 'application/ld+json'})\n", "    \n", "    if jsonld_script:\n", "        try:\n", "            # Extract and parse the JSON-LD data\n", "            jsonld_data = json.loads(jsonld_script.string)\n", "            return {\n", "                \"source\": \"schema.org\",\n", "                \"term\": term,\n", "                \"jsonld\": jsonld_data,\n", "                \"url\": url\n", "            }\n", "        except json.JSONDecodeError:\n", "            return {\"error\": \"Failed to parse JSON-LD from the page\"}\n", "    \n", "    # If no JSON-LD, extract basic info from HTML\n", "    description = soup.find('div', class_='description')\n", "    if description:\n", "        return {\n", "            \"source\": \"schema.org\",\n", "            \"term\": term,\n", "            \"description\": description.text.strip(),\n", "            \"url\": url\n", "        }\n", "    \n", "    return {\"error\": \"Could not extract term information\"}\n", "\n", "# Let's try it with \"Dataset\"\n", "dataset_info = fetch_schema_org_term_info(\"Dataset\")\n", "dataset_info"], "outputs": [{"data": {"text/plain": ["{'source': 'schema.org',\n", " 'term': 'Dataset',\n", " 'jsonld': {'@context': {'brick': 'https://brickschema.org/schema/Brick#',\n", "   'csvw': 'http://www.w3.org/ns/csvw#',\n", "   'dc': 'http://purl.org/dc/elements/1.1/',\n", "   'dcam': 'http://purl.org/dc/dcam/',\n", "   'dcat': 'http://www.w3.org/ns/dcat#',\n", "   'dcmitype': 'http://purl.org/dc/dcmitype/',\n", "   'dcterms': 'http://purl.org/dc/terms/',\n", "   'doap': 'http://usefulinc.com/ns/doap#',\n", "   'foaf': 'http://xmlns.com/foaf/0.1/',\n", "   'odrl': 'http://www.w3.org/ns/odrl/2/',\n", "   'org': 'http://www.w3.org/ns/org#',\n", "   'owl': 'http://www.w3.org/2002/07/owl#',\n", "   'prof': 'http://www.w3.org/ns/dx/prof/',\n", "   'prov': 'http://www.w3.org/ns/prov#',\n", "   'qb': 'http://purl.org/linked-data/cube#',\n", "   'rdf': 'http://www.w3.org/1999/02/22-rdf-syntax-ns#',\n", "   'rdfs': 'http://www.w3.org/2000/01/rdf-schema#',\n", "   'schema': 'https://schema.org/',\n", "   'sh': 'http://www.w3.org/ns/shacl#',\n", "   'skos': 'http://www.w3.org/2004/02/skos/core#',\n", "   'sosa': 'http://www.w3.org/ns/sosa/',\n", "   'ssn': 'http://www.w3.org/ns/ssn/',\n", "   'time': 'http://www.w3.org/2006/time#',\n", "   'vann': 'http://purl.org/vocab/vann/',\n", "   'void': 'http://rdfs.org/ns/void#',\n", "   'xsd': 'http://www.w3.org/2001/XMLSchema#'},\n", "  '@graph': [{'@id': 'schema:isBasedOn',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'A resource from which this work is derived or from which it is a modification or adaptation.',\n", "    'rdfs:label': 'isBasedOn',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:URL'},\n", "     {'@id': 'schema:Product'}]},\n", "   {'@id': 'schema:potentialAction',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': \"Indicates a potential Action, which describes an idealized action in which this thing would play an 'object' role.\",\n", "    'rdfs:label': 'potentialAction',\n", "    'schema:domainIncludes': {'@id': 'schema:Thing'},\n", "    'schema:rangeIncludes': {'@id': 'schema:Action'}},\n", "   {'@id': 'schema:hasPart',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'Indicates an item or CreativeWork that is part of this item, or CreativeWork (in some sense).',\n", "    'rdfs:label': 'hasPart',\n", "    'schema:contributor': {'@id': 'https://schema.org/docs/collab/bibex'},\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:inverseOf': {'@id': 'schema:isPartOf'},\n", "    'schema:rangeIncludes': {'@id': 'schema:CreativeWork'}},\n", "   {'@id': 'schema:publishingPrinciples',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'The publishingPrinciples property indicates (typically via [[URL]]) a document describing the editorial principles of an [[Organization]] (or individual, e.g. a [[Person]] writing a blog) that relate to their activities as a publisher, e.g. ethics or diversity policies. When applied to a [[CreativeWork]] (e.g. [[NewsArticle]]) the principles are those of the party primarily responsible for the creation of the [[CreativeWork]].\\n\\nWhile such policies are most typically expressed in natural language, sometimes related information (e.g. indicating a [[funder]]) can be expressed using schema.org terminology.\\n',\n", "    'rdfs:label': 'publishingPrinciples',\n", "    'schema:domainIncludes': [{'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:Person'},\n", "     {'@id': 'schema:Organization'}],\n", "    'schema:rangeIncludes': [{'@id': 'schema:URL'},\n", "     {'@id': 'schema:CreativeWork'}]},\n", "   {'@id': 'schema:creativeWorkStatus',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'The status of a creative work in terms of its stage in a lifecycle. Example terms include Incomplete, Draft, Published, Obsolete. Some organizations define a set of terms for the stages of their publication lifecycle.',\n", "    'rdfs:label': 'creativeWorkStatus',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:isPartOf': {'@id': 'https://pending.schema.org'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:DefinedTerm'},\n", "     {'@id': 'schema:Text'}],\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/987'}},\n", "   {'@id': 'schema:locationCreated',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'The location where the CreativeWork was created, which may not be the same as the location depicted in the CreativeWork.',\n", "    'rdfs:label': 'locationCreated',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': {'@id': 'schema:Place'}},\n", "   {'@id': 'schema:conditionsOfAccess',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'Conditions that affect the availability of, or method(s) of access to, an item. Typically used for real world items such as an [[ArchiveComponent]] held by an [[ArchiveOrganization]]. This property is not suitable for use as a general Web access control mechanism. It is expressed only in natural language.\\\\n\\\\nFor example \"Available by appointment from the Reading Room\" or \"Accessible only from logged-in accounts \". ',\n", "    'rdfs:label': 'conditionsOfAccess',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:isPartOf': {'@id': 'https://pending.schema.org'},\n", "    'schema:rangeIncludes': {'@id': 'schema:Text'},\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/2173'}},\n", "   {'@id': 'schema:spatial',\n", "    '@type': 'rdf:Property',\n", "    'owl:equivalentProperty': {'@id': 'dcterms:spatial'},\n", "    'rdfs:comment': 'The \"spatial\" property can be used in cases when more specific properties\\n(e.g. [[locationCreated]], [[spatialCoverage]], [[contentLocation]]) are not known to be appropriate.',\n", "    'rdfs:label': 'spatial',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': {'@id': 'schema:Place'}},\n", "   {'@id': 'schema:encoding',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'A media object that encodes this CreativeWork. This property is a synonym for associatedMedia.',\n", "    'rdfs:label': 'encoding',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:inverseOf': {'@id': 'schema:encodesCreativeWork'},\n", "    'schema:rangeIncludes': {'@id': 'schema:MediaObject'}},\n", "   {'@id': 'schema:catalog',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'A data catalog which contains this dataset.',\n", "    'rdfs:label': 'catalog',\n", "    'schema:domainIncludes': {'@id': 'schema:Dataset'},\n", "    'schema:rangeIncludes': {'@id': 'schema:DataCatalog'},\n", "    'schema:supersededBy': {'@id': 'schema:includedInDataCatalog'}},\n", "   {'@id': 'schema:workTranslation',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'A work that is a translation of the content of this work. E.g. \u897f\u904a\u8a18 has an English workTranslation \u201cJourney to the West\u201d, a German workTranslation \u201cMonkeys Pilgerfahrt\u201d and a Vietnamese  translation T\u00e2y du k\u00fd b\u00ecnh kh\u1ea3o.',\n", "    'rdfs:label': 'workTranslation',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:inverseOf': {'@id': 'schema:translationOfWork'},\n", "    'schema:isPartOf': {'@id': 'https://bib.schema.org'},\n", "    'schema:rangeIncludes': {'@id': 'schema:CreativeWork'}},\n", "   {'@id': 'schema:isBasedOnUrl',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'A resource that was used in the creation of this resource. This term can be repeated for multiple sources. For example, http://example.com/great-multiplication-intro.html.',\n", "    'rdfs:label': 'isBasedOnUrl',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:URL'},\n", "     {'@id': 'schema:Product'}],\n", "    'schema:supersededBy': {'@id': 'schema:isBasedOn'}},\n", "   {'@id': 'schema:acquireLicensePage',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'Indicates a page documenting how licenses can be purchased or otherwise acquired, for the current item.',\n", "    'rdfs:label': 'acquireLicensePage',\n", "    'rdfs:subPropertyOf': {'@id': 'schema:usageInfo'},\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:isPartOf': {'@id': 'https://pending.schema.org'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:URL'}],\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/2454'}},\n", "   {'@id': 'schema:contributor',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'A secondary contributor to the CreativeWork or Event.',\n", "    'rdfs:label': 'contributor',\n", "    'schema:domainIncludes': [{'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:Event'}],\n", "    'schema:rangeIncludes': [{'@id': 'schema:Person'},\n", "     {'@id': 'schema:Organization'}]},\n", "   {'@id': 'schema:publication',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'A publication event associated with the item.',\n", "    'rdfs:label': 'publication',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': {'@id': 'schema:PublicationEvent'}},\n", "   {'@id': 'schema:publisherImprint',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'The publishing division which published the comic.',\n", "    'rdfs:label': 'publisherImprint',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:isPartOf': {'@id': 'https://bib.schema.org'},\n", "    'schema:rangeIncludes': {'@id': 'schema:Organization'}},\n", "   {'@id': 'schema:editor',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'Specifies the Person who edited the CreativeWork.',\n", "    'rdfs:label': 'editor',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': {'@id': 'schema:Person'}},\n", "   {'@id': 'schema:Dataset',\n", "    '@type': 'rdfs:Class',\n", "    'owl:equivalentClass': [{'@id': 'void:Dataset'},\n", "     {'@id': 'dcmitype:Dataset'},\n", "     {'@id': 'dcat:Dataset'}],\n", "    'rdfs:comment': 'A body of structured information describing some topic(s) of interest.',\n", "    'rdfs:label': 'Dataset',\n", "    'rdfs:subClassOf': {'@id': 'schema:CreativeWork'},\n", "    'schema:contributor': {'@id': 'https://schema.org/docs/collab/DatasetClass'}},\n", "   {'@id': 'schema:educationalLevel',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': \"The level in terms of progression through an educational or training context. Examples of educational levels include 'beginner', 'intermediate' or 'advanced', and formal sets of level indicators.\",\n", "    'rdfs:label': 'educationalLevel',\n", "    'schema:domainIncludes': [{'@id': 'schema:EducationalOccupationalCredential'},\n", "     {'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:EducationEvent'},\n", "     {'@id': 'schema:LearningResource'}],\n", "    'schema:isPartOf': {'@id': 'https://pending.schema.org'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:DefinedTerm'},\n", "     {'@id': 'schema:URL'},\n", "     {'@id': 'schema:Text'}],\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/1779'}},\n", "   {'@id': 'schema:award',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'An award won by or for this item.',\n", "    'rdfs:label': 'award',\n", "    'schema:domainIncludes': [{'@id': 'schema:Organization'},\n", "     {'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:Person'},\n", "     {'@id': 'schema:Product'},\n", "     {'@id': 'schema:Service'}],\n", "    'schema:rangeIncludes': {'@id': 'schema:Text'}},\n", "   {'@id': 'schema:additionalType',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'An additional type for the item, typically used for adding more specific types from external vocabularies in microdata syntax. This is a relationship between something and a class that the thing is in. Typically the value is a URI-identified RDF class, and in this case corresponds to the\\n    use of rdf:type in RDF. Text values can be used sparingly, for cases where useful information can be added without their being an appropriate schema to reference. In the case of text values, the class label should follow the schema.org <a href=\"https://schema.org/docs/styleguide.html\">style guide</a>.',\n", "    'rdfs:label': 'additionalType',\n", "    'rdfs:subPropertyOf': {'@id': 'rdf:type'},\n", "    'schema:domainIncludes': {'@id': 'schema:Thing'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:Text'}, {'@id': 'schema:URL'}]},\n", "   {'@id': 'schema:contentRating',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': \"Official rating of a piece of content&#x2014;for example, 'MPAA PG-13'.\",\n", "    'rdfs:label': 'contentRating',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:Rating'},\n", "     {'@id': 'schema:Text'}]},\n", "   {'@id': 'schema:accessibilityControl',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'Identifies input methods that are sufficient to fully control the described resource. Values should be drawn from the [approved vocabulary](https://www.w3.org/2021/a11y-discov-vocab/latest/#accessibilityControl-vocabulary).',\n", "    'rdfs:label': 'accessibilityControl',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': {'@id': 'schema:Text'}},\n", "   {'@id': 'schema:aggregateRating',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'The overall rating, based on a collection of reviews or ratings, of the item.',\n", "    'rdfs:label': 'aggregateRating',\n", "    'schema:domainIncludes': [{'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:Brand'},\n", "     {'@id': 'schema:Product'},\n", "     {'@id': 'schema:Offer'},\n", "     {'@id': 'schema:Service'},\n", "     {'@id': 'schema:Place'},\n", "     {'@id': 'schema:Event'},\n", "     {'@id': 'schema:Organization'}],\n", "    'schema:rangeIncludes': {'@id': 'schema:AggregateRating'}},\n", "   {'@id': 'schema:abstract',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'An abstract is a short description that summarizes a [[CreativeWork]].',\n", "    'rdfs:label': 'abstract',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:isPartOf': {'@id': 'https://pending.schema.org'},\n", "    'schema:rangeIncludes': {'@id': 'schema:Text'},\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/276'}},\n", "   {'@id': 'schema:learningResourceType',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': \"The predominant type or kind characterizing the learning resource. For example, 'presentation', 'handout'.\",\n", "    'rdfs:label': 'learningResourceType',\n", "    'schema:domainIncludes': [{'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:LearningResource'}],\n", "    'schema:rangeIncludes': [{'@id': 'schema:Text'},\n", "     {'@id': 'schema:DefinedTerm'}]},\n", "   {'@id': 'schema:funding',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'A [[Grant]] that directly or indirectly provide funding or sponsorship for this item. See also [[ownershipFundingInfo]].',\n", "    'rdfs:label': 'funding',\n", "    'schema:contributor': {'@id': 'https://schema.org/docs/collab/TP'},\n", "    'schema:domainIncludes': [{'@id': 'schema:MedicalEntity'},\n", "     {'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:Person'},\n", "     {'@id': 'schema:Product'},\n", "     {'@id': 'schema:Organization'},\n", "     {'@id': 'schema:Event'},\n", "     {'@id': 'schema:BioChemEntity'}],\n", "    'schema:inverseOf': {'@id': 'schema:fundedItem'},\n", "    'schema:isPartOf': {'@id': 'https://pending.schema.org'},\n", "    'schema:rangeIncludes': {'@id': 'schema:Grant'},\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/383'}},\n", "   {'@id': 'schema:thumbnailUrl',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'A thumbnail image relevant to the Thing.',\n", "    'rdfs:label': 'thumbnailUrl',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': {'@id': 'schema:URL'}},\n", "   {'@id': 'schema:inLanguage',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'The language of the content or performance or used in an action. Please use one of the language codes from the [IETF BCP 47 standard](http://tools.ietf.org/html/bcp47). See also [[availableLanguage]].',\n", "    'rdfs:label': 'inLanguage',\n", "    'schema:domainIncludes': [{'@id': 'schema:Event'},\n", "     {'@id': 'schema:WriteAction'},\n", "     {'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:CommunicateAction'},\n", "     {'@id': 'schema:LinkRole'},\n", "     {'@id': 'schema:BroadcastService'},\n", "     {'@id': 'schema:PronounceableText'}],\n", "    'schema:rangeIncludes': [{'@id': 'schema:Text'},\n", "     {'@id': 'schema:Language'}],\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/2382'}},\n", "   {'@id': 'schema:author',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'The author of this content or rating. Please note that author is special in that HTML 5 provides a special mechanism for indicating authorship via the rel tag. That is equivalent to this and may be used interchangeably.',\n", "    'rdfs:label': 'author',\n", "    'schema:domainIncludes': [{'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:Rating'}],\n", "    'schema:rangeIncludes': [{'@id': 'schema:Organization'},\n", "     {'@id': 'schema:Person'}]},\n", "   {'@id': 'schema:copyrightNotice',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'Text of a notice appropriate for describing the copyright aspects of this Creative Work, ideally indicating the owner of the copyright for the Work.',\n", "    'rdfs:label': 'copyrightNotice',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:isPartOf': {'@id': 'https://pending.schema.org'},\n", "    'schema:rangeIncludes': {'@id': 'schema:Text'},\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/2659'}},\n", "   {'@id': 'schema:teaches',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'The item being described is intended to help a person learn the competency or learning outcome defined by the referenced term.',\n", "    'rdfs:label': 'teaches',\n", "    'schema:domainIncludes': [{'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:EducationEvent'},\n", "     {'@id': 'schema:LearningResource'}],\n", "    'schema:isPartOf': {'@id': 'https://pending.schema.org'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:DefinedTerm'},\n", "     {'@id': 'schema:Text'}],\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/2427'}},\n", "   {'@id': 'schema:assesses',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'The item being described is intended to assess the competency or learning outcome defined by the referenced term.',\n", "    'rdfs:label': 'assesses',\n", "    'schema:domainIncludes': [{'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:EducationEvent'},\n", "     {'@id': 'schema:LearningResource'}],\n", "    'schema:isPartOf': {'@id': 'https://pending.schema.org'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:Text'},\n", "     {'@id': 'schema:DefinedTerm'}],\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/2427'}},\n", "   {'@id': 'schema:datePublished',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'Date of first publication or broadcast. For example the date a [[CreativeWork]] was broadcast or a [[Certification]] was issued.',\n", "    'rdfs:label': 'datePublished',\n", "    'schema:domainIncludes': [{'@id': 'schema:Certification'},\n", "     {'@id': 'schema:CreativeWork'}],\n", "    'schema:rangeIncludes': [{'@id': 'schema:DateTime'},\n", "     {'@id': 'schema:Date'}]},\n", "   {'@id': 'schema:maintainer',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'A maintainer of a [[Dataset]], software package ([[SoftwareApplication]]), or other [[Project]]. A maintainer is a [[Person]] or [[Organization]] that manages contributions to, and/or publication of, some (typically complex) artifact. It is common for distributions of software and data to be based on \"upstream\" sources. When [[maintainer]] is applied to a specific version of something e.g. a particular version or packaging of a [[Dataset]], it is always  possible that the upstream source has a different maintainer. The [[isBasedOn]] property can be used to indicate such relationships between datasets to make the different maintenance roles clear. Similarly in the case of software, a package may have dedicated maintainers working on integration into software distributions such as Ubuntu, as well as upstream maintainers of the underlying work.\\n      ',\n", "    'rdfs:label': 'maintainer',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:isPartOf': {'@id': 'https://pending.schema.org'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:Organization'},\n", "     {'@id': 'schema:Person'}],\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/2311'}},\n", "   {'@id': 'schema:educationalAlignment',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'An alignment to an established educational framework.\\n\\nThis property should not be used where the nature of the alignment can be described using a simple property, for example to express that a resource [[teaches]] or [[assesses]] a competency.',\n", "    'rdfs:label': 'educationalAlignment',\n", "    'schema:domainIncludes': [{'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:LearningResource'}],\n", "    'schema:rangeIncludes': {'@id': 'schema:AlignmentObject'}},\n", "   {'@id': 'schema:comment',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'Comments, typically from users.',\n", "    'rdfs:label': 'comment',\n", "    'schema:domainIncludes': [{'@id': 'schema:RsvpAction'},\n", "     {'@id': 'schema:CreativeWork'}],\n", "    'schema:rangeIncludes': {'@id': 'schema:Comment'}},\n", "   {'@id': 'schema:associatedMedia',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'A media object that encodes this CreativeWork. This property is a synonym for encoding.',\n", "    'rdfs:label': 'associatedMedia',\n", "    'schema:domainIncludes': [{'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:HyperToc'},\n", "     {'@id': 'schema:HyperTocEntry'}],\n", "    'schema:rangeIncludes': {'@id': 'schema:MediaObject'}},\n", "   {'@id': 'schema:identifier',\n", "    '@type': 'rdf:Property',\n", "    'owl:equivalentProperty': {'@id': 'dcterms:identifier'},\n", "    'rdfs:comment': 'The identifier property represents any kind of identifier for any kind of [[Thing]], such as ISBNs, GTIN codes, UUIDs etc. Schema.org provides dedicated properties for representing many of these, either as textual strings or as URL (URI) links. See [background notes](/docs/datamodel.html#identifierBg) for more details.\\n        ',\n", "    'rdfs:label': 'identifier',\n", "    'schema:domainIncludes': {'@id': 'schema:Thing'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:URL'},\n", "     {'@id': 'schema:PropertyValue'},\n", "     {'@id': 'schema:Text'}]},\n", "   {'@id': 'schema:usageInfo',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'The schema.org [[usageInfo]] property indicates further information about a [[CreativeWork]]. This property is applicable both to works that are freely available and to those that require payment or other transactions. It can reference additional information, e.g. community expectations on preferred linking and citation conventions, as well as purchasing details. For something that can be commercially licensed, usageInfo can provide detailed, resource-specific information about licensing options.\\n\\nThis property can be used alongside the license property which indicates license(s) applicable to some piece of content. The usageInfo property can provide information about other licensing options, e.g. acquiring commercial usage rights for an image that is also available under non-commercial creative commons licenses.',\n", "    'rdfs:label': 'usageInfo',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:isPartOf': {'@id': 'https://pending.schema.org'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:URL'}],\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/2454'}},\n", "   {'@id': 'schema:producer',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'The person or organization who produced the work (e.g. music album, movie, TV/radio series etc.).',\n", "    'rdfs:label': 'producer',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:Person'},\n", "     {'@id': 'schema:Organization'}]},\n", "   {'@id': 'schema:headline',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'Headline of the article.',\n", "    'rdfs:label': 'headline',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': {'@id': 'schema:Text'}},\n", "   {'@id': 'schema:includedInDataCatalog',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'A data catalog which contains this dataset.',\n", "    'rdfs:label': 'includedInDataCatalog',\n", "    'schema:domainIncludes': {'@id': 'schema:Dataset'},\n", "    'schema:inverseOf': {'@id': 'schema:dataset'},\n", "    'schema:rangeIncludes': {'@id': 'schema:DataCatalog'}},\n", "   {'@id': 'schema:sdLicense',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'A license document that applies to this structured data, typically indicated by URL.',\n", "    'rdfs:label': 'sdLicense',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:isPartOf': {'@id': 'https://pending.schema.org'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:URL'},\n", "     {'@id': 'schema:CreativeWork'}],\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/1886'}},\n", "   {'@id': 'schema:thumbnail',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'Thumbnail image for an image or video.',\n", "    'rdfs:label': 'thumbnail',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': {'@id': 'schema:ImageObject'}},\n", "   {'@id': 'schema:interpretedAsClaim',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'Used to indicate a specific claim contained, implied, translated or refined from the content of a [[MediaObject]] or other [[CreativeWork]]. The interpreting party can be indicated using [[claimInterpreter]].',\n", "    'rdfs:label': 'interpretedAsClaim',\n", "    'rdfs:subPropertyOf': {'@id': 'schema:description'},\n", "    'schema:domainIncludes': [{'@id': 'schema:MediaObject'},\n", "     {'@id': 'schema:CreativeWork'}],\n", "    'schema:isPartOf': {'@id': 'https://pending.schema.org'},\n", "    'schema:rangeIncludes': {'@id': 'schema:Claim'},\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/2450'}},\n", "   {'@id': 'schema:expires',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'Date the content expires and is no longer useful or available. For example a [[VideoObject]] or [[NewsArticle]] whose availability or relevance is time-limited, a [[ClaimReview]] fact check whose publisher wants to indicate that it may no longer be relevant (or helpful to highlight) after some date, or a [[Certification]] the validity has expired.',\n", "    'rdfs:label': 'expires',\n", "    'schema:domainIncludes': [{'@id': 'schema:Certification'},\n", "     {'@id': 'schema:CreativeWork'}],\n", "    'schema:rangeIncludes': [{'@id': 'schema:Date'},\n", "     {'@id': 'schema:DateTime'}]},\n", "   {'@id': 'schema:fileFormat',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': \"Media type, typically MIME format (see [IANA site](http://www.iana.org/assignments/media-types/media-types.xhtml)) of the content, e.g. application/zip of a SoftwareApplication binary. In cases where a CreativeWork has several media type representations, 'encoding' can be used to indicate each MediaObject alongside particular fileFormat information. Unregistered or niche file formats can be indicated instead via the most appropriate URL, e.g. defining Web page or a Wikipedia entry.\",\n", "    'rdfs:label': 'fileFormat',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:URL'}, {'@id': 'schema:Text'}],\n", "    'schema:supersededBy': {'@id': 'schema:encodingFormat'}},\n", "   {'@id': 'schema:alternativeHeadline',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'A secondary title of the CreativeWork.',\n", "    'rdfs:label': 'alternativeHeadline',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': {'@id': 'schema:Text'}},\n", "   {'@id': 'schema:sdDatePublished',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'Indicates the date on which the current structured data was generated / published. Typically used alongside [[sdPublisher]].',\n", "    'rdfs:label': 'sdDatePublished',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:isPartOf': {'@id': 'https://pending.schema.org'},\n", "    'schema:rangeIncludes': {'@id': 'schema:Date'},\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/1886'}},\n", "   {'@id': 'schema:editEIDR',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'An [EIDR](https://eidr.org/) (Entertainment Identifier Registry) [[identifier]] representing a specific edit / edition for a work of film or television.\\n\\nFor example, the motion picture known as \"Ghostbusters\" whose [[titleEIDR]] is \"10.5240/7EC7-228A-510A-053E-CBB8-J\" has several edits, e.g. \"10.5240/1F2A-E1C5-680A-14C6-E76B-I\" and \"10.5240/8A35-3BEE-6497-5D12-9E4F-3\".\\n\\nSince schema.org types like [[Movie]] and [[TVEpisode]] can be used for both works and their multiple expressions, it is possible to use [[titleEIDR]] alone (for a general description), or alongside [[editEIDR]] for a more edit-specific description.\\n',\n", "    'rdfs:label': 'editEIDR',\n", "    'rdfs:subPropertyOf': {'@id': 'schema:identifier'},\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:isPartOf': {'@id': 'https://pending.schema.org'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:Text'}, {'@id': 'schema:URL'}],\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/2469'}},\n", "   {'@id': 'schema:correction',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'Indicates a correction to a [[CreativeWork]], either via a [[CorrectionComment]], textually or in another document.',\n", "    'rdfs:label': 'correction',\n", "    'schema:contributor': {'@id': 'https://schema.org/docs/collab/TP'},\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:isPartOf': {'@id': 'https://pending.schema.org'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:URL'},\n", "     {'@id': 'schema:CorrectionComment'},\n", "     {'@id': 'schema:Text'}],\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/1950'}},\n", "   {'@id': 'schema:audio',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'An embedded audio object.',\n", "    'rdfs:label': 'audio',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:Clip'},\n", "     {'@id': 'schema:AudioObject'},\n", "     {'@id': 'schema:MusicRecording'}],\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/2420'}},\n", "   {'@id': 'schema:dateCreated',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'The date on which the CreativeWork was created or the item was added to a DataFeed.',\n", "    'rdfs:label': 'dateCreated',\n", "    'schema:domainIncludes': [{'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:DataFeedItem'}],\n", "    'schema:rangeIncludes': [{'@id': 'schema:DateTime'},\n", "     {'@id': 'schema:Date'}]},\n", "   {'@id': 'schema:reviews',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'Review of the item.',\n", "    'rdfs:label': 'reviews',\n", "    'schema:domainIncludes': [{'@id': 'schema:Place'},\n", "     {'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:Organization'},\n", "     {'@id': 'schema:Offer'},\n", "     {'@id': 'schema:Product'}],\n", "    'schema:rangeIncludes': {'@id': 'schema:Review'},\n", "    'schema:supersededBy': {'@id': 'schema:review'}},\n", "   {'@id': 'schema:publisher',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'The publisher of the creative work.',\n", "    'rdfs:label': 'publisher',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:Organization'},\n", "     {'@id': 'schema:Person'}]},\n", "   {'@id': 'schema:disambiguatingDescription',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'A sub property of description. A short description of the item used to disambiguate from other, similar items. Information from other properties (in particular, name) may be necessary for the description to be useful for disambiguation.',\n", "    'rdfs:label': 'disambiguatingDescription',\n", "    'rdfs:subPropertyOf': {'@id': 'schema:description'},\n", "    'schema:domainIncludes': {'@id': 'schema:Thing'},\n", "    'schema:rangeIncludes': {'@id': 'schema:Text'}},\n", "   {'@id': 'schema:discussionUrl',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'A link to the page containing the comments of the CreativeWork.',\n", "    'rdfs:label': 'discussionUrl',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': {'@id': 'schema:URL'}},\n", "   {'@id': 'schema:provider',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'The service provider, service operator, or service performer; the goods producer. Another party (a seller) may offer those services or goods on behalf of the provider. A provider may also serve as the seller.',\n", "    'rdfs:label': 'provider',\n", "    'schema:domainIncludes': [{'@id': 'schema:Trip'},\n", "     {'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:Reservation'},\n", "     {'@id': 'schema:Invoice'},\n", "     {'@id': 'schema:ParcelDelivery'},\n", "     {'@id': 'schema:Service'},\n", "     {'@id': 'schema:Action'},\n", "     {'@id': 'schema:EducationalOccupationalProgram'}],\n", "    'schema:isPartOf': {'@id': 'https://pending.schema.org'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:Organization'},\n", "     {'@id': 'schema:Person'}],\n", "    'sch", "\n========== TRUNCATED ==========\n", "ty',\n", "    'rdfs:comment': 'The year during which the claimed copyright for the CreativeWork was first asserted.',\n", "    'rdfs:label': 'copyrightYear',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': {'@id': 'schema:Number'}},\n", "   {'@id': 'schema:license',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'A license document that applies to this content, typically indicated by URL.',\n", "    'rdfs:label': 'license',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:URL'},\n", "     {'@id': 'schema:CreativeWork'}]},\n", "   {'@id': 'schema:size',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': \"A standardized size of a product or creative work, specified either through a simple textual string (for example 'XL', '32Wx34L'), a  QuantitativeValue with a unitCode, or a comprehensive and structured [[SizeSpecification]]; in other cases, the [[width]], [[height]], [[depth]] and [[weight]] properties may be more applicable. \",\n", "    'rdfs:label': 'size',\n", "    'schema:domainIncludes': [{'@id': 'schema:Product'},\n", "     {'@id': 'schema:CreativeWork'}],\n", "    'schema:isPartOf': {'@id': 'https://pending.schema.org'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:Text'},\n", "     {'@id': 'schema:QuantitativeValue'},\n", "     {'@id': 'schema:DefinedTerm'},\n", "     {'@id': 'schema:SizeSpecification'}],\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/1797'}},\n", "   {'@id': 'schema:isPartOf',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'Indicates an item or CreativeWork that this item, or CreativeWork (in some sense), is part of.',\n", "    'rdfs:label': 'isPartOf',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:inverseOf': {'@id': 'schema:hasPart'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:URL'}]},\n", "   {'@id': 'schema:measurementTechnique',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'A technique, method or technology used in an [[Observation]], [[StatisticalVariable]] or [[Dataset]] (or [[DataDownload]], [[DataCatalog]]), corresponding to the method used for measuring the corresponding variable(s) (for datasets, described using [[variableMeasured]]; for [[Observation]], a [[StatisticalVariable]]). Often but not necessarily each [[variableMeasured]] will have an explicit representation as (or mapping to) an property such as those defined in Schema.org, or other RDF vocabularies and \"knowledge graphs\". In that case the subproperty of [[variableMeasured]] called [[measuredProperty]] is applicable.\\n    \\nThe [[measurementTechnique]] property helps when extra clarification is needed about how a [[measuredProperty]] was measured. This is oriented towards scientific and scholarly dataset publication but may have broader applicability; it is not intended as a full representation of measurement, but can often serve as a high level summary for dataset discovery. \\n\\nFor example, if [[variableMeasured]] is: molecule concentration, [[measurementTechnique]] could be: \"mass spectrometry\" or \"nmr spectroscopy\" or \"colorimetry\" or \"immunofluorescence\". If the [[variableMeasured]] is \"depression rating\", the [[measurementTechnique]] could be \"Zung Scale\" or \"HAM-D\" or \"Beck Depression Inventory\". \\n\\nIf there are several [[variableMeasured]] properties recorded for some given data object, use a [[PropertyValue]] for each [[variableMeasured]] and attach the corresponding [[measurementTechnique]]. The value can also be from an enumeration, organized as a [[MeasurementMetholdEnumeration]].',\n", "    'rdfs:label': 'measurementTechnique',\n", "    'schema:domainIncludes': [{'@id': 'schema:Dataset'},\n", "     {'@id': 'schema:DataCatalog'},\n", "     {'@id': 'schema:Observation'},\n", "     {'@id': 'schema:DataDownload'},\n", "     {'@id': 'schema:StatisticalVariable'},\n", "     {'@id': 'schema:PropertyValue'}],\n", "    'schema:isPartOf': {'@id': 'https://pending.schema.org'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:URL'},\n", "     {'@id': 'schema:Text'},\n", "     {'@id': 'schema:MeasurementMethodEnum'},\n", "     {'@id': 'schema:DefinedTerm'}],\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/1425'}},\n", "   {'@id': 'schema:contentLocation',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'The location depicted or described in the content. For example, the location in a photograph or painting.',\n", "    'rdfs:label': 'contentLocation',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': {'@id': 'schema:Place'}},\n", "   {'@id': 'schema:encodings',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'A media object that encodes this CreativeWork.',\n", "    'rdfs:label': 'encodings',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': {'@id': 'schema:MediaObject'},\n", "    'schema:supersededBy': {'@id': 'schema:encoding'}},\n", "   {'@id': 'schema:digitalSourceType',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'Indicates an IPTCDigitalSourceEnumeration code indicating the nature of the digital source(s) for some [[CreativeWork]].',\n", "    'rdfs:label': 'digitalSourceType',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:isPartOf': {'@id': 'https://pending.schema.org'},\n", "    'schema:rangeIncludes': {'@id': 'schema:IPTCDigitalSourceEnumeration'},\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/3392'}},\n", "   {'@id': 'schema:releasedEvent',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'The place and time the release was issued, expressed as a PublicationEvent.',\n", "    'rdfs:label': 'releasedEvent',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': {'@id': 'schema:PublicationEvent'}},\n", "   {'@id': 'schema:creator',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'The creator/author of this CreativeWork. This is the same as the Author property for CreativeWork.',\n", "    'rdfs:label': 'creator',\n", "    'schema:domainIncludes': [{'@id': 'schema:UserComments'},\n", "     {'@id': 'schema:CreativeWork'}],\n", "    'schema:rangeIncludes': [{'@id': 'schema:Person'},\n", "     {'@id': 'schema:Organization'}]},\n", "   {'@id': 'schema:sourceOrganization',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'The Organization on whose behalf the creator was working.',\n", "    'rdfs:label': 'sourceOrganization',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': {'@id': 'schema:Organization'}},\n", "   {'@id': 'schema:accountablePerson',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'Specifies the Person that is legally accountable for the CreativeWork.',\n", "    'rdfs:label': 'accountablePerson',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': {'@id': 'schema:Person'}},\n", "   {'@id': 'schema:text',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'The textual content of this CreativeWork.',\n", "    'rdfs:label': 'text',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': {'@id': 'schema:Text'}},\n", "   {'@id': 'schema:url',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'URL of the item.',\n", "    'rdfs:label': 'url',\n", "    'schema:domainIncludes': {'@id': 'schema:Thing'},\n", "    'schema:rangeIncludes': {'@id': 'schema:URL'}},\n", "   {'@id': 'schema:pattern',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': \"A pattern that something has, for example 'polka dot', 'striped', 'Canadian flag'. Values are typically expressed as text, although links to controlled value schemes are also supported.\",\n", "    'rdfs:label': 'pattern',\n", "    'schema:domainIncludes': [{'@id': 'schema:Product'},\n", "     {'@id': 'schema:CreativeWork'}],\n", "    'schema:isPartOf': {'@id': 'https://pending.schema.org'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:DefinedTerm'},\n", "     {'@id': 'schema:Text'}],\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/1797'}},\n", "   {'@id': 'schema:schemaVersion',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'Indicates (by URL or string) a particular version of a schema used in some CreativeWork. This property was created primarily to\\n    indicate the use of a specific schema.org release, e.g. ```10.0``` as a simple string, or more explicitly via URL, ```https://schema.org/docs/releases.html#v10.0```. There may be situations in which other schemas might usefully be referenced this way, e.g. ```http://dublincore.org/specifications/dublin-core/dces/1999-07-02/``` but this has not been carefully explored in the community.',\n", "    'rdfs:label': 'schemaVersion',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:Text'}, {'@id': 'schema:URL'}]},\n", "   {'@id': 'schema:character',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'Fictional person connected with a creative work.',\n", "    'rdfs:label': 'character',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': {'@id': 'schema:Person'}},\n", "   {'@id': 'schema:review',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'A review of the item.',\n", "    'rdfs:label': 'review',\n", "    'schema:domainIncludes': [{'@id': 'schema:Event'},\n", "     {'@id': 'schema:Product'},\n", "     {'@id': 'schema:Service'},\n", "     {'@id': 'schema:Place'},\n", "     {'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:Organization'},\n", "     {'@id': 'schema:Brand'},\n", "     {'@id': 'schema:Offer'}],\n", "    'schema:rangeIncludes': {'@id': 'schema:Review'}},\n", "   {'@id': 'schema:Thing',\n", "    '@type': 'rdfs:Class',\n", "    'rdfs:comment': 'The most generic type of item.',\n", "    'rdfs:label': 'Thing'},\n", "   {'@id': 'schema:mainEntityOfPage',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'Indicates a page (or other CreativeWork) for which this thing is the main entity being described. See [background notes](/docs/datamodel.html#mainEntityBackground) for details.',\n", "    'rdfs:label': 'mainEntityOfPage',\n", "    'schema:domainIncludes': {'@id': 'schema:Thing'},\n", "    'schema:inverseOf': {'@id': 'schema:mainEntity'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:URL'}]},\n", "   {'@id': 'schema:distribution',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'A downloadable form of this dataset, at a specific location, in a specific format. This property can be repeated if different variations are available. There is no expectation that different downloadable distributions must contain exactly equivalent information (see also [DCAT](https://www.w3.org/TR/vocab-dcat-3/#Class:Distribution) on this point). Different distributions might include or exclude different subsets of the entire dataset, for example.',\n", "    'rdfs:label': 'distribution',\n", "    'schema:domainIncludes': {'@id': 'schema:Dataset'},\n", "    'schema:rangeIncludes': {'@id': 'schema:DataDownload'}},\n", "   {'@id': 'schema:sameAs',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': \"URL of a reference Web page that unambiguously indicates the item's identity. E.g. the URL of the item's Wikipedia page, Wikidata entry, or official website.\",\n", "    'rdfs:label': 'sameAs',\n", "    'schema:domainIncludes': {'@id': 'schema:Thing'},\n", "    'schema:rangeIncludes': {'@id': 'schema:URL'}},\n", "   {'@id': 'schema:exampleOfWork',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'A creative work that this work is an example/instance/realization/derivation of.',\n", "    'rdfs:label': 'exampleOfWork',\n", "    'schema:contributor': {'@id': 'https://schema.org/docs/collab/bibex'},\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:inverseOf': {'@id': 'schema:workExample'},\n", "    'schema:rangeIncludes': {'@id': 'schema:CreativeWork'}},\n", "   {'@id': 'schema:material',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'A material that something is made from, e.g. leather, wool, cotton, paper.',\n", "    'rdfs:label': 'material',\n", "    'schema:domainIncludes': [{'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:Product'}],\n", "    'schema:rangeIncludes': [{'@id': 'schema:Product'},\n", "     {'@id': 'schema:Text'},\n", "     {'@id': 'schema:URL'}]},\n", "   {'@id': 'schema:materialExtent',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': {'@language': 'en',\n", "     '@value': 'The quantity of the materials being described or an expression of the physical space they occupy.'},\n", "    'rdfs:label': {'@language': 'en', '@value': 'materialExtent'},\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:isPartOf': {'@id': 'https://pending.schema.org'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:QuantitativeValue'},\n", "     {'@id': 'schema:Text'}],\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/1759'}},\n", "   {'@id': 'schema:image',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'An image of the item. This can be a [[URL]] or a fully described [[ImageObject]].',\n", "    'rdfs:label': 'image',\n", "    'schema:domainIncludes': {'@id': 'schema:Thing'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:ImageObject'},\n", "     {'@id': 'schema:URL'}]},\n", "   {'@id': 'schema:educationalUse',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': \"The purpose of a work in the context of education; for example, 'assignment', 'group work'.\",\n", "    'rdfs:label': 'educationalUse',\n", "    'schema:domainIncludes': [{'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:LearningResource'}],\n", "    'schema:rangeIncludes': [{'@id': 'schema:DefinedTerm'},\n", "     {'@id': 'schema:Text'}]},\n", "   {'@id': 'schema:audience',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'An intended audience, i.e. a group for whom something was created.',\n", "    'rdfs:label': 'audience',\n", "    'schema:domainIncludes': [{'@id': 'schema:LodgingBusiness'},\n", "     {'@id': 'schema:PlayAction'},\n", "     {'@id': 'schema:Service'},\n", "     {'@id': 'schema:Event'},\n", "     {'@id': 'schema:Product'},\n", "     {'@id': 'schema:CreativeWork'}],\n", "    'schema:rangeIncludes': {'@id': 'schema:Audience'}},\n", "   {'@id': 'schema:isAccessibleForFree',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'A flag to signal that the item, event, or place is accessible for free.',\n", "    'rdfs:label': 'isAccessibleForFree',\n", "    'schema:domainIncludes': [{'@id': 'schema:Place'},\n", "     {'@id': 'schema:Event'},\n", "     {'@id': 'schema:CreativeWork'}],\n", "    'schema:rangeIncludes': {'@id': 'schema:Boolean'}},\n", "   {'@id': 'schema:name',\n", "    '@type': 'rdf:Property',\n", "    'owl:equivalentProperty': {'@id': 'dcterms:title'},\n", "    'rdfs:comment': 'The name of the item.',\n", "    'rdfs:label': 'name',\n", "    'rdfs:subPropertyOf': {'@id': 'rdfs:label'},\n", "    'schema:domainIncludes': {'@id': 'schema:Thing'},\n", "    'schema:rangeIncludes': {'@id': 'schema:Text'}},\n", "   {'@id': 'schema:CreativeWork',\n", "    '@type': 'rdfs:Class',\n", "    'rdfs:comment': 'The most generic kind of creative work, including books, movies, photographs, software programs, etc.',\n", "    'rdfs:label': 'CreativeWork',\n", "    'rdfs:subClassOf': {'@id': 'schema:Thing'},\n", "    'schema:contributor': {'@id': 'https://schema.org/docs/collab/rNews'}},\n", "   {'@id': 'schema:accessibilityFeature',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'Content features of the resource, such as accessible media, alternatives and supported enhancements for accessibility. Values should be drawn from the [approved vocabulary](https://www.w3.org/2021/a11y-discov-vocab/latest/#accessibilityFeature-vocabulary).',\n", "    'rdfs:label': 'accessibilityFeature',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': {'@id': 'schema:Text'}},\n", "   {'@id': 'schema:dateModified',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': \"The date on which the CreativeWork was most recently modified or when the item's entry was modified within a DataFeed.\",\n", "    'rdfs:label': 'dateModified',\n", "    'schema:domainIncludes': [{'@id': 'schema:DataFeedItem'},\n", "     {'@id': 'schema:CreativeWork'}],\n", "    'schema:rangeIncludes': [{'@id': 'schema:DateTime'},\n", "     {'@id': 'schema:Date'}]},\n", "   {'@id': 'schema:alternateName',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'An alias for the item.',\n", "    'rdfs:label': 'alternateName',\n", "    'schema:domainIncludes': {'@id': 'schema:Thing'},\n", "    'schema:rangeIncludes': {'@id': 'schema:Text'}},\n", "   {'@id': 'schema:subjectOf',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'A CreativeWork or Event about this Thing.',\n", "    'rdfs:label': 'subjectOf',\n", "    'schema:domainIncludes': {'@id': 'schema:Thing'},\n", "    'schema:inverseOf': {'@id': 'schema:about'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:Event'},\n", "     {'@id': 'schema:CreativeWork'}],\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/1670'}},\n", "   {'@id': 'schema:accessibilitySummary',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'A human-readable summary of specific accessibility features or deficiencies, consistent with the other accessibility metadata but expressing subtleties such as \"short descriptions are present but long descriptions will be needed for non-visual users\" or \"short descriptions are present and no long descriptions are needed\".',\n", "    'rdfs:label': 'accessibilitySummary',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': {'@id': 'schema:Text'},\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/1100'}},\n", "   {'@id': 'schema:countryOfOrigin',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'The country of origin of something, including products as well as creative  works such as movie and TV content.\\n\\nIn the case of TV and movie, this would be the country of the principle offices of the production company or individual responsible for the movie. For other kinds of [[CreativeWork]] it is difficult to provide fully general guidance, and properties such as [[contentLocation]] and [[locationCreated]] may be more applicable.\\n\\nIn the case of products, the country of origin of the product. The exact interpretation of this may vary by context and product type, and cannot be fully enumerated here.',\n", "    'rdfs:label': 'countryOfOrigin',\n", "    'schema:domainIncludes': [{'@id': 'schema:Product'},\n", "     {'@id': 'schema:TVEpisode'},\n", "     {'@id': 'schema:TVSeries'},\n", "     {'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:Movie'},\n", "     {'@id': 'schema:TVSeason'}],\n", "    'schema:rangeIncludes': {'@id': 'schema:Country'}},\n", "   {'@id': 'schema:accessModeSufficient',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'A list of single or combined accessModes that are sufficient to understand all the intellectual content of a resource. Values should be drawn from the [approved vocabulary](https://www.w3.org/2021/a11y-discov-vocab/latest/#accessModeSufficient-vocabulary).',\n", "    'rdfs:label': 'accessModeSufficient',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': {'@id': 'schema:ItemList'},\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/1100'}},\n", "   {'@id': 'schema:issn',\n", "    '@type': 'rdf:Property',\n", "    'owl:equivalentProperty': {'@id': 'http://purl.org/ontology/bibo/issn'},\n", "    'rdfs:comment': 'The International Standard Serial Number (ISSN) that identifies this serial publication. You can repeat this property to identify different formats of, or the linking ISSN (ISSN-L) for, this serial publication.',\n", "    'rdfs:label': 'issn',\n", "    'rdfs:subPropertyOf': {'@id': 'schema:identifier'},\n", "    'schema:contributor': {'@id': 'https://schema.org/docs/collab/bibex'},\n", "    'schema:domainIncludes': [{'@id': 'schema:Dataset'},\n", "     {'@id': 'schema:Blog'},\n", "     {'@id': 'schema:WebSite'},\n", "     {'@id': 'schema:CreativeWorkSeries'}],\n", "    'schema:rangeIncludes': {'@id': 'schema:Text'}},\n", "   {'@id': 'schema:about',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'The subject matter of the content.',\n", "    'rdfs:label': 'about',\n", "    'schema:domainIncludes': [{'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:CommunicateAction'},\n", "     {'@id': 'schema:Event'},\n", "     {'@id': 'schema:Certification'}],\n", "    'schema:inverseOf': {'@id': 'schema:subjectOf'},\n", "    'schema:rangeIncludes': {'@id': 'schema:Thing'},\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/1670'}},\n", "   {'@id': 'schema:accessibilityHazard',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'A characteristic of the described resource that is physiologically dangerous to some users. Related to WCAG 2.0 guideline 2.3. Values should be drawn from the [approved vocabulary](https://www.w3.org/2021/a11y-discov-vocab/latest/#accessibilityHazard-vocabulary).',\n", "    'rdfs:label': 'accessibilityHazard',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': {'@id': 'schema:Text'}},\n", "   {'@id': 'schema:citation',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'A citation or reference to another creative work, such as another publication, web page, scholarly article, etc.',\n", "    'rdfs:label': 'citation',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:Text'}]},\n", "   {'@id': 'schema:measurementMethod',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'A subproperty of [[measurementTechnique]] that can be used for specifying specific methods, in particular via [[MeasurementMethodEnum]].',\n", "    'rdfs:label': 'measurementMethod',\n", "    'rdfs:subPropertyOf': {'@id': 'schema:measurementTechnique'},\n", "    'schema:domainIncludes': [{'@id': 'schema:StatisticalVariable'},\n", "     {'@id': 'schema:PropertyValue'},\n", "     {'@id': 'schema:Dataset'},\n", "     {'@id': 'schema:DataCatalog'},\n", "     {'@id': 'schema:Observation'},\n", "     {'@id': 'schema:DataDownload'}],\n", "    'schema:isPartOf': {'@id': 'https://pending.schema.org'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:URL'},\n", "     {'@id': 'schema:Text'},\n", "     {'@id': 'schema:MeasurementMethodEnum'},\n", "     {'@id': 'schema:DefinedTerm'}],\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/1425'}},\n", "   {'@id': 'schema:interactivityType',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': \"The predominant mode of learning supported by the learning resource. Acceptable values are 'active', 'expositive', or 'mixed'.\",\n", "    'rdfs:label': 'interactivityType',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': {'@id': 'schema:Text'}},\n", "   {'@id': 'schema:version',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'The version of the CreativeWork embodied by a specified resource.',\n", "    'rdfs:label': 'version',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:Number'},\n", "     {'@id': 'schema:Text'}]},\n", "   {'@id': 'schema:interactionStatistic',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'The number of interactions for the CreativeWork using the WebSite or SoftwareApplication. The most specific child type of InteractionCounter should be used.',\n", "    'rdfs:label': 'interactionStatistic',\n", "    'schema:domainIncludes': [{'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:Person'},\n", "     {'@id': 'schema:Organization'}],\n", "    'schema:rangeIncludes': {'@id': 'schema:InteractionCounter'},\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/2421'}},\n", "   {'@id': 'schema:translationOfWork',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'The work that this work has been translated from. E.g. \u7269\u79cd\u8d77\u6e90 is a translationOf \u201cOn the Origin of Species\u201d.',\n", "    'rdfs:label': 'translationOfWork',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:inverseOf': {'@id': 'schema:workTranslation'},\n", "    'schema:isPartOf': {'@id': 'https://bib.schema.org'},\n", "    'schema:rangeIncludes': {'@id': 'schema:CreativeWork'}},\n", "   {'@id': 'schema:commentCount',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'The number of comments this CreativeWork (e.g. Article, Question or Answer) has received. This is most applicable to works published in Web sites with commenting system; additional comments may exist elsewhere.',\n", "    'rdfs:label': 'commentCount',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': {'@id': 'schema:Integer'}},\n", "   {'@id': 'schema:genre',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'Genre of the creative work, broadcast channel or group.',\n", "    'rdfs:label': 'genre',\n", "    'schema:domainIncludes': [{'@id': 'schema:MusicGroup'},\n", "     {'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:BroadcastChannel'}],\n", "    'schema:rangeIncludes': [{'@id': 'schema:Text'}, {'@id': 'schema:URL'}]},\n", "   {'@id': 'schema:accessMode',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'The human sensory perceptual system or cognitive faculty through which a person may process or perceive information. Values should be drawn from the [approved vocabulary](https://www.w3.org/2021/a11y-discov-vocab/latest/#accessMode-vocabulary).',\n", "    'rdfs:label': 'accessMode',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': {'@id': 'schema:Text'},\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/1100'}},\n", "   {'@id': 'schema:datasetTimeInterval',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'The range of temporal applicability of a dataset, e.g. for a 2011 census dataset, the year 2011 (in ISO 8601 time interval format).',\n", "    'rdfs:label': 'datasetTimeInterval',\n", "    'schema:domainIncludes': {'@id': 'schema:Dataset'},\n", "    'schema:rangeIncludes': {'@id': 'schema:DateTime'},\n", "    'schema:supersededBy': {'@id': 'schema:temporalCoverage'}},\n", "   {'@id': 'schema:awards',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'Awards won by or for this item.',\n", "    'rdfs:label': 'awards',\n", "    'schema:domainIncludes': [{'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:Person'},\n", "     {'@id': 'schema:Product'},\n", "     {'@id': 'schema:Organization'}],\n", "    'schema:rangeIncludes': {'@id': 'schema:Text'},\n", "    'schema:supersededBy': {'@id': 'schema:award'}},\n", "   {'@id': 'schema:offers',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'An offer to provide this item&#x2014;for example, an offer to sell a product, rent the DVD of a movie, perform a service, or give away tickets to an event. Use [[businessFunction]] to indicate the kind of transaction offered, i.e. sell, lease, etc. This property can also be used to describe a [[Demand]]. While this property is listed as expected on a number of common types, it can be used in others. In that case, using a second type, such as Product or a subtype of Product, can clarify the nature of the offer.\\n      ',\n", "    'rdfs:label': 'offers',\n", "    'schema:domainIncludes': [{'@id': 'schema:Trip'},\n", "     {'@id': 'schema:AggregateOffer'},\n", "     {'@id': 'schema:Service'},\n", "     {'@id': 'schema:Event'},\n", "     {'@id': 'schema:Product'},\n", "     {'@id': 'schema:MenuItem'},\n", "     {'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:EducationalOccupationalProgram'}],\n", "    'schema:inverseOf': {'@id': 'schema:itemOffered'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:Offer'},\n", "     {'@id': 'schema:Demand'}],\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/2289'}},\n", "   {'@id': 'schema:temporalCoverage',\n", "    '@type': 'rdf:Property',\n", "    'owl:equivalentProperty': {'@id': 'dcterms:temporal'},\n", "    'rdfs:comment': 'The temporalCoverage of a CreativeWork indicates the period that the content applies to, i.e. that it describes, either as a DateTime or as a textual string indicating a time period in [ISO 8601 time interval format](https://en.wikipedia.org/wiki/ISO_8601#Time_intervals). In\\n      the case of a Dataset it will typically indicate the relevant time period in a precise notation (e.g. for a 2011 census dataset, the year 2011 would be written \"2011/2012\"). Other forms of content, e.g. ScholarlyArticle, Book, TVSeries or TVEpisode, may indicate their temporalCoverage in broader terms - textually or via well-known URL.\\n      Written works such as books may sometimes have precise temporal coverage too, e.g. a work set in 1939 - 1945 can be indicated in ISO 8601 interval format format via \"1939/1945\".\\n\\nOpen-ended date ranges can be written with \"..\" in place of the end date. For example, \"2015-11/..\" indicates a range beginning in November 2015 and with no specified final date. This is tentative and might be updated in future when ISO 8601 is officially updated.',\n", "    'rdfs:label': 'temporalCoverage',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:DateTime'},\n", "     {'@id': 'schema:Text'},\n", "     {'@id': 'schema:URL'}]},\n", "   {'@id': 'schema:funder',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'A person or organization that supports (sponsors) something through some kind of financial contribution.',\n", "    'rdfs:label': 'funder',\n", "    'rdfs:subPropertyOf': {'@id': 'schema:sponsor'},\n", "    'schema:domainIncludes': [{'@id': 'schema:Person'},\n", "     {'@id': 'schema:Event'},\n", "     {'@id': 'schema:Organization'},\n", "     {'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:Grant'},\n", "     {'@id': 'schema:MonetaryGrant'}],\n", "    'schema:rangeIncludes': [{'@id': 'schema:Organization'},\n", "     {'@id': 'schema:Person'}]},\n", "   {'@id': 'schema:typicalAgeRange',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': \"The typical expected age range, e.g. '7-9', '11-'.\",\n", "    'rdfs:label': 'typicalAgeRange',\n", "    'schema:domainIncludes': [{'@id': 'schema:Event'},\n", "     {'@id': 'schema:CreativeWork'}],\n", "    'schema:rangeIncludes': {'@id': 'schema:Text'}},\n", "   {'@id': 'schema:description',\n", "    '@type': 'rdf:Property',\n", "    'owl:equivalentProperty': {'@id': 'dcterms:description'},\n", "    'rdfs:comment': 'A description of the item.',\n", "    'rdfs:label': 'description',\n", "    'schema:domainIncludes': {'@id': 'schema:Thing'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:Text'},\n", "     {'@id': 'schema:TextObject'}]},\n", "   {'@id': 'schema:variablesMeasured',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'Originally named [[variablesMeasured]], the [[variableMeasured]] property can indicate (repeated as necessary) the  variables that are measured in some dataset, either described as text or as pairs of identifier and description using PropertyValue.',\n", "    'rdfs:label': 'variablesMeasured',\n", "    'schema:domainIncludes': {'@id': 'schema:Dataset'},\n", "    'schema:isPartOf': {'@id': 'https://attic.schema.org'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:PropertyValue'},\n", "     {'@id': 'schema:Text'}]},\n", "   {'@id': 'schema:keywords',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'Keywords or tags used to describe some item. Multiple textual entries in a keywords list are typically delimited by commas, or by repeating the property.',\n", "    'rdfs:label': 'keywords',\n", "    'schema:domainIncludes': [{'@id': 'schema:Event'},\n", "     {'@id': 'schema:Product'},\n", "     {'@id': 'schema:Place'},\n", "     {'@id': 'schema:CreativeWork'},\n", "     {'@id': 'schema:Organization'}],\n", "    'schema:rangeIncludes': [{'@id': 'schema:URL'},\n", "     {'@id': 'schema:Text'},\n", "     {'@id': 'schema:DefinedTerm'}]},\n", "   {'@id': 'schema:archivedAt',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'Indicates a page or other link involved in archival of a [[CreativeWork]]. In the case of [[MediaReview]], the items in a [[MediaReviewItem]] may often become inaccessible, but be archived by archival, journalistic, activist, or law enforcement organizations. In such cases, the referenced page may not directly publish the content.',\n", "    'rdfs:label': 'archivedAt',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:isPartOf': {'@id': 'https://pending.schema.org'},\n", "    'schema:rangeIncludes': [{'@id': 'schema:URL'}, {'@id': 'schema:WebPage'}],\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/2450'}},\n", "   {'@id': 'schema:mentions',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'Indicates that the CreativeWork contains a reference to, but is not necessarily about a concept.',\n", "    'rdfs:label': 'mentions',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:rangeIncludes': {'@id': 'schema:Thing'}},\n", "   {'@id': 'schema:contentReferenceTime',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'The specific time described by a creative work, for works (e.g. articles, video objects etc.) that emphasise a particular moment within an Event.',\n", "    'rdfs:label': 'contentReferenceTime',\n", "    'schema:domainIncludes': {'@id': 'schema:CreativeWork'},\n", "    'schema:isPartOf': {'@id': 'https://pending.schema.org'},\n", "    'schema:rangeIncludes': {'@id': 'schema:DateTime'},\n", "    'schema:source': {'@id': 'https://github.com/schemaorg/schemaorg/issues/1050'}},\n", "   {'@id': 'schema:isFamilyFriendly',\n", "    '@type': 'rdf:Property',\n", "    'rdfs:comment': 'Indicates whether this content is family friendly.',\n", "    'rdfs:label': 'isFamilyFriendly',\n", "    'schema:domainIncludes': [{'@id': 'schema:Product'},\n", "     {'@id': 'schema:Offer'},\n", "     {'@id': 'schema:CreativeWork'}],\n", "    'schema:rangeIncludes': {'@id': 'schema:Boolean'}}]},\n", " 'url': 'https://schema.org/Dataset'}", "\n========== MIDDLE OF OUTPUT TRUNCATED ==========\n"]}, "metadata": {}, "output_type": "execute_result", "execution_count": null}], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["def extract_schema_term_info(jsonld_data, term_id=None):\n", "    \"Extract essential information about a term from Schema.org JSON-LD\"\n", "    # If no specific term requested, find the main term (usually the one matching the URL)\n", "    if term_id is None:\n", "        # Try to find the term that matches the URL path\n", "        for item in jsonld_data.get('@graph', []):\n", "            if item.get('@type') in ['rdfs:Class', 'rdf:Property']:\n", "                term_id = item.get('@id')\n", "                break\n", "    \n", "    # Find the term in the graph\n", "    term_info = {}\n", "    for item in jsonld_data.get('@graph', []):\n", "        if item.get('@id') == term_id:\n", "            # Basic info\n", "            term_info['id'] = item.get('@id')\n", "            term_info['type'] = item.get('@type')\n", "            term_info['label'] = item.get('rdfs:label')\n", "            term_info['comment'] = item.get('rdfs:comment')\n", "            \n", "            # Properties specific to classes\n", "            if item.get('@type') == 'rdfs:Class':\n", "                term_info['subClassOf'] = item.get('rdfs:subClassOf', {}).get('@id')\n", "                term_info['equivalentClass'] = [c.get('@id') for c in L(item.get('owl:equivalentClass', []))]\n", "            \n", "            # Properties specific to properties\n", "            if item.get('@type') == 'rdf:Property':\n", "                term_info['domainIncludes'] = [d.get('@id') for d in L(item.get('schema:domainIncludes', []))]\n", "                term_info['rangeIncludes'] = [r.get('@id') for r in L(item.get('schema:rangeIncludes', []))]\n", "                term_info['subPropertyOf'] = item.get('rdfs:subPropertyOf', {}).get('@id')\n", "            \n", "            break\n", "    \n", "    return term_info\n", "\n", "# Helper to always return a list\n", "def L(x): return x if isinstance(x, list) else [x] if x is not None else []"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["def llm_friendly_term_summary(term_info):\n", "    \"Create an LLM-friendly summary of a Schema.org term\"\n", "    if not term_info: return \"Term not found\"\n", "    \n", "    # Format the term info in a way that's easy for an LLM to understand\n", "    summary = {\n", "        'term': term_info.get('id', '').replace('schema:', ''),\n", "        'type': 'Class' if term_info.get('type') == 'rdfs:Class' else 'Property',\n", "        'label': term_info.get('label'),\n", "        'description': term_info.get('comment'),\n", "        'url': f\"https://schema.org/{term_info.get('id', '').replace('schema:', '')}\"\n", "    }\n", "    \n", "    # Add type-specific information\n", "    if term_info.get('type') == 'rdfs:Class':\n", "        summary['parent'] = term_info.get('subClassOf')\n", "        summary['equivalent_classes'] = term_info.get('equivalentClass')\n", "    else:\n", "        summary['domains'] = term_info.get('domainIncludes')\n", "        summary['ranges'] = term_info.get('rangeIncludes')\n", "    \n", "    return summary"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["# Extract Dataset info\n", "dataset_term = extract_schema_term_info(dataset_info['jsonld'])\n", "dataset_summary = llm_friendly_term_summary(dataset_term)\n", "dataset_summary"], "outputs": [{"data": {"text/plain": ["{'term': 'isBasedOn',\n", " 'type': 'Property',\n", " 'label': 'isBasedOn',\n", " 'description': 'A resource from which this work is derived or from which it is a modification or adaptation.',\n", " 'url': 'https://schema.org/isBasedOn',\n", " 'domains': ['schema:CreativeWork'],\n", " 'ranges': ['schema:CreativeWork', 'schema:URL', 'schema:Product']}"]}, "metadata": {}, "output_type": "execute_result", "execution_count": null}], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "What do we think of this, and is this what we want to do?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "Hmm, it looks like we're getting information about `isBasedOn` rather than `Dataset`. This is likely because the function is picking the first term it finds in the JSON-LD `@graph` array rather than specifically looking for the Dataset class.\n", "\n", "For our JSON-LD navigation tool, we need to:\n", "\n", "1. Be more precise about finding the specific term we're looking for\n", "2. Create a way to navigate between related terms (like from Dataset to its properties)\n", "3. Build a structure that helps LLMs understand the semantics of the JSON-LD document\n", "\n", "Let's modify our approach to specifically find the Dataset term and then build a more complete navigation structure:\n", "\n", "```python\n", "def find_term_by_label(jsonld_data, label):\n", "    \"Find a term in the JSON-LD graph by its label\"\n", "    for item in jsonld_data.get('@graph', []):\n", "        if isinstance(item.get('rdfs:label'), str) and item.get('rdfs:label') == label:\n", "            return item\n", "        elif isinstance(item.get('rdfs:label'), dict) and item.get('rdfs:label').get('@value') == label:\n", "            return item\n", "    return None\n", "\n", "# Let's try again with Dataset\n", "dataset_item = find_term_by_label(dataset_info['jsonld'], 'Dataset')\n", "```\n", "\n", "What do you think? Should we continue in this direction, or would you prefer a different approach?"]}, {"cell_type": "code", "metadata": {}, "source": ["def find_term_by_label(jsonld_data, label):\n", "    \"Find a term in the JSON-LD graph by its label\"\n", "    for item in jsonld_data.get('@graph', []):\n", "        if isinstance(item.get('rdfs:label'), str) and item.get('rdfs:label') == label:\n", "            return item\n", "        elif isinstance(item.get('rdfs:label'), dict) and item.get('rdfs:label').get('@value') == label:\n", "            return item\n", "    return None\n", "\n", "# Let's try again with Dataset\n", "dataset_item = find_term_by_label(dataset_info['jsonld'], 'Dataset')\n", "dataset_item"], "outputs": [{"data": {"text/plain": ["{'@id': 'schema:Dataset',\n", " '@type': 'rdfs:Class',\n", " 'owl:equivalentClass': [{'@id': 'void:Dataset'},\n", "  {'@id': 'dcmitype:Dataset'},\n", "  {'@id': 'dcat:Dataset'}],\n", " 'rdfs:comment': 'A body of structured information describing some topic(s) of interest.',\n", " 'rdfs:label': 'Dataset',\n", " 'rdfs:subClassOf': {'@id': 'schema:CreativeWork'},\n", " 'schema:contributor': {'@id': 'https://schema.org/docs/collab/DatasetClass'}}"]}, "metadata": {}, "output_type": "execute_result", "execution_count": null}], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "Okay, what do we think of this?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "Great! Now we've successfully found the Dataset class. This looks much better - we can see its definition, parent class (CreativeWork), and equivalent classes in other vocabularies.\n", "\n", "Let's continue building our JSON-LD navigation tool in a Jeremy Howard style. We need to:\n", "\n", "1. Improve our term summary function to work with this more specific data\n", "2. Add a way to find related properties (properties that can be used with Dataset)\n", "3. Create a navigation structure that an LLM could use\n", "\n", "Here's how we might proceed:\n", "\n", "```python\n", "def create_term_summary(term_item):\n", "    \"Create a clean, LLM-friendly summary of a term\"\n", "    if not term_item: return None\n", "    \n", "    summary = {\n", "        'id': term_item.get('@id'),\n", "        'label': term_item.get('rdfs:label'),\n", "        'description': term_item.get('rdfs:comment'),\n", "        'type': term_item.get('@type')\n", "    }\n", "    \n", "    # Add class-specific information\n", "    if term_item.get('@type') == 'rdfs:Class':\n", "        parent = term_item.get('rdfs:subClassOf', {}).get('@id')\n", "        summary['parent_class'] = parent\n", "        \n", "        # Handle equivalent classes\n", "        eq_classes = term_item.get('owl:equivalentClass', [])\n", "        if not isinstance(eq_classes, list): eq_classes = [eq_classes]\n", "        summary['equivalent_classes'] = [c.get('@id') for c in eq_classes if c]\n", "    \n", "    # Add property-specific information\n", "    if term_item.get('@type') == 'rdf:Property':\n", "        # Handle domains\n", "        domains = term_item.get('schema:domainIncludes', [])\n", "        if not isinstance(domains, list): domains = [domains]\n", "        summary['domains'] = [d.get('@id') for d in domains if d]\n", "        \n", "        # Handle ranges\n", "        ranges = term_item.get('schema:rangeIncludes', [])\n", "        if not isinstance(ranges, list): ranges = [ranges]\n", "        summary['ranges'] = [r.get('@id') for r in ranges if r]\n", "    \n", "    return summary\n", "```\n", "\n", "What do you think of this improved summary function? Should we test it with our Dataset term?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "I think this could be good, but I want to think about this step-by-step from an agentic workflow perspective.So the goal here is to get information into the LLM's context window through RAG.Can use dictionaries to help structure that information. We need a way of indexing essentially that regular memory for JSON-LD.Within the indexing, we need to be able to walk through and get the semantic information, like getting the term summaries.This needs to be dynamic so that we can dereference online definitions via Schema.org.The Schema.org approach has both human-readable documentation and JSON-LD that are useful for the LLM.Don't write any code, but let's just think through this a little bit.Are we on the right track?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "You're absolutely right to approach this from an agentic workflow perspective. Let's think through this step by step:\n", "\n", "For JSON-LD navigation as part of a RAG system, we need to consider:\n", "\n", "1. **Indexing Structure**: We need a way to index JSON-LD documents that preserves their semantic relationships. Unlike plain text, JSON-LD has explicit relationships (subclasses, properties, domains, ranges) that are valuable for navigation.\n", "\n", "2. **Semantic Walking**: An agent needs to be able to \"walk\" through the semantic graph - from a class to its properties, from a property to its range types, etc. This is different from keyword search; it's about following semantic pathways.\n", "\n", "3. **Dynamic Dereferencing**: As you noted, we need to dynamically dereference terms from online sources like Schema.org. This means we're not just working with a static index but actively expanding our knowledge graph as needed.\n", "\n", "4. **Dual Representation**: Schema.org and many vocabularies have both human-readable documentation and structured JSON-LD. Both are valuable - the human docs for explanation and the JSON-LD for precise semantics.\n", "\n", "5. **Context Window Optimization**: We need to be strategic about what we put in the LLM's context window. Full JSON-LD documents can be verbose, so our summaries need to be concise yet semantically rich.\n", "\n", "6. **Navigation Affordances**: We should provide clear \"affordances\" for the LLM - suggested paths for exploration based on the semantic structure.\n", "\n", "I think we're on the right track with our approach. The term summaries provide a concise view of each term, and we can build navigation functions to move between related terms. The key will be designing this system to support the LLM's reasoning process rather than just providing raw data.\n", "\n", "Does this align with your thinking? Would you like to explore any particular aspect of this approach in more detail?"]}, {"cell_type": "code", "metadata": {}, "source": ["def create_term_summary(term_item):\n", "    \"Create a clean, LLM-friendly summary of a term\"\n", "    if not term_item: return None\n", "    \n", "    summary = {\n", "        'id': term_item.get('@id'),\n", "        'label': term_item.get('rdfs:label'),\n", "        'description': term_item.get('rdfs:comment'),\n", "        'type': term_item.get('@type')\n", "    }\n", "    \n", "    # Add class-specific information\n", "    if term_item.get('@type') == 'rdfs:Class':\n", "        parent = term_item.get('rdfs:subClassOf', {}).get('@id')\n", "        summary['parent_class'] = parent\n", "        \n", "        # Handle equivalent classes\n", "        eq_classes = term_item.get('owl:equivalentClass', [])\n", "        if not isinstance(eq_classes, list): eq_classes = [eq_classes]\n", "        summary['equivalent_classes'] = [c.get('@id') for c in eq_classes if c]\n", "    \n", "    # Add property-specific information\n", "    if term_item.get('@type') == 'rdf:Property':\n", "        # Handle domains\n", "        domains = term_item.get('schema:domainIncludes', [])\n", "        if not isinstance(domains, list): domains = [domains]\n", "        summary['domains'] = [d.get('@id') for d in domains if d]\n", "        \n", "        # Handle ranges\n", "        ranges = term_item.get('schema:rangeIncludes', [])\n", "        if not isinstance(ranges, list): ranges = [ranges]\n", "        summary['ranges'] = [r.get('@id') for r in ranges if r]\n", "    \n", "    return summary"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "What is the next step now?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "Now that we've thought through our approach, let's implement a key function to enable semantic walking through JSON-LD documents. The next logical step would be to create a function that can find related properties for a given class - this is one of the most common navigation patterns in semantic data.\n", "\n", "For our implementation, we should:\n", "\n", "1. Create a function that identifies all properties applicable to a specific class (like Dataset)\n", "2. Include the ability to filter these properties by type or usage\n", "3. Format the results in an LLM-friendly way\n", "\n", "Let's sketch out how this function might work. We'll need to search through the JSON-LD graph for properties that have our target class in their domain.\n", "\n", "Would you like me to implement this function next? Or would you prefer to focus on a different aspect of the navigation system?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "No, I think this is a good approach.Let's assume that the LLM has a pretty good understanding of RDF, RDFS, and Schema.org, but needs to be reminded a little bit about their semantic structure.For instance, Game.org has made some... choices in modeling schema.org"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "You make an excellent point. Even with a good understanding of RDF, RDFS, and Schema.org, LLMs can benefit from reminders about the semantic structure, especially when dealing with the nuances and modeling choices made by different organizations.\n", "\n", "Let's implement our function to find related properties, but include some contextual information that helps the LLM understand the semantic relationships properly:\n", "\n", "```python\n", "def find_class_properties(jsonld_data, class_id):\n", "    \"\"\"Find all properties that can be used with a specific class\n", "    \n", "    Args:\n", "        jsonld_data: The JSON-LD data containing the graph\n", "        class_id: The ID of the class (e.g., 'schema:Dataset')\n", "        \n", "    Returns:\n", "        A dictionary of property summaries grouped by category\n", "    \"\"\"\n", "    properties = {\n", "        'direct_properties': [],  # Properties that directly include this class in their domain\n", "        'inherited_properties': [],  # Properties inherited from parent classes\n", "        'recommended_properties': []  # Properties commonly used with this class (if available)\n", "    }\n", "    \n", "    # Find all properties that have this class in their domain\n", "    for item in jsonld_data.get('@graph', []):\n", "        if item.get('@type') == 'rdf:Property':\n", "            domains = item.get('schema:domainIncludes', [])\n", "            if not isinstance(domains, list): domains = [domains]\n", "            \n", "            # Check if this class is in the property's domain\n", "            if any(d.get('@id') == class_id for d in domains if d):\n", "                prop_summary = create_term_summary(item)\n", "                properties['direct_properties'].append(prop_summary)\n", "    \n", "    return properties\n", "```\n", "\n", "This gives us a basic structure to work with. Would you like me to implement this function now, or would you prefer to refine it further before implementation?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "Okay, properties are a weird thing because we are using the subproperty relation, right?So there are properties that are inherited from the parent class, but the problem is that a property in and of itself may be a subproperty of another property."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "You've hit on an important complexity in RDF/RDFS modeling! You're absolutely right - the property hierarchy adds another dimension to consider.\n", "\n", "In RDF/RDFS (and by extension, Schema.org), we have two separate inheritance mechanisms happening simultaneously:\n", "\n", "1. **Class inheritance**: Classes inherit properties from their parent classes (e.g., Dataset inherits properties from CreativeWork)\n", "\n", "2. **Property inheritance**: Properties can be subproperties of other properties (e.g., 'author' might be a subproperty of 'creator')\n", "\n", "This creates a complex inheritance web that our navigation system needs to account for. When a property is a subproperty of another property, it typically:\n", "\n", "- Inherits the domains and ranges of its parent property\n", "- Represents a more specific relationship than its parent\n", "- Should be displayed in the context of its parent property for better understanding\n", "\n", "Let's refine our approach to account for this dual inheritance structure:\n", "\n", "```python\n", "def find_class_properties(jsonld_data, class_id):\n", "    \"\"\"Find all properties that can be used with a specific class, accounting for both\n", "    class inheritance and property hierarchies\n", "    \n", "    Args:\n", "        jsonld_data: The JSON-LD data containing the graph\n", "        class_id: The ID of the class (e.g., 'schema:Dataset')\n", "        \n", "    Returns:\n", "        A dictionary of property summaries grouped by category\n", "    \"\"\"\n", "    properties = {\n", "        'direct_properties': [],  # Properties that directly include this class in their domain\n", "        'inherited_properties': [],  # Properties inherited from parent classes\n", "        'property_hierarchy': {}  # Mapping of properties to their subproperties\n", "    }\n", "    \n", "    # First, build a property hierarchy map\n", "    property_hierarchy = {}\n", "    for item in jsonld_data.get('@graph', []):\n", "        if item.get('@type') == 'rdf:Property':\n", "            prop_id = item.get('@id')\n", "            parent_prop = item.get('rdfs:subPropertyOf', {}).get('@id')\n", "            if parent_prop:\n", "                if parent_prop not in property_hierarchy:\n", "                    property_hierarchy[parent_prop] = []\n", "                property_hierarchy[parent_prop].append(prop_id)\n", "    \n", "    properties['property_hierarchy'] = property_hierarchy\n", "    \n", "    # Now find direct properties as before\n", "    # [implementation as before]\n", "    \n", "    return properties\n", "```\n", "\n", "This is getting more complex, but it's necessary to properly represent the semantic structure. What do you think about this approach?"]}, {"cell_type": "code", "metadata": {}, "source": ["def find_class_properties(jsonld_data, class_id):\n", "    \"\"\"Find all properties that can be used with a specific class, accounting for both\n", "    class inheritance and property hierarchies\n", "    \n", "    Args:\n", "        jsonld_data: The JSON-LD data containing the graph\n", "        class_id: The ID of the class (e.g., 'schema:Dataset')\n", "        \n", "    Returns:\n", "        A dictionary of property summaries grouped by category\n", "    \"\"\"\n", "    properties = {\n", "        'direct_properties': [],  # Properties that directly include this class in their domain\n", "        'inherited_properties': [],  # Properties inherited from parent classes\n", "        'property_hierarchy': {}  # Mapping of properties to their subproperties\n", "    }\n", "    \n", "    # First, build a property hierarchy map\n", "    property_hierarchy = {}\n", "    for item in jsonld_data.get('@graph', []):\n", "        if item.get('@type') == 'rdf:Property':\n", "            prop_id = item.get('@id')\n", "            parent_prop = item.get('rdfs:subPropertyOf', {}).get('@id')\n", "            if parent_prop:\n", "                if parent_prop not in property_hierarchy:\n", "                    property_hierarchy[parent_prop] = []\n", "                property_hierarchy[parent_prop].append(prop_id)\n", "    \n", "    properties['property_hierarchy'] = property_hierarchy\n", "    \n", "    # Now find direct properties as before\n", "    # [implementation as before]\n", "    \n", "    return properties"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "What is the next step here?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "The next step is to complete the implementation of our `find_class_properties` function by adding:\n", "\n", "1. The logic to find direct properties for the specified class\n", "2. The logic to find inherited properties from parent classes\n", "3. A way to organize these properties in an LLM-friendly structure\n", "\n", "Let's sketch out the complete implementation:\n", "\n", "```python\n", "def find_class_properties(jsonld_data, class_id):\n", "    \"\"\"Find all properties that can be used with a specific class, accounting for both\n", "    class inheritance and property hierarchies\n", "    \n", "    Args:\n", "        jsonld_data: The JSON-LD data containing the graph\n", "        class_id: The ID of the class (e.g., 'schema:Dataset')\n", "        \n", "    Returns:\n", "        A dictionary of property summaries grouped by category\n", "    \"\"\"\n", "    properties = {\n", "        'direct_properties': [],  # Properties that directly include this class in their domain\n", "        'inherited_properties': [],  # Properties inherited from parent classes\n", "        'property_hierarchy': {}  # Mapping of properties to their subproperties\n", "    }\n", "    \n", "    # First, build a property hierarchy map\n", "    property_hierarchy = {}\n", "    for item in jsonld_data.get('@graph', []):\n", "        if item.get('@type') == 'rdf:Property':\n", "            prop_id = item.get('@id')\n", "            parent_prop = item.get('rdfs:subPropertyOf', {}).get('@id')\n", "            if parent_prop:\n", "                if parent_prop not in property_hierarchy:\n", "                    property_hierarchy[parent_prop] = []\n", "                property_hierarchy[parent_prop].append(prop_id)\n", "    \n", "    properties['property_hierarchy'] = property_hierarchy\n", "    \n", "    # Find the class hierarchy (this class and its parent classes)\n", "    class_hierarchy = [class_id]\n", "    current_class = find_term_by_id(jsonld_data, class_id)\n", "    while current_class:\n", "        parent_class = current_class.get('rdfs:subClassOf', {}).get('@id')\n", "        if parent_class and parent_class not in class_hierarchy:\n", "            class_hierarchy.append(parent_class)\n", "            current_class = find_term_by_id(jsonld_data, parent_class)\n", "        else:\n", "            break\n", "    \n", "    # Now find properties for each class in the hierarchy\n", "    for item in jsonld_data.get('@graph', []):\n", "        if item.get('@type') == 'rdf:Property':\n", "            domains = item.get('schema:domainIncludes', [])\n", "            if not isinstance(domains, list): domains = [domains]\n", "            domain_ids = [d.get('@id') for d in domains if d]\n", "            \n", "            # Check if this property applies to our class\n", "            prop_summary = create_term_summary(item)\n", "            if class_id in domain_ids:\n", "                properties['direct_properties'].append(prop_summary)\n", "            elif any(parent in domain_ids for parent in class_hierarchy[1:]):\n", "                properties['inherited_properties'].append(prop_summary)\n", "    \n", "    return properties\n", "\n", "def find_term_by_id(jsonld_data, term_id):\n", "    \"Find a term in the JSON-LD graph by its ID\"\n", "    for item in jsonld_data.get('@graph', []):\n", "        if item.get('@id') == term_id:\n", "            return item\n", "    return None\n", "```\n", "\n", "After implementing this function, we would want to test it with our Dataset class to see what properties we find. Then we could consider adding additional functionality like:\n", "\n", "1. A function to organize properties by category (e.g., basic properties, media properties, etc.)\n", "2. A function to find related classes (e.g., classes that are in the range of a property)\n", "3. A function to generate natural language explanations of the relationships\n", "\n", "What do you think about this approach? Would you like to focus on any particular aspect next?"]}, {"cell_type": "code", "metadata": {}, "source": ["def find_class_properties(jsonld_data, class_id):\n", "    \"\"\"Find all properties that can be used with a specific class, accounting for both\n", "    class inheritance and property hierarchies\n", "    \n", "    Args:\n", "        jsonld_data: The JSON-LD data containing the graph\n", "        class_id: The ID of the class (e.g., 'schema:Dataset')\n", "        \n", "    Returns:\n", "        A dictionary of property summaries grouped by category\n", "    \"\"\"\n", "    properties = {\n", "        'direct_properties': [],  # Properties that directly include this class in their domain\n", "        'inherited_properties': [],  # Properties inherited from parent classes\n", "        'property_hierarchy': {}  # Mapping of properties to their subproperties\n", "    }\n", "    \n", "    # First, build a property hierarchy map\n", "    property_hierarchy = {}\n", "    for item in jsonld_data.get('@graph', []):\n", "        if item.get('@type') == 'rdf:Property':\n", "            prop_id = item.get('@id')\n", "            parent_prop = item.get('rdfs:subPropertyOf', {}).get('@id')\n", "            if parent_prop:\n", "                if parent_prop not in property_hierarchy:\n", "                    property_hierarchy[parent_prop] = []\n", "                property_hierarchy[parent_prop].append(prop_id)\n", "    \n", "    properties['property_hierarchy'] = property_hierarchy\n", "    \n", "    # Find the class hierarchy (this class and its parent classes)\n", "    class_hierarchy = [class_id]\n", "    current_class = find_term_by_id(jsonld_data, class_id)\n", "    while current_class:\n", "        parent_class = current_class.get('rdfs:subClassOf', {}).get('@id')\n", "        if parent_class and parent_class not in class_hierarchy:\n", "            class_hierarchy.append(parent_class)\n", "            current_class = find_term_by_id(jsonld_data, parent_class)\n", "        else:\n", "            break\n", "    \n", "    # Now find properties for each class in the hierarchy\n", "    for item in jsonld_data.get('@graph', []):\n", "        if item.get('@type') == 'rdf:Property':\n", "            domains = item.get('schema:domainIncludes', [])\n", "            if not isinstance(domains, list): domains = [domains]\n", "            domain_ids = [d.get('@id') for d in domains if d]\n", "            \n", "            # Check if this property applies to our class\n", "            prop_summary = create_term_summary(item)\n", "            if class_id in domain_ids:\n", "                properties['direct_properties'].append(prop_summary)\n", "            elif any(parent in domain_ids for parent in class_hierarchy[1:]):\n", "                properties['inherited_properties'].append(prop_summary)\n", "    \n", "    return properties\n", "\n", "def find_term_by_id(jsonld_data, term_id):\n", "    \"Find a term in the JSON-LD graph by its ID\"\n", "    for item in jsonld_data.get('@graph', []):\n", "        if item.get('@id') == term_id:\n", "            return item\n", "    return None"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "I feel like we're getting a little bit away from the Jeremy Howard-based approach here.Got a bunch of code but I don't know how the LLM is going to interpret that and what it's going to look like."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "You're absolutely right - we've drifted from the Jeremy Howard approach. Let's take a step back and refocus on a more practical, step-by-step approach with clear outputs at each stage.\n", "\n", "The Jeremy Howard approach would:\n", "1. Start with a concrete example\n", "2. Build a minimal function that works\n", "3. Test it immediately to see the results\n", "4. Iterate based on what we learn\n", "\n", "Let's simplify and implement a more focused function to find Dataset properties:\n", "\n", "```python\n", "def find_dataset_properties(jsonld_data):\n", "    \"Find properties applicable to Dataset in a clear, LLM-friendly format\"\n", "    # Get a list of direct properties for Dataset\n", "    direct_props = []\n", "    \n", "    for item in jsonld_data.get('@graph', []):\n", "        if item.get('@type') == 'rdf:Property':\n", "            domains = item.get('schema:domainIncludes', [])\n", "            if not isinstance(domains, list): domains = [domains]\n", "            \n", "            # Check if Dataset is in the domains\n", "            if any(d.get('@id') == 'schema:Dataset' for d in domains if d):\n", "                # Create a simple, readable summary\n", "                prop = {\n", "                    'name': item.get('rdfs:label'),\n", "                    'description': item.get('rdfs:comment'),\n", "                    'id': item.get('@id')\n", "                }\n", "                direct_props.append(prop)\n", "    \n", "    return direct_props\n", "```\n", "\n", "Let's implement this and see what we get before adding more complexity:\n", "\n", "```python\n", "# Test with our dataset info\n", "dataset_properties = find_dataset_properties(dataset_info['jsonld'])\n", "print(f\"Found {len(dataset_properties)} properties for Dataset\")\n", "for prop in dataset_properties[:3]:  # Show first 3 for brevity\n", "    print(f\"- {prop['name']}: {prop['description'][:100]}...\")\n", "```\n", "\n", "This gives us a concrete starting point with real output. What do you think about this more focused approach?"]}, {"cell_type": "code", "metadata": {}, "source": ["def find_dataset_properties(jsonld_data):\n", "    \"Find properties applicable to Dataset in a clear, LLM-friendly format\"\n", "    # Get a list of direct properties for Dataset\n", "    direct_props = []\n", "    \n", "    for item in jsonld_data.get('@graph', []):\n", "        if item.get('@type') == 'rdf:Property':\n", "            domains = item.get('schema:domainIncludes', [])\n", "            if not isinstance(domains, list): domains = [domains]\n", "            \n", "            # Check if Dataset is in the domains\n", "            if any(d.get('@id') == 'schema:Dataset' for d in domains if d):\n", "                # Create a simple, readable summary\n", "                prop = {\n", "                    'name': item.get('rdfs:label'),\n", "                    'description': item.get('rdfs:comment'),\n", "                    'id': item.get('@id')\n", "                }\n", "                direct_props.append(prop)\n", "    \n", "    return direct_props"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["# Test with our dataset info\n", "dataset_properties = find_dataset_properties(dataset_info['jsonld'])\n", "print(f\"Found {len(dataset_properties)} properties for Dataset\")\n", "for prop in dataset_properties[:3]:  # Show first 3 for brevity\n", "    print(f\"- {prop['name']}: {prop['description'][:100]}...\")"], "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Found 10 properties for Dataset\n", "- catalog: A data catalog which contains this dataset....\n", "- includedInDataCatalog: A data catalog which contains this dataset....\n", "- variableMeasured: The variableMeasured property can indicate (repeated as necessary) the  variables that are measured ...\n"]}], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "What do we think of this?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "This is much better! Now we have a focused function that gives us clear, tangible results. We found 10 properties that directly apply to Dataset, and we can see the first three with their descriptions.\n", "\n", "This follows the Jeremy Howard approach better because:\n", "\n", "1. We started with a concrete example (Dataset)\n", "2. Built a minimal function that works\n", "3. Tested it immediately with real output\n", "4. Now we can iterate based on what we learned\n", "\n", "The output is also much more LLM-friendly - we have simple property summaries with names, descriptions, and IDs that an LLM can easily understand and reason about.\n", "\n", "From here, we could expand in several ways:\n", "\n", "1. Add the ability to retrieve properties from parent classes (like CreativeWork)\n", "2. Include information about the expected values (ranges) for each property\n", "3. Organize properties by category or importance\n", "4. Create a similar function for exploring classes referenced by these properties\n", "\n", "What direction would you like to take next? Should we focus on adding inherited properties from parent classes?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "Okay, I'm starting to get a little bit lost. I think this is a good approach and I feel good that we're on the right track here, but let's go back and think of this in terms of our master plan, what we need to do, and what we've learned thus far.We need a RAG master index that's semantically structured for the LLM based off of the JSON-LD and RDFS semantics."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "You're right, let's take a step back and refocus on our master plan. Here's what we've learned and where we need to go:\n", "\n", "## What We've Learned\n", "\n", "1. We can extract structured information from JSON-LD documents\n", "2. We've created a function to find properties directly applicable to a class (like Dataset)\n", "3. We understand that semantic relationships (class inheritance, property hierarchies) need to be preserved\n", "\n", "## Our Master Plan: JSON-LD RAG Index\n", "\n", "Our goal is to create a semantically structured RAG index for JSON-LD documents that:\n", "\n", "1. **Preserves semantic relationships** - Class hierarchies, property domains/ranges, etc.\n", "2. **Is LLM-friendly** - Structured in a way that helps LLMs understand and navigate the data\n", "3. **Supports semantic queries** - Allows finding related terms, following relationships, etc.\n", "\n", "## Next Steps\n", "\n", "1. **Define our core index structure**:\n", "   - How do we represent classes, properties, and their relationships?\n", "   - What metadata do we store with each term?\n", "\n", "2. **Create basic indexing functions**:\n", "   - Function to index a JSON-LD document\n", "   - Function to retrieve term information\n", "   - Function to find related terms\n", "\n", "3. **Add semantic navigation helpers**:\n", "   - Follow class hierarchies\n", "   - Find applicable properties\n", "   - Resolve term references\n", "\n", "4. **Create LLM-friendly output formatters**:\n", "   - Concise term summaries\n", "   - Relationship explanations\n", "   - Navigation suggestions\n", "\n", "Does this restructuring help clarify where we are and where we need to go? Would you like to focus on defining the core index structure first?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "Okay, so you also forgot about the affordances, the referencing stuff, and all of those important things.It's not just about extracting the structured information from JSON-LD documents. It's about being able to selectively retrieve based on affordances and then creating an index structure that makes sense to the LLM so that it can pull things into its context window dynamically. We don't want to load lots of information into the context window; we want the LLM to be able to understand what our index looks like and then use that to load information, just like we did with the markdown documents."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "You're absolutely right, and I apologize for missing those crucial aspects. Let's refocus properly:\n", "\n", "## Core Concept: Affordance-Based JSON-LD Navigation\n", "\n", "The key insight is that we need to create affordances (clear interaction possibilities) that allow the LLM to:\n", "\n", "1. **Understand what information is available** without loading everything\n", "2. **Selectively request specific information** to bring into its context window\n", "3. **Navigate relationships dynamically** based on what it's currently exploring\n", "\n", "Just like with markdown documents, where the LLM could see headings and request specific sections, we need a similar approach for JSON-LD where the LLM can see:\n", "- What classes and properties exist\n", "- How they're related\n", "- How to request more details about specific terms\n", "\n", "## Revised Master Plan\n", "\n", "1. **Create an index of available terms and relationships**:\n", "   - A concise listing of classes and properties\n", "   - Clear indicators of relationships without full details\n", "   - Metadata about what information is available for each term\n", "\n", "2. **Provide affordance functions**:\n", "   - `get_class_details(class_id)` - Load detailed info about a class\n", "   - `get_property_details(property_id)` - Load detailed info about a property\n", "   - `get_class_properties(class_id)` - Get properties applicable to a class\n", "   - `get_related_classes(class_id)` - Find classes related to a given class\n", "\n", "3. **Define a context window optimization strategy**:\n", "   - How to summarize terms concisely\n", "   - How to indicate relationships without loading full details\n", "   - How to prioritize what information to load first\n", "\n", "Does this better capture the affordance-based approach we need? The goal is to create a system where the LLM can see what's available and selectively load what it needs, rather than trying to load everything at once."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "I'd like to think a bit more about what the index for the LLM looks like. It should be able to be accessed through agentic workflow tool use to find relevant information."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "Let's think more deeply about what the index for the LLM should look like, focusing on how it would be accessed through agentic workflow tool use.\n", "\n", "## LLM-Optimized JSON-LD Index Structure\n", "\n", "The index should provide:\n", "\n", "1. **A high-level map** of the available semantic structures\n", "2. **Clear access patterns** for retrieving specific information\n", "3. **Contextual hints** about relationships without overwhelming detail\n", "\n", "Here's a conceptual structure:\n", "\n", "```\n", "{\n", "  \"vocabularies\": {\n", "    \"schema.org\": {\n", "      \"prefix\": \"schema\",\n", "      \"namespace\": \"https://schema.org/\",\n", "      \"description\": \"Schema.org vocabulary for structured data on the internet\",\n", "      \"classes\": [\"Dataset\", \"CreativeWork\", \"Person\", ...],  // Just names, not full details\n", "      \"properties\": [\"name\", \"description\", \"url\", ...],      // Just names, not full details\n", "    },\n", "    \"dcterms\": {\n", "      \"prefix\": \"dc\",\n", "      \"namespace\": \"http://purl.org/dc/terms/\",\n", "      \"description\": \"Dublin Core metadata terms\",\n", "      \"classes\": [...],\n", "      \"properties\": [...]\n", "    }\n", "  },\n", "  \n", "  \"class_relationships\": {\n", "    \"schema:Dataset\": {\n", "      \"parent_classes\": [\"schema:CreativeWork\"],\n", "      \"equivalent_classes\": [\"dcat:Dataset\"],\n", "      \"property_count\": 35,  // Hint about how many properties are available\n", "      \"direct_property_count\": 10\n", "    }\n", "  },\n", "  \n", "  \"access_patterns\": {\n", "    \"get_class_details(class_id)\": \"Get detailed information about a specific class\",\n", "    \"get_property_details(property_id)\": \"Get detailed information about a specific property\",\n", "    \"get_class_properties(class_id, include_inherited=True)\": \"Get properties applicable to a class\",\n", "    \"find_related_classes(class_id)\": \"Find classes related to the specified class\",\n", "    \"search_terms(query)\": \"Search for classes or properties matching a query\"\n", "  }\n", "}\n", "```\n", "\n", "## Agentic Workflow Integration\n", "\n", "For an agent to effectively use this index:\n", "\n", "1. **The index is provided as context** at the start of a task involving semantic data\n", "2. **The agent identifies needed information** based on the task and what's in the index\n", "3. **The agent calls appropriate functions** to retrieve specific information\n", "4. **Retrieved information is added to context** for the agent to use in reasoning\n", "\n", "For example, if an agent is analyzing a Croissant dataset about weather data:\n", "\n", "1. Agent sees \"Dataset\" is mentioned in the document and notes it's available in the index\n", "2. Agent calls `get_class_details(\"schema:Dataset\")` to understand what a Dataset is\n", "3. Agent calls `get_class_properties(\"schema:Dataset\")` to see what properties are available\n", "4. Agent might then call `get_property_details(\"schema:variableMeasured\")` to understand a specific property\n", "\n", "This approach allows the agent to navigate the semantic structure efficiently, bringing in only what's needed for the current reasoning step.\n", "\n", "Does this approach to structuring the index make sense for agentic workflows? Would you like to refine any aspects of this?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "How do we start to test our theory about an agentic workflow for JSON-LD multi-agentic system? We need an agent that is an expert in JSON-LD semantics, RDF semantics, schema.org semantics and the subset of RDFS semantics relevant to schema.org."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "To test our theory about an agentic workflow for JSON-LD, let's create a small prototype with the following components:\n", "\n", "1. **A JSON-LD Semantic Navigator Agent**: This will be our specialized agent with knowledge of JSON-LD, RDF, RDFS, and Schema.org semantics\n", "\n", "2. **A minimal implementation of our index structure**: Just enough to demonstrate the concept\n", "\n", "3. **A set of tool functions**: That allow the agent to navigate and retrieve information\n", "\n", "4. **A simple test case**: Using a real-world JSON-LD document (like our Schema.org Dataset example)\n", "\n", "Here's how we could approach this:\n", "\n", "```python\n", "# 1. Create a minimal index from our Schema.org data\n", "def create_minimal_index(jsonld_data):\n", "    \"Create a minimal semantic index from JSON-LD data\"\n", "    index = {\n", "        \"vocabularies\": {\n", "            \"schema.org\": {\n", "                \"prefix\": \"schema\",\n", "                \"namespace\": \"https://schema.org/\",\n", "                \"description\": \"Schema.org vocabulary for structured data\",\n", "                \"classes\": [],\n", "                \"properties\": []\n", "            }\n", "        },\n", "        \"class_relationships\": {},\n", "        \"access_patterns\": {\n", "            \"get_class_details(class_id)\": \"Get detailed information about a class\",\n", "            \"get_property_details(property_id)\": \"Get detailed information about a property\",\n", "            \"get_class_properties(class_id)\": \"Get properties for a class\"\n", "        }\n", "    }\n", "    \n", "    # Extract classes and properties\n", "    for item in jsonld_data.get('@graph', []):\n", "        if item.get('@type') == 'rdfs:Class':\n", "            class_name = item.get('rdfs:label')\n", "            if class_name:\n", "                index[\"vocabularies\"][\"schema.org\"][\"classes\"].append(class_name)\n", "                \n", "                # Add class relationship info\n", "                class_id = item.get('@id')\n", "                if class_id:\n", "                    parent = item.get('rdfs:subClassOf', {}).get('@id')\n", "                    index[\"class_relationships\"][class_id] = {\n", "                        \"parent_classes\": [parent] if parent else [],\n", "                        \"property_count\": 0  # We'll calculate this later\n", "                    }\n", "        \n", "        elif item.get('@type') == 'rdf:Property':\n", "            prop_name = item.get('rdfs:label')\n", "            if prop_name:\n", "                index[\"vocabularies\"][\"schema.org\"][\"properties\"].append(prop_name)\n", "    \n", "    return index\n", "\n", "# 2. Implement our tool functions\n", "def get_class_details(jsonld_data, class_id):\n", "    \"Get detailed information about a specific class\"\n", "    for item in jsonld_data.get('@graph', []):\n", "        if item.get('@id') == class_id:\n", "            return {\n", "                \"id\": item.get('@id'),\n", "                \"label\": item.get('rdfs:label'),\n", "                \"description\": item.get('rdfs:comment'),\n", "                \"parent_class\": item.get('rdfs:subClassOf', {}).get('@id'),\n", "                \"equivalent_classes\": [c.get('@id') for c in item.get('owl:equivalentClass', [])]\n", "                                     if isinstance(item.get('owl:equivalentClass'), list)\n", "                                     else [item.get('owl:equivalentClass', {}).get('@id')] \n", "                                     if item.get('owl:equivalentClass') else []\n", "            }\n", "    return {\"error\": f\"Class {class_id} not found\"}\n", "\n", "def get_class_properties(jsonld_data, class_id):\n", "    \"Get properties applicable to a class\"\n", "    properties = []\n", "    \n", "    for item in jsonld_data.get('@graph', []):\n", "        if item.get('@type') == 'rdf:Property':\n", "            domains = item.get('schema:domainIncludes', [])\n", "            if not isinstance(domains, list): domains = [domains]\n", "            \n", "            if any(d.get('@id') == class_id for d in domains if d):\n", "                properties.append({\n", "                    \"id\": item.get('@id'),\n", "                    \"label\": item.get('rdfs:label'),\n", "                    \"description\": item.get('rdfs:comment')[:100] + \"...\" \n", "                        if item.get('rdfs:comment') and len(item.get('rdfs:comment')) > 100 \n", "                        else item.get('rdfs:comment')\n", "                })\n", "    \n", "    return properties\n", "```\n", "\n", "To test this prototype:\n", "\n", "1. Create the index from our Schema.org data\n", "2. Test the tool functions directly\n", "3. Set up a prompt for the LLM to act as a JSON-LD semantic expert\n", "4. Give the LLM a task that requires navigating the semantic structure\n", "\n", "For example:\n", "\n", "```python\n", "# Create our index\n", "schema_index = create_minimal_index(dataset_info['jsonld'])\n", "\n", "# Test a tool function\n", "dataset_details = get_class_details(dataset_info['jsonld'], 'schema:Dataset')\n", "dataset_props = get_class_properties(dataset_info['jsonld'], 'schema:Dataset')\n", "\n", "# Now we could set up a prompt for the LLM to use these tools\n", "agent_prompt = \"\"\"\n", "You are a JSON-LD Semantic Navigator, an expert in RDF, RDFS, Schema.org and JSON-LD semantics.\n", "You have access to a semantic index and tools to navigate it.\n", "\n", "Available tools:\n", "- get_class_details(class_id): Get detailed information about a class\n", "- get_class_properties(class_id): Get properties for a class\n", "\n", "Your task is to help users understand and navigate semantic data structures.\n", "\"\"\"\n", "```\n", "\n", "This would give us a basic prototype to test our agentic workflow approach. What do you think? Should we implement this minimal version and see how it works?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "Yeah, let's implement this minimal version and see what it looks like."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "Great! Let's implement our minimal version and test it out:\n", "\n", "```python\n", "# 1. Create a minimal index from our Schema.org data\n", "def create_minimal_index(jsonld_data):\n", "    \"Create a minimal semantic index from JSON-LD data\"\n", "    index = {\n", "        \"vocabularies\": {\n", "            \"schema.org\": {\n", "                \"prefix\": \"schema\",\n", "                \"namespace\": \"https://schema.org/\",\n", "                \"description\": \"Schema.org vocabulary for structured data\",\n", "                \"classes\": [],\n", "                \"properties\": []\n", "            }\n", "        },\n", "        \"class_relationships\": {},\n", "        \"access_patterns\": {\n", "            \"get_class_details(class_id)\": \"Get detailed information about a class\",\n", "            \"get_property_details(property_id)\": \"Get detailed information about a property\",\n", "            \"get_class_properties(class_id)\": \"Get properties for a class\"\n", "        }\n", "    }\n", "    \n", "    # Extract classes and properties\n", "    for item in jsonld_data.get('@graph', []):\n", "        if item.get('@type') == 'rdfs:Class':\n", "            class_name = item.get('rdfs:label')\n", "            if class_name:\n", "                index[\"vocabularies\"][\"schema.org\"][\"classes\"].append(class_name)\n", "                \n", "                # Add class relationship info\n", "                class_id = item.get('@id')\n", "                if class_id:\n", "                    parent = item.get('rdfs:subClassOf', {}).get('@id')\n", "                    index[\"class_relationships\"][class_id] = {\n", "                        \"parent_classes\": [parent] if parent else [],\n", "                        \"property_count\": 0  # We'll calculate this later\n", "                    }\n", "        \n", "        elif item.get('@type') == 'rdf:Property':\n", "            prop_name = item.get('rdfs:label')\n", "            if prop_name:\n", "                index[\"vocabularies\"][\"schema.org\"][\"properties\"].append(prop_name)\n", "    \n", "    return index\n", "\n", "# 2. Implement our tool functions\n", "def get_class_details(jsonld_data, class_id):\n", "    \"Get detailed information about a specific class\"\n", "    for item in jsonld_data.get('@graph', []):\n", "        if item.get('@id') == class_id:\n", "            return {\n", "                \"id\": item.get('@id'),\n", "                \"label\": item.get('rdfs:label'),\n", "                \"description\": item.get('rdfs:comment'),\n", "                \"parent_class\": item.get('rdfs:subClassOf', {}).get('@id'),\n", "                \"equivalent_classes\": [c.get('@id') for c in item.get('owl:equivalentClass', [])]\n", "                                     if isinstance(item.get('owl:equivalentClass'), list)\n", "                                     else [item.get('owl:equivalentClass', {}).get('@id')] \n", "                                     if item.get('owl:equivalentClass') else []\n", "            }\n", "    return {\"error\": f\"Class {class_id} not found\"}\n", "\n", "def get_property_details(jsonld_data, property_id):\n", "    \"Get detailed information about a specific property\"\n", "    for item in jsonld_data.get('@graph', []):\n", "        if item.get('@id') == property_id:\n", "            # Handle domains and ranges which might be lists or single items\n", "            domains = item.get('schema:domainIncludes', [])\n", "            if not isinstance(domains, list): domains = [domains]\n", "            domain_ids = [d.get('@id') for d in domains if d]\n", "            \n", "            ranges = item.get('schema:rangeIncludes', [])\n", "            if not isinstance(ranges, list): ranges = [ranges]\n", "            range_ids = [r.get('@id') for r in ranges if r]\n", "            \n", "            return {\n", "                \"id\": item.get('@id'),\n", "                \"label\": item.get('rdfs:label'),\n", "                \"description\": item.get('rdfs:comment'),\n", "                \"domains\": domain_ids,\n", "                \"ranges\": range_ids,\n", "                \"subproperty_of\": item.get('rdfs:subPropertyOf', {}).get('@id')\n", "            }\n", "    return {\"error\": f\"Property {property_id} not found\"}\n", "\n", "def get_class_properties(jsonld_data, class_id):\n", "    \"Get properties applicable to a class\"\n", "    properties = []\n", "    \n", "    for item in jsonld_data.get('@graph', []):\n", "        if item.get('@type') == 'rdf:Property':\n", "            domains = item.get('schema:domainIncludes', [])\n", "            if not isinstance(domains, list): domains = [domains]\n", "            \n", "            if any(d.get('@id') == class_id for d in domains if d):\n", "                properties.append({\n", "                    \"id\": item.get('@id'),\n", "                    \"label\": item.get('rdfs:label'),\n", "                    \"description\": item.get('rdfs:comment')[:100] + \"...\" \n", "                        if item.get('rdfs:comment') and len(item.get('rdfs:comment')) > 100 \n", "                        else item.get('rdfs:comment')\n", "                })\n", "    \n", "    return properties\n", "\n", "# Create our index\n", "schema_index = create_minimal_index(dataset_info['jsonld'])\n", "\n", "# Test our index and tools\n", "print(\"Schema.org Index:\")\n", "print(f\"- Classes: {len(schema_index['vocabularies']['schema.org']['classes'])}\")\n", "print(f\"- Properties: {len(schema_index['vocabularies']['schema.org']['properties'])}\")\n", "print(f\"- Class relationships: {len(schema_index['class_relationships'])}\")\n", "\n", "# Get Dataset class details\n", "dataset_details = get_class_details(dataset_info['jsonld'], 'schema:Dataset')\n", "print(\"\\nDataset Class Details:\")\n", "print(f\"- Label: {dataset_details.get('label')}\")\n", "print(f\"- Description: {dataset_details.get('description')[:100]}...\")\n", "print(f\"- Parent class: {dataset_details.get('parent_class')}\")\n", "print(f\"- Equivalent classes: {dataset_details.get('equivalent_classes')}\")\n", "\n", "# Get Dataset properties\n", "dataset_props = get_class_properties(dataset_info['jsonld'], 'schema:Dataset')\n", "print(f\"\\nDataset Properties ({len(dataset_props)}):\")\n", "for i, prop in enumerate(dataset_props[:3], 1):  # Show first 3\n", "    print(f\"{i}. {prop.get('label')}: {prop.get('description')}\")\n", "\n", "# Get details for a specific property\n", "if dataset_props:\n", "    prop_id = dataset_props[0]['id']\n", "    prop_details = get_property_details(jsonld_data=dataset_info['jsonld'], property_id=prop_id)\n", "    print(f\"\\nProperty Details for {prop_details.get('label')}:\")\n", "    print(f\"- Description: {prop_details.get('description')[:100]}...\")\n", "    print(f\"- Domains: {prop_details.get('domains')}\")\n", "    print(f\"- Ranges: {prop_details.get('ranges')}\")\n", "```\n", "\n", "This will give us a good look at our minimal implementation and how it works with real data. Let's see what we get!"]}, {"cell_type": "code", "metadata": {}, "source": ["# 1. Create a minimal index from our Schema.org data\n", "def create_minimal_index(jsonld_data):\n", "    \"Create a minimal semantic index from JSON-LD data\"\n", "    index = {\n", "        \"vocabularies\": {\n", "            \"schema.org\": {\n", "                \"prefix\": \"schema\",\n", "                \"namespace\": \"https://schema.org/\",\n", "                \"description\": \"Schema.org vocabulary for structured data\",\n", "                \"classes\": [],\n", "                \"properties\": []\n", "            }\n", "        },\n", "        \"class_relationships\": {},\n", "        \"access_patterns\": {\n", "            \"get_class_details(class_id)\": \"Get detailed information about a class\",\n", "            \"get_property_details(property_id)\": \"Get detailed information about a property\",\n", "            \"get_class_properties(class_id)\": \"Get properties for a class\"\n", "        }\n", "    }\n", "    \n", "    # Extract classes and properties\n", "    for item in jsonld_data.get('@graph', []):\n", "        if item.get('@type') == 'rdfs:Class':\n", "            class_name = item.get('rdfs:label')\n", "            if class_name:\n", "                index[\"vocabularies\"][\"schema.org\"][\"classes\"].append(class_name)\n", "                \n", "                # Add class relationship info\n", "                class_id = item.get('@id')\n", "                if class_id:\n", "                    parent = item.get('rdfs:subClassOf', {}).get('@id')\n", "                    index[\"class_relationships\"][class_id] = {\n", "                        \"parent_classes\": [parent] if parent else [],\n", "                        \"property_count\": 0  # We'll calculate this later\n", "                    }\n", "        \n", "        elif item.get('@type') == 'rdf:Property':\n", "            prop_name = item.get('rdfs:label')\n", "            if prop_name:\n", "                index[\"vocabularies\"][\"schema.org\"][\"properties\"].append(prop_name)\n", "    \n", "    return index\n", "\n", "# 2. Implement our tool functions\n", "def get_class_details(jsonld_data, class_id):\n", "    \"Get detailed information about a specific class\"\n", "    for item in jsonld_data.get('@graph', []):\n", "        if item.get('@id') == class_id:\n", "            return {\n", "                \"id\": item.get('@id'),\n", "                \"label\": item.get('rdfs:label'),\n", "                \"description\": item.get('rdfs:comment'),\n", "                \"parent_class\": item.get('rdfs:subClassOf', {}).get('@id'),\n", "                \"equivalent_classes\": [c.get('@id') for c in item.get('owl:equivalentClass', [])]\n", "                                     if isinstance(item.get('owl:equivalentClass'), list)\n", "                                     else [item.get('owl:equivalentClass', {}).get('@id')] \n", "                                     if item.get('owl:equivalentClass') else []\n", "            }\n", "    return {\"error\": f\"Class {class_id} not found\"}\n", "\n", "def get_property_details(jsonld_data, property_id):\n", "    \"Get detailed information about a specific property\"\n", "    for item in jsonld_data.get('@graph', []):\n", "        if item.get('@id') == property_id:\n", "            # Handle domains and ranges which might be lists or single items\n", "            domains = item.get('schema:domainIncludes', [])\n", "            if not isinstance(domains, list): domains = [domains]\n", "            domain_ids = [d.get('@id') for d in domains if d]\n", "            \n", "            ranges = item.get('schema:rangeIncludes', [])\n", "            if not isinstance(ranges, list): ranges = [ranges]\n", "            range_ids = [r.get('@id') for r in ranges if r]\n", "            \n", "            return {\n", "                \"id\": item.get('@id'),\n", "                \"label\": item.get('rdfs:label'),\n", "                \"description\": item.get('rdfs:comment'),\n", "                \"domains\": domain_ids,\n", "                \"ranges\": range_ids,\n", "                \"subproperty_of\": item.get('rdfs:subPropertyOf', {}).get('@id')\n", "            }\n", "    return {\"error\": f\"Property {property_id} not found\"}\n", "\n", "def get_class_properties(jsonld_data, class_id):\n", "    \"Get properties applicable to a class\"\n", "    properties = []\n", "    \n", "    for item in jsonld_data.get('@graph', []):\n", "        if item.get('@type') == 'rdf:Property':\n", "            domains = item.get('schema:domainIncludes', [])\n", "            if not isinstance(domains, list): domains = [domains]\n", "            \n", "            if any(d.get('@id') == class_id for d in domains if d):\n", "                properties.append({\n", "                    \"id\": item.get('@id'),\n", "                    \"label\": item.get('rdfs:label'),\n", "                    \"description\": item.get('rdfs:comment')[:100] + \"...\" \n", "                        if item.get('rdfs:comment') and len(item.get('rdfs:comment')) > 100 \n", "                        else item.get('rdfs:comment')\n", "                })\n", "    \n", "    return properties\n", "\n", "# Create our index\n", "schema_index = create_minimal_index(dataset_info['jsonld'])\n", "\n", "# Test our index and tools\n", "print(\"Schema.org Index:\")\n", "print(f\"- Classes: {len(schema_index['vocabularies']['schema.org']['classes'])}\")\n", "print(f\"- Properties: {len(schema_index['vocabularies']['schema.org']['properties'])}\")\n", "print(f\"- Class relationships: {len(schema_index['class_relationships'])}\")\n", "\n", "# Get Dataset class details\n", "dataset_details = get_class_details(dataset_info['jsonld'], 'schema:Dataset')\n", "print(\"\\nDataset Class Details:\")\n", "print(f\"- Label: {dataset_details.get('label')}\")\n", "print(f\"- Description: {dataset_details.get('description')[:100]}...\")\n", "print(f\"- Parent class: {dataset_details.get('parent_class')}\")\n", "print(f\"- Equivalent classes: {dataset_details.get('equivalent_classes')}\")\n", "\n", "# Get Dataset properties\n", "dataset_props = get_class_properties(dataset_info['jsonld'], 'schema:Dataset')\n", "print(f\"\\nDataset Properties ({len(dataset_props)}):\")\n", "for i, prop in enumerate(dataset_props[:3], 1):  # Show first 3\n", "    print(f\"{i}. {prop.get('label')}: {prop.get('description')}\")\n", "\n", "# Get details for a specific property\n", "if dataset_props:\n", "    prop_id = dataset_props[0]['id']\n", "    prop_details = get_property_details(jsonld_data=dataset_info['jsonld'], property_id=prop_id)\n", "    print(f\"\\nProperty Details for {prop_details.get('label')}:\")\n", "    print(f\"- Description: {prop_details.get('description')[:100]}...\")\n", "    print(f\"- Domains: {prop_details.get('domains')}\")\n", "    print(f\"- Ranges: {prop_details.get('ranges')}\")"], "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Schema.org Index:\n", "- Classes: 3\n", "- Properties: 136\n", "- Class relationships: 3\n", "\n", "Dataset Class Details:\n", "- Label: Dataset\n", "- Description: A body of structured information describing some topic(s) of interest....\n", "- Parent class: schema:CreativeWork\n", "- Equivalent classes: ['void:Dataset', 'dcmitype:Dataset', 'dcat:Dataset']\n", "\n", "Dataset Properties (10):\n", "1. catalog: A data catalog which contains this dataset.\n", "2. includedInDataCatalog: A data catalog which contains this dataset.\n", "3. variableMeasured: The variableMeasured property can indicate (repeated as necessary) the  variables that are measured ...\n", "\n", "Property Details for catalog:\n", "- Description: A data catalog which contains this dataset....\n", "- Domains: ['schema:Dataset']\n", "- Ranges: ['schema:DataCatalog']\n"]}], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["# jsonldnav.py\n", "__all__ = ['JsonLdNavigator', 'create_schema_index', 'get_class_details', \n", "           'get_property_details', 'get_class_properties', 'find_related_classes', \n", "           'search_terms', 'get_property_path']"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["#| export\n", "class JsonLdNavigator:\n", "    \"Navigator for JSON-LD documents with semantic understanding\"\n", "    def __init__(self, jsonld_data):\n", "        \"Initialize with JSON-LD data\"\n", "        self.data = jsonld_data if not isinstance(jsonld_data, str) else json.loads(jsonld_data)\n", "        self.index = create_schema_index(self.data)\n", "        \n", "    def get_class(self, class_id):\n", "        \"Get details about a class\"\n", "        return get_class_details(self.data, class_id)\n", "    \n", "    def get_property(self, property_id):\n", "        \"Get details about a property\"\n", "        return get_property_details(self.data, property_id)\n", "    \n", "    def get_properties_for(self, class_id, include_inherited=True):\n", "        \"Get properties applicable to a class\"\n", "        return get_class_properties(self.data, class_id, include_inherited)\n", "    \n", "    def find_related(self, class_id):\n", "        \"Find classes related to the specified class\"\n", "        return find_related_classes(self.data, class_id)\n", "    \n", "    def search(self, query):\n", "        \"Search for classes or properties matching query\"\n", "        return search_terms(self.data, query)\n", "    \n", "    def find_path(self, source_class, target_class, max_depth=2):\n", "        \"Find property paths between classes\"\n", "        return get_property_path(self.data, source_class, target_class, max_depth)\n", "    \n", "    def show_index(self):\n", "        \"Show a summary of the index\"\n", "        vocab = self.index[\"vocabularies\"][\"schema.org\"]\n", "        print(f\"Schema.org Index:\")\n", "        print(f\"- Classes: {vocab['class_count']}\")\n", "        print(f\"- Properties: {vocab['property_count']}\")\n", "        print(f\"\\nAvailable Affordances:\")\n", "        for name, desc in self.index[\"affordances\"].items():\n", "            print(f\"- {name}: {desc}\")\n", "        \n", "    def __repr__(self):\n", "        vocab = self.index[\"vocabularies\"][\"schema.org\"]\n", "        return f\"JsonLdNavigator(classes={vocab['class_count']}, properties={vocab['property_count']})\""], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["#| export\n", "# Core indexing function\n", "def create_schema_index(jsonld_data):\n", "    \"Create a semantic index from JSON-LD data\"\n", "    index = {\n", "        \"vocabularies\": {\n", "            \"schema.org\": {\n", "                \"prefix\": \"schema\",\n", "                \"namespace\": \"https://schema.org/\",\n", "                \"description\": \"Schema.org vocabulary for structured data\",\n", "                \"classes\": [],\n", "                \"properties\": [],\n", "                \"class_count\": 0,\n", "                \"property_count\": 0\n", "            }\n", "        },\n", "        \"class_hierarchy\": {},  # Tree structure of classes\n", "        \"property_groups\": {},  # Properties grouped by domain/function\n", "        \"affordances\": {\n", "            \"get_class(class_id)\": \"Get detailed information about a class\",\n", "            \"get_property(property_id)\": \"Get detailed information about a property\",\n", "            \"get_properties_for(class_id, include_inherited=True)\": \"Get properties for a class\",\n", "            \"find_related(class_id)\": \"Find classes semantically related to this class\",\n", "            \"search(query)\": \"Search for classes or properties matching a query\",\n", "            \"find_path(source_class, target_class)\": \"Find property paths between classes\"\n", "        }\n", "    }\n", "    \n", "    # Process classes and build class hierarchy\n", "    class_hierarchy = {}\n", "    for item in jsonld_data.get('@graph', []):\n", "        if item.get('@type') == 'rdfs:Class':\n", "            class_id = item.get('@id')\n", "            class_name = safe_text(item.get('rdfs:label'))\n", "            \n", "            if class_name:\n", "                index[\"vocabularies\"][\"schema.org\"][\"classes\"].append(class_name)\n", "                index[\"vocabularies\"][\"schema.org\"][\"class_count\"] += 1\n", "                \n", "                # Add to class hierarchy\n", "                parent_class = item.get('rdfs:subClassOf', {}).get('@id')\n", "                if parent_class:\n", "                    if parent_class not in class_hierarchy:\n", "                        class_hierarchy[parent_class] = []\n", "                    class_hierarchy[parent_class].append(class_id)\n", "    \n", "    index[\"class_hierarchy\"] = class_hierarchy\n", "    \n", "    # Process properties and group them\n", "    property_groups = {\n", "        \"identification\": [],  # Properties for identifying things\n", "        \"descriptive\": [],     # Properties for describing things\n", "        \"relational\": [],      # Properties linking to other entities\n", "        \"temporal\": [],        # Time-related properties\n", "        \"other\": []            # Other properties\n", "    }\n", "    \n", "    for item in jsonld_data.get('@graph', []):\n", "        if item.get('@type') == 'rdf:Property':\n", "            prop_id = item.get('@id')\n", "            prop_name = safe_text(item.get('rdfs:label'))\n", "            \n", "            if prop_name:\n", "                index[\"vocabularies\"][\"schema.org\"][\"properties\"].append(prop_name)\n", "                index[\"vocabularies\"][\"schema.org\"][\"property_count\"] += 1\n", "                \n", "                # Simple property categorization\n", "                if prop_name in ['identifier', 'url', 'name', 'id']:\n", "                    property_groups[\"identification\"].append(prop_id)\n", "                elif prop_name in ['description', 'text', 'keywords']:\n", "                    property_groups[\"descriptive\"].append(prop_id)\n", "                elif any(x in prop_name.lower() for x in ['date', 'time', 'duration']):\n", "                    property_groups[\"temporal\"].append(prop_id)\n", "                else:\n", "                    # Check if it links to another entity by examining ranges\n", "                    ranges = item.get('schema:rangeIncludes', [])\n", "                    if not isinstance(ranges, list): ranges = [ranges]\n", "                    \n", "                    if any('schema:' in r.get('@id', '') for r in ranges if r):\n", "                        property_groups[\"relational\"].append(prop_id)\n", "                    else:\n", "                        property_groups[\"other\"].append(prop_id)\n", "    \n", "    index[\"property_groups\"] = property_groups\n", "    \n", "    return index"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["#| export\n", "# Core navigation functions\n", "def get_class_details(jsonld_data, class_id):\n", "    \"Get detailed information about a specific class\"\n", "    for item in jsonld_data.get('@graph', []):\n", "        if item.get('@id') == class_id:\n", "            return {\n", "                \"id\": item.get('@id'),\n", "                \"label\": item.get('rdfs:label'),\n", "                \"description\": item.get('rdfs:comment'),\n", "                \"parent_class\": item.get('rdfs:subClassOf', {}).get('@id'),\n", "                \"equivalent_classes\": [c.get('@id') for c in L(item.get('owl:equivalentClass'))]\n", "            }\n", "    return {\"error\": f\"Class {class_id} not found\"}"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["#| export\n", "def get_property_details(jsonld_data, property_id):\n", "    \"Get detailed information about a specific property\"\n", "    for item in jsonld_data.get('@graph', []):\n", "        if item.get('@id') == property_id:\n", "            # Handle domains and ranges which might be lists or single items\n", "            domains = item.get('schema:domainIncludes', [])\n", "            if not isinstance(domains, list): domains = [domains]\n", "            domain_ids = [d.get('@id') for d in domains if d]\n", "            \n", "            ranges = item.get('schema:rangeIncludes', [])\n", "            if not isinstance(ranges, list): ranges = [ranges]\n", "            range_ids = [r.get('@id') for r in ranges if r]\n", "            \n", "            return {\n", "                \"id\": item.get('@id'),\n", "                \"label\": item.get('rdfs:label'),\n", "                \"description\": item.get('rdfs:comment'),\n", "                \"domains\": domain_ids,\n", "                \"ranges\": range_ids,\n", "                \"subproperty_of\": item.get('rdfs:subPropertyOf', {}).get('@id')\n", "            }\n", "    return {\"error\": f\"Property {property_id} not found\"}"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["#| export\n", "def get_class_properties(jsonld_data, class_id, include_inherited=True):\n", "    \"Get properties applicable to a class\"\n", "    properties = []\n", "    \n", "    # Get class hierarchy if including inherited properties\n", "    class_hierarchy = [class_id]\n", "    if include_inherited:\n", "        current_class = get_class_details(jsonld_data, class_id)\n", "        while current_class and 'error' not in current_class:\n", "            parent_class = current_class.get('parent_class')\n", "            if parent_class and parent_class not in class_hierarchy:\n", "                class_hierarchy.append(parent_class)\n", "                current_class = get_class_details(jsonld_data, parent_class)\n", "            else:\n", "                break\n", "    \n", "    # Find properties for each class in the hierarchy\n", "    for item in jsonld_data.get('@graph', []):\n", "        if item.get('@type') == 'rdf:Property':\n", "            domains = item.get('schema:domainIncludes', [])\n", "            if not isinstance(domains, list): domains = [domains]\n", "            domain_ids = [d.get('@id') for d in domains if d]\n", "            \n", "            # Check if any class in the hierarchy is in the domains\n", "            if any(cls_id in domain_ids for cls_id in class_hierarchy):\n", "                prop = {\n", "                    \"id\": item.get('@id'),\n", "                    \"label\": item.get('rdfs:label'),\n", "                    \"description\": item.get('rdfs:comment')[:100] + \"...\" \n", "                        if item.get('rdfs:comment') and len(item.get('rdfs:comment')) > 100 \n", "                        else item.get('rdfs:comment'),\n", "                    \"inherited\": class_id != domain_ids[0] if domain_ids else False\n", "                }\n", "                properties.append(prop)\n", "    \n", "    return properties"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["#| export\n", "def find_related_classes(jsonld_data, class_id):\n", "    \"\"\"Find classes related to the specified class through properties\"\"\"\n", "    related = {\n", "        \"parent_classes\": [],\n", "        \"child_classes\": [],\n", "        \"referenced_by\": [],\n", "        \"references\": []\n", "    }\n", "    \n", "    # Find parent class\n", "    for item in jsonld_data.get('@graph', []):\n", "        if item.get('@id') == class_id and item.get('@type') == 'rdfs:Class':\n", "            parent = item.get('rdfs:subClassOf', {}).get('@id')\n", "            if parent:\n", "                related[\"parent_classes\"].append(parent)\n", "    \n", "    # Find child classes\n", "    for item in jsonld_data.get('@graph', []):\n", "        if item.get('@type') == 'rdfs:Class':\n", "            parent = item.get('rdfs:subClassOf', {}).get('@id')\n", "            if parent == class_id:\n", "                related[\"child_classes\"].append(item.get('@id'))\n", "    \n", "    # Find classes referenced by this class's properties\n", "    properties = get_class_properties(jsonld_data, class_id)\n", "    for prop in properties:\n", "        prop_details = get_property_details(jsonld_data, prop.get('id'))\n", "        for range_class in prop_details.get('ranges', []):\n", "            if range_class not in related[\"references\"]:\n", "                related[\"references\"].append(range_class)\n", "    \n", "    # Find classes that reference this class\n", "    for item in jsonld_data.get('@graph', []):\n", "        if item.get('@type') == 'rdf:Property':\n", "            domains = item.get('schema:domainIncludes', [])\n", "            if not isinstance(domains, list): domains = [domains]\n", "            domain_ids = [d.get('@id') for d in domains if d]\n", "            \n", "            ranges = item.get('schema:rangeIncludes', [])\n", "            if not isinstance(ranges, list): ranges = [ranges]\n", "            range_ids = [r.get('@id') for r in ranges if r]\n", "            \n", "            if class_id in range_ids:\n", "                for domain in domain_ids:\n", "                    if domain not in related[\"referenced_by\"]:\n", "                        related[\"referenced_by\"].append(domain)\n", "    \n", "    return related"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["#| export\n", "def search_terms(jsonld_data, query):\n", "    \"\"\"Search for classes or properties matching a query string\"\"\"\n", "    results = {\n", "        \"classes\": [],\n", "        \"properties\": []\n", "    }\n", "    \n", "    query = query.lower()\n", "    \n", "    for item in jsonld_data.get('@graph', []):\n", "        label = str(item.get('rdfs:label', '')).lower()\n", "        description = str(item.get('rdfs:comment', '')).lower()\n", "        \n", "        if query in label or query in description:\n", "            result = {\n", "                \"id\": item.get('@id'),\n", "                \"label\": item.get('rdfs:label'),\n", "                \"description\": item.get('rdfs:comment')[:100] + \"...\" \n", "                    if item.get('rdfs:comment') and len(item.get('rdfs:comment')) > 100 \n", "                    else item.get('rdfs:comment')\n", "            }\n", "            \n", "            if item.get('@type') == 'rdfs:Class':\n", "                results[\"classes\"].append(result)\n", "            elif item.get('@type') == 'rdf:Property':\n", "                results[\"properties\"].append(result)\n", "    \n", "    return results"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["#| export\n", "def get_property_path(jsonld_data, source_class, target_class, max_depth=2):\n", "    \"\"\"Find property paths between two classes\"\"\"\n", "    paths = []\n", "    \n", "    # Get properties of the source class\n", "    properties = get_class_properties(jsonld_data, source_class)\n", "    \n", "    # First level - direct connections\n", "    for prop in properties:\n", "        prop_details = get_property_details(jsonld_data, prop.get('id'))\n", "        if target_class in prop_details.get('ranges', []):\n", "            paths.append({\n", "                \"path\": [{\"class\": source_class, \"property\": prop.get('id'), \"target\": target_class}],\n", "                \"description\": f\"{source_class} \u2192 {prop.get('label')} \u2192 {target_class}\"\n", "            })\n", "    \n", "    # Second level - if max_depth > 1\n", "    if max_depth > 1 and not paths:\n", "        for prop in properties:\n", "            prop_details = get_property_details(jsonld_data, prop.get('id'))\n", "            for intermediate_class in prop_details.get('ranges', []):\n", "                # Skip if not a class (like literal values)\n", "                if not intermediate_class.startswith('schema:'):\n", "                    continue\n", "                    \n", "                # Check if this intermediate class has properties to the target\n", "                intermediate_properties = get_class_properties(jsonld_data, intermediate_class)\n", "                for int_prop in intermediate_properties:\n", "                    int_prop_details = get_property_details(jsonld_data, int_prop.get('id'))\n", "                    if target_class in int_prop_details.get('ranges', []):\n", "                        paths.append({\n", "                            \"path\": [\n", "                                {\"class\": source_class, \"property\": prop.get('id'), \"target\": intermediate_class},\n", "                                {\"class\": intermediate_class, \"property\": int_prop.get('id'), \"target\": target_class}\n", "                            ],\n", "                            \"description\": f\"{source_class} \u2192 {prop.get('label')} \u2192 {intermediate_class} \u2192 {int_prop.get('label')} \u2192 {target_class}\"\n", "                        })\n", "    \n", "    return paths"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["#| export\n", "# Helper function to always return a list\n", "def L(x): return x if isinstance(x, list) else [x] if x is not None else []"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["#| export\n", "def safe_text(value):\n", "    \"Safely extract text from a JSON-LD value which might be a string or a dict\"\n", "    if value is None:\n", "        return \"\"\n", "    if isinstance(value, dict):\n", "        return str(value.get('@value', ''))\n", "    return str(value)"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["# Example usage\n", "nav = JsonLdNavigator(dataset_info['jsonld'])\n", "nav.show_index()"], "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Schema.org Index:\n", "- Classes: 3\n", "- Properties: 136\n", "\n", "Available Affordances:\n", "- get_class(class_id): Get detailed information about a class\n", "- get_property(property_id): Get detailed information about a property\n", "- get_properties_for(class_id, include_inherited=True): Get properties for a class\n", "- find_related(class_id): Find classes semantically related to this class\n", "- search(query): Search for classes or properties matching a query\n", "- find_path(source_class, target_class): Find property paths between classes\n"]}], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["# Get Dataset class details\n", "dataset = nav.get_class('schema:Dataset')\n", "print(f\"\\nDataset: {dataset['label']}\")\n", "print(f\"Description: {dataset['description'][:100]}...\")"], "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "Dataset: Dataset\n", "Description: A body of structured information describing some topic(s) of interest....\n"]}], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["# Find Dataset properties\n", "props = nav.get_properties_for('schema:Dataset')\n", "print(f\"\\nDataset has {len(props)} properties:\")\n", "for i, prop in enumerate(props[:3], 1):  # Show first 3\n", "    print(f\"{i}. {prop['label']}: {prop['description']}\")"], "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "Dataset has 136 properties:\n", "1. isBasedOn: A resource from which this work is derived or from which it is a modification or adaptation.\n", "2. potentialAction: Indicates a potential Action, which describes an idealized action in which this thing would play an ...\n", "3. hasPart: Indicates an item or CreativeWork that is part of this item, or CreativeWork (in some sense).\n"]}], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["# Find related classes\n", "related = nav.find_related('schema:Dataset')\n", "print(f\"\\nClasses related to Dataset:\")\n", "print(f\"- Parent classes: {related['parent_classes']}\")\n", "print(f\"- Referenced classes: {related['references'][:3]}...\")"], "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "Classes related to Dataset:\n", "- Parent classes: ['schema:CreativeWork']\n", "- Referenced classes: ['schema:CreativeWork', 'schema:URL', 'schema:Product']...\n"]}], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["# Search for a term\n", "results = nav.search('catalog')\n", "print(f\"\\nSearch results for 'catalog':\")\n", "print(f\"- Found {len(results['properties'])} properties and {len(results['classes'])} classes\")"], "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "Search results for 'catalog':\n", "- Found 4 properties and 0 classes\n"]}], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "Is this working the way that we think it should be? Have we made any progress here?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "Yes, this is working well! We've made significant progress in developing a coherent, fastai-style library for JSON-LD navigation that could be integrated with nbdev.\n", "\n", "Our accomplishments:\n", "\n", "1. **Created a clean, object-oriented API**: The `JsonLdNavigator` class provides a simple interface to all our functionality, following fastai's style of having a core class with intuitive methods.\n", "\n", "2. **Implemented proper code organization**: We've structured the code with proper exports, documentation strings, and a clear separation of concerns - exactly how you'd want it for nbdev development.\n", "\n", "3. **Built powerful semantic navigation tools**: The functions we've created allow for sophisticated exploration of JSON-LD documents:\n", "   - Finding classes and their properties\n", "   - Discovering relationships between classes\n", "   - Searching for terms\n", "   - Identifying paths between classes\n", "\n", "4. **Demonstrated working functionality**: Our test code shows that the library works with real Schema.org data, finding properties, related classes, and search results.\n", "\n", "The output shows we're successfully:\n", "- Indexing the Schema.org vocabulary (3 classes, 136 properties)\n", "- Getting detailed information about the Dataset class\n", "- Finding all 136 applicable properties (both direct and inherited)\n", "- Identifying related classes (parent class and referenced classes)\n", "- Searching for terms within the vocabulary\n", "\n", "This is a solid foundation for a JSON-LD navigation library that could be used by LLMs in agentic workflows. The next steps would be to package this properly with nbdev and develop the LLM integration components.\n", "\n", "What aspect would you like to focus on next?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "Okay, so we need some wrapper functions for actually going to URLs and pulling back either JSON-LD, RDF, or other vocabularies.Maybe even texts in the case of Schema.org documentation.This sounds really complicated, so how should we approach this? Because right now we've only done the simple thing of manually loading the schema.org Dataset example, correct?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "You're right - we've only manually loaded the Schema.org Dataset example so far. To make this library truly useful, we need to add functions that can fetch and process vocabulary data from various sources.\n", "\n", "Let's approach this step by step:\n", "\n", "1. **Create a vocabulary fetcher module** that can handle different formats:\n", "   - JSON-LD from URLs\n", "   - RDF/XML, Turtle, and other RDF formats\n", "   - HTML with embedded structured data\n", "   - Documentation pages for human-readable explanations\n", "\n", "2. **Implement content negotiation** to request the appropriate format from vocabulary servers\n", "\n", "3. **Add caching** to avoid repeated requests for the same resources\n", "\n", "Here's how we might structure this:\n", "\n", "```python\n", "# vocab_fetcher.py\n", "__all__ = ['fetch_vocabulary', 'fetch_term', 'fetch_documentation']\n", "\n", "def fetch_vocabulary(url, format='jsonld', cache=True):\n", "    \"\"\"Fetch a vocabulary from a URL in the specified format\n", "    \n", "    Args:\n", "        url: URL of the vocabulary\n", "        format: Desired format ('jsonld', 'rdf', 'turtle', 'html')\n", "        cache: Whether to cache the result\n", "        \n", "    Returns:\n", "        The vocabulary data in the requested format\n", "    \"\"\"\n", "    # Check cache first\n", "    if cache and url in _vocab_cache:\n", "        return _vocab_cache[url]\n", "    \n", "    # Determine appropriate headers for content negotiation\n", "    headers = get_content_headers(format)\n", "    \n", "    try:\n", "        # Make the request\n", "        response = xget(url, headers=headers)\n", "        \n", "        if response.status_code == 200:\n", "            # Parse the response based on format\n", "            result = parse_response(response, format)\n", "            \n", "            # Cache the result\n", "            if cache:\n", "                _vocab_cache[url] = result\n", "                \n", "            return result\n", "        else:\n", "            print(f\"Failed to fetch vocabulary: {response.status_code}\")\n", "            return None\n", "    except Exception as e:\n", "        print(f\"Error fetching vocabulary: {e}\")\n", "        return None\n", "\n", "def fetch_term(vocabulary_url, term, format='jsonld', cache=True):\n", "    \"\"\"Fetch a specific term from a vocabulary\n", "    \n", "    Args:\n", "        vocabulary_url: Base URL of the vocabulary\n", "        term: The term to fetch\n", "        format: Desired format\n", "        cache: Whether to cache the result\n", "        \n", "    Returns:\n", "        The term data in the requested format\n", "    \"\"\"\n", "    # Handle different vocabulary sources differently\n", "    if 'schema.org' in vocabulary_url:\n", "        return fetch_schema_org_term(term, format, cache)\n", "    elif 'w3.org' in vocabulary_url:\n", "        return fetch_w3c_term(vocabulary_url, term, format, cache)\n", "    else:\n", "        # Generic approach\n", "        term_url = f\"{vocabulary_url.rstrip('/')}/{term}\"\n", "        return fetch_vocabulary(term_url, format, cache)\n", "\n", "def fetch_documentation(vocabulary_url, term, cache=True):\n", "    \"\"\"Fetch human-readable documentation for a term\n", "    \n", "    Args:\n", "        vocabulary_url: Base URL of the vocabulary\n", "        term: The term to fetch documentation for\n", "        cache: Whether to cache the result\n", "        \n", "    Returns:\n", "        Human-readable documentation as text\n", "    \"\"\"\n", "    # Handle different vocabulary sources\n", "    if 'schema.org' in vocabulary_url:\n", "        return fetch_schema_org_docs(term, cache)\n", "    elif 'w3.org' in vocabulary_url:\n", "        return fetch_w3c_docs(vocabulary_url, term, cache)\n", "    else:\n", "        # Try to get HTML and extract text\n", "        term_url = f\"{vocabulary_url.rstrip('/')}/{term}\"\n", "        html = fetch_vocabulary(term_url, format='html', cache=cache)\n", "        if html:\n", "            return extract_documentation_from_html(html)\n", "        return None\n", "\n", "# Helper functions\n", "def get_content_headers(format):\n", "    \"\"\"Get appropriate headers for content negotiation\"\"\"\n", "    if format == 'jsonld':\n", "        return {'Accept': 'application/ld+json'}\n", "    elif format == 'rdf':\n", "        return {'Accept': 'application/rdf+xml'}\n", "    elif format == 'turtle':\n", "        return {'Accept': 'text/turtle'}\n", "    else:\n", "        return {'Accept': 'text/html'}\n", "\n", "def parse_response(response, format):\n", "    \"\"\"Parse response based on format\"\"\"\n", "    if format == 'jsonld':\n", "        return response.json()\n", "    elif format in ['rdf', 'turtle']:\n", "        # Would need rdflib or similar here\n", "        return response.text\n", "    else:\n", "        return response.text\n", "\n", "# Vocabulary-specific functions\n", "def fetch_schema_org_term(term, format='jsonld', cache=True):\n", "    \"\"\"Fetch a term from Schema.org\"\"\"\n", "    if format == 'jsonld':\n", "        url = f\"https://schema.org/{term}.jsonld\"\n", "    else:\n", "        url = f\"https://schema.org/{term}\"\n", "    return fetch_vocabulary(url, format, cache)\n", "\n", "def fetch_schema_org_docs(term, cache=True):\n", "    \"\"\"Fetch documentation for a Schema.org term\"\"\"\n", "    url = f\"https://schema.org/{term}\"\n", "    html = fetch_vocabulary(url, format='html', cache=cache)\n", "    if html:\n", "        # Extract the main documentation section\n", "        soup = bs(html, 'html.parser')\n", "        main_content = soup.find('div', class_='description')\n", "        if main_content:\n", "            return main_content.get_text()\n", "    return None\n", "\n", "# Initialize cache\n", "_vocab_cache = {}\n", "```\n", "\n", "This module would give us the foundation for fetching vocabulary data from different sources. We could then integrate it with our `JsonLdNavigator` class to allow dynamic loading of vocabularies.\n", "\n", "What do you think? Is this approach comprehensive enough, or should we focus on a specific aspect first?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "Ok. If I'm moving this to a github repo using nbdev to export the python modules, how should we structure the project?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "For an nbdev project focused on JSON-LD navigation, here's how I'd structure the repository:\n", "\n", "## Project Structure for `jsonldnav`\n", "\n", "```\n", "jsonldnav/\n", "\u251c\u2500\u2500 .github/\n", "\u2502   \u2514\u2500\u2500 workflows/\n", "\u2502       \u251c\u2500\u2500 test.yaml\n", "\u2502       \u2514\u2500\u2500 deploy.yaml\n", "\u251c\u2500\u2500 nbs/\n", "\u2502   \u251c\u2500\u2500 00_core.ipynb       # Core functionality, base classes\n", "\u2502   \u251c\u2500\u2500 01_fetch.ipynb      # Vocabulary fetching functionality\n", "\u2502   \u251c\u2500\u2500 02_navigate.ipynb   # Navigation and relationship discovery\n", "\u2502   \u251c\u2500\u2500 03_index.ipynb      # Indexing and search functionality\n", "\u2502   \u251c\u2500\u2500 04_schema.ipynb     # Schema.org specific functionality\n", "\u2502   \u251c\u2500\u2500 05_llm.ipynb        # LLM integration helpers\n", "\u2502   \u251c\u2500\u2500 index.ipynb         # Landing page for documentation\n", "\u2502   \u2514\u2500\u2500 examples.ipynb      # Usage examples\n", "\u251c\u2500\u2500 jsonldnav/\n", "\u2502   \u251c\u2500\u2500 __init__.py         # Auto-generated by nbdev\n", "\u2502   \u251c\u2500\u2500 _modidx.py          # Auto-generated by nbdev\n", "\u2502   \u2514\u2500\u2500 [other modules]     # Auto-generated by nbdev\n", "\u251c\u2500\u2500 settings.ini            # nbdev configuration\n", "\u251c\u2500\u2500 setup.py                # Auto-generated by nbdev\n", "\u251c\u2500\u2500 README.md               # Auto-generated from index.ipynb\n", "\u251c\u2500\u2500 LICENSE                 # License file\n", "\u2514\u2500\u2500 .gitignore              # Standard Python gitignore + nbdev specifics\n", "```\n", "\n", "## Notebook Content Structure\n", "\n", "### 00_core.ipynb\n", "- Base `JsonLdNavigator` class\n", "- Core data structures and utilities\n", "- Helper functions for handling JSON-LD\n", "\n", "### 01_fetch.ipynb\n", "- Vocabulary fetching functions\n", "- Content negotiation\n", "- Format conversion\n", "- Caching mechanism\n", "\n", "### 02_navigate.ipynb\n", "- Class and property navigation\n", "- Relationship discovery\n", "- Path finding between concepts\n", "\n", "### 03_index.ipynb\n", "- Index creation and management\n", "- Search functionality\n", "- Affordance generation\n", "\n", "### 04_schema.ipynb\n", "- Schema.org specific functionality\n", "- Handling Schema.org's unique structure\n", "- Schema.org documentation extraction\n", "\n", "### 05_llm.ipynb\n", "- LLM integration helpers\n", "- Agentic workflow tools\n", "- Context window optimization\n", "\n", "## settings.ini Configuration\n", "\n", "```ini\n", "[DEFAULT]\n", "# Library name\n", "lib_name = jsonldnav\n", "# Exported module name\n", "module_name = jsonldnav\n", "# Description\n", "description = Semantic navigation for JSON-LD documents\n", "# Keywords\n", "keywords = json-ld, semantic web, rdf, schema.org, llm\n", "# Author\n", "author = Your Name\n", "# Author email\n", "author_email = your.email@example.com\n", "# Copyright\n", "copyright = Your Name or Company\n", "# Branch\n", "branch = main\n", "# Version\n", "version = 0.0.1\n", "# Min python version\n", "min_python = 3.7\n", "# License\n", "license = apache2\n", "# Status\n", "status = 2\n", "# Requirements\n", "requirements = fastcore httpx beautifulsoup4 lxml\n", "# Optional requirements\n", "dev_requirements = pytest black isort\n", "# Black formatting\n", "black_formatting = True\n", "```\n", "\n", "## Development Workflow\n", "\n", "1. Start by creating the core notebooks and implementing basic functionality\n", "2. Use `nbdev_build_lib` to generate the Python modules\n", "3. Use `nbdev_test` to run tests\n", "4. Use `nbdev_build_docs` to generate documentation\n", "5. Iterate and refine\n", "\n", "This structure follows the nbdev philosophy of \"notebooks first\" development, where all code lives in notebooks and is exported to Python modules. It also makes it easy to add documentation and examples alongside the code.\n", "\n", "Does this structure make sense for your project?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "So there's a lot of experimentation in this notebook. Could you give me a list of the functions that need to go into the 00_core?You don't actually have to write any code, just list the functions."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "Here's a list of the core functions that should go into `00_core.ipynb`:\n", "\n", "### Core Functions for 00_core.ipynb\n", "\n", "1. `JsonLdNavigator` class (main class)\n", "   - `__init__`\n", "   - `get_class`\n", "   - `get_property`\n", "   - `get_properties_for`\n", "   - `find_related`\n", "   - `search`\n", "   - `find_path`\n", "   - `show_index`\n", "   - `__repr__`\n", "\n", "2. Basic helpers:\n", "   - `L` (list wrapper)\n", "   - `safe_text`\n", "\n", "3. JSON-LD processing:\n", "   - `create_schema_index`\n", "   - `get_class_details`\n", "   - `get_property_details` \n", "   - `get_class_properties`\n", "\n", "4. Relationship functions:\n", "   - `find_related_classes`\n", "   - `search_terms`\n", "   - `get_property_path`\n", "\n", "These functions form the foundation of the library, providing the core functionality for navigating JSON-LD documents. The other notebooks would build on this foundation by adding fetching capabilities, specialized vocabulary handling, and LLM integration."]}, {"cell_type": "code", "metadata": {}, "source": [], "outputs": [], "execution_count": null}], "metadata": {"kernelspec": {"display_name": "python3", "language": "python", "name": "python3"}}, "nbformat": 4, "nbformat_minor": 4}